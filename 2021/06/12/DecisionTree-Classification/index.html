<!DOCTYPE html>
<html lang="zh-Hans">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="x5-fullscreen" content="true">
<meta name="full-screen" content="yes">
<meta name="theme-color" content="#317EFB" />
<meta content="width=device-width, initial-scale=1.0, maximum-scale=5.0, user-scalable=0" name="viewport">
<meta name="description" content="决策树">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树分类算法原理">
<meta property="og:url" content="https://www.adream.icu/2021/06/12/DecisionTree-Classification/index.html">
<meta property="og:site_name" content="Adream blog">
<meta property="og:description" content="决策树">
<meta property="og:locale">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="og:image" content="https://www.adream.icu/img/404.jpg">
<meta property="article:published_time" content="2021-06-12T15:20:59.000Z">
<meta property="article:modified_time" content="2024-03-12T11:09:01.537Z">
<meta property="article:author" content="Adream">
<meta property="article:tag" content="算法">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.adream.icu/img/404.jpg">

    <meta name="keywords" content="决策树,分类">


<title >决策树分类算法原理</title>

<!-- Favicon -->

    <link href='/favicon.png?v=2.1.10' rel='icon' type='image/png' sizes='16x16' ></link>


    <link href='/favicon.png?v=2.1.10' rel='icon' type='image/png' sizes='32x32' ></link>


    <link href='/apple-touch-icon.png?v=2.1.10' rel='apple-touch-icon' sizes='180x180' ></link>


    <link href='/site.webmanifest' rel='manifest' ></link>


<!-- Plugin -->




    
<link rel="stylesheet" href="/css/plugins/bootstrap.row.css">

    
<link rel="stylesheet" href="https://npm.elemecdn.com/@fancyapps/ui@4.0/dist/fancybox.css">

    
    
<link rel="stylesheet" href="https://npm.elemecdn.com/katex@latest/dist/katex.min.css">





<!-- Icon -->

    
<link rel="stylesheet" href="/css/plugins/font-awesome.min.css">



    
<script src="//at.alicdn.com/t/c/font_3637590_i4hyyea14ur.js"></script>



<!-- Variable -->
<script>window.ASYNC_CONFIG = {"hostname":"www.adream.icu","author":"Adream","root":"/","typed_text":["AI Developer"],"theme_version":"2.1.10","theme":{"switch":false,"default":"auto"},"favicon":{"logo":"favicon.svg","icon16":"favicon.png","icon32":"favicon.png","appleTouchIcon":"apple-touch-icon.png","webmanifest":"/site.webmanifest","visibilitychange":true,"hidden":"/failure.ico","showText":"(/≧▽≦/)咦！又好了！","hideText":"(●—●)喔哟，崩溃啦！"},"i18n":{"placeholder":"搜索文章...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）","author":"本文作者：","copyright_link":"本文链接：","copyright_license_title":"版权声明：","copyright_license_content":"本博客所有文章除特别声明外，均默认采用 undefined 许可协议。","copy_success":"复制成功","copy_failure":"复制失败","open_read_mode":"进入阅读模式","exit_read_mode":"退出阅读模式","notice_outdate_message":"距离上次更新已经 undefined 天了, 文章内容可能已经过时。","sticky":"置顶","just":"刚刚","min":"分钟前","hour":"小时前","day":"天前","month":"个月前"},"swup":true,"plugin":{"flickr_justified_gallery":"https://npm.elemecdn.com/flickr-justified-gallery@latest/dist/fjGallery.min.js"},"icons":{"sun":"far fa-sun","moon":"far fa-moon","play":"icon-yunhang","email":"icon-email","next":"icon-arrow-right","calendar":"icon-rili","clock":"icon-shijian","user":"icon-yonghu","back_top":"icon-backtop","close":"icon-guanbi","search":"icon-chaxun","reward":"icon-qiandai","user_tag":"icon-yonghu1","toc_tag":"icon-liebiao","read":"icon-yuedu","arrows":"icon-arrows-h","double_arrows":"icon-angle-double-down","copy":"icon-copy"},"icontype":"symbol","highlight":{"plugin":"highlighjs","theme":true,"copy":true,"lang":true,"title":"mac","height_limit":200},"toc":{"post_title":false},"live_time":{"start_time":"2021/04/10 17:00:00","prefix":"博客已萌萌哒运行 undefined 天"},"covers":["/img/block.jpg","https://th.wallhaven.cc/orig/wq/wqvkl7.jpg","https://th.wallhaven.cc/orig/rd/rdq3v1.jpg","https://th.wallhaven.cc/orig/rd/rd183j.jpg","https://th.wallhaven.cc/orig/q2/q287wd.jpg","https://th.wallhaven.cc/orig/g7/g79ov3.jpg","https://th.wallhaven.cc/orig/q2/q2mkzr.jpg","https://th.wallhaven.cc/orig/v9/v9j3yp.jpg","https://th.wallhaven.cc/orig/y8/y8yvzx.jpg","https://th.wallhaven.cc/orig/1k/1kdw2w.jpg","https://th.wallhaven.cc/orig/57/57jqk1.jpg","https://th.wallhaven.cc/orig/57/5762p1.jpg","https://th.wallhaven.cc/orig/j3/j3zo1y.jpg","https://th.wallhaven.cc/orig/m9/m9gkky.jpg","https://th.wallhaven.cc/orig/e7/e7kv9k.jpg","https://th.wallhaven.cc/orig/ym/ym9ldk.jpg","https://th.wallhaven.cc/orig/pk/pk5259.jpg","https://th.wallhaven.cc/orig/8o/8opxpk.jpg","https://th.wallhaven.cc/orig/k7/k7yog7.jpg","https://th.wallhaven.cc/orig/v9/v93zv3.jpg","https://th.wallhaven.cc/orig/wq/wqj65q.jpg","https://th.wallhaven.cc/orig/p9/p9kg1m.jpg","https://th.wallhaven.cc/orig/8o/8o9vw1.jpg","https://th.wallhaven.cc/orig/x8/x8yy3o.jpg"],"search":{"enable":true,"type":"local","href":"https://www.google.com/search?q=site:","domain":null,"preload":true,"trigger":"auto","path":"search.xml"}};</script>
<script id="async-page-config">window.PAGE_CONFIG = {"isPost":true,"isHome":false,"postUpdate":"2024-03-12 19:09:01"};</script>

<!-- Theme mode css -->
<link data-swup-theme rel="stylesheet" href="/css/index.css?v=2.1.10" id="trm-switch-style">
<script>
    let defaultMode = ASYNC_CONFIG.theme.default !=='auto' ?  ASYNC_CONFIG.theme.default : (window.matchMedia("(prefers-color-scheme: light)").matches ? 'style-light' : 'style-dark')
    let catchMode = localStorage.getItem('theme-mode') || defaultMode;
    let type = catchMode === 'style-dark' ? 'add' : 'remove';
    document.documentElement.classList[type]('dark')
</script>

<!-- CDN -->


    
    



<!-- Site Analytics -->
 
<meta name="generator" content="Hexo 7.1.1"><link rel="alternate" href="/atom.xml" title="Adream blog" type="application/atom+xml">
</head>

<body>

  <!-- app wrapper -->
  <div class="trm-app-frame">

    <!-- page preloader -->
    <div class="trm-preloader">
  <div class="loader">
    <div class="inner one"></div>
    <div class="inner two"></div>
    <div class="inner three"></div>
  </div>
  <div style="margin-top: 120px; font-weight: bold; font-size: 20px">
    努力加载中......
  </div>
</div>

    <!-- page preloader end -->

    <!-- change mode preloader -->
    <div class="trm-mode-swich-animation-frame">
    <div class="trm-mode-swich-animation">
        <i class="i-sun"><svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#far fa-sun"></use>
</svg></i>
        <div class="trm-horizon"></div>
        <i class="i-moon"><svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#far fa-moon"></use>
</svg></i>
    </div>
</div>
    <!-- change mode preloader end -->

      <!-- scroll container -->
      <div id="trm-dynamic-content" class="trm-swup-animation">
        <div id="trm-scroll-container" class="trm-scroll-container" style="opacity: 0">
            <!-- top bar -->
            <header class="trm-top-bar">
	<div class="container">
		<div class="trm-left-side">
			<!-- logo -->
<a href="/" class="trm-logo-frame trm-anima-link">
    
        <img alt="logo" src="/favicon.svg">
    
    
</a>
<!-- logo end -->
		</div>
		<div class="trm-right-side">
			<!-- menu -->
<div class="trm-menu">
    <nav>
        <ul>
            
            <li class="menu-item-has-children ">
                <a  href="/" target="">
                    首页
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a  href="/archives/" target="">
                    归档
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a  href="/projects/" target="">
                    项目
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a  href="/links/" target="">
                    友链
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a  href="/about/" target="">
                    关于
                </a>
                
            </li>
            
        </ul>
    </nav>
</div>
<!-- menu end -->
			
			
		</div>
		<div class="trm-menu-btn">
			<span></span>
		</div>
	</div>
</header>
            <!-- top bar end -->

            <!-- body -->
            
<div class="trm-content-start">
    <!-- banner -->
    <div class="trm-banner">
    
    <!-- banner video cover -->
    <video autoplay="autoplay" loop muted playsinline webkit-playinginline class="trm-banner-cover">
        <source src="//cdn.moji.com/websrc/video/autumn20190924.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'>
        Your browser does not support HTML5 video.
    </video>
    <!-- banner video cover end -->
    

    <!-- banner content -->
    <div class="trm-banner-content trm-overlay">
        <div class="container">
            <div class="row">
                
                <div class="col-lg-4"></div>
                
                <div class="col-lg-8">

                    <!-- banner title -->
                    <div class="trm-banner-text ">
                        <div class="trm-label trm-mb-20">
                            NEWS LETTER
                        </div>
                        <h1 class="trm-mb-30 trm-hsmb-font">
                            决策树分类算法原理
                        </h1>

                        
                            <ul class="trm-breadcrumbs trm-label">
                                <li>
                                    <a href="/" class="trm-anima-link">Home</a>
                                </li>
                                <li>
                                    <span>
                                        2021
                                    </span>
                                </li>
                            </ul>
                        
                    </div>
                    <!-- banner title end -->

                    <!-- scroll hint -->
                    <span id="scroll-triger" class="trm-scroll-hint-frame">
                        <div class="trm-scroll-hint"></div>
                        <span class="trm-label">Scroll down</span>
                    </span>
                    <!-- scroll hint end -->

                </div>
            </div>
        </div>
    </div>
    <!-- banner content end -->
</div>
    <!-- banner end -->
    <div class="container">
        <div class="row">
            
                <div class="trm-page-sidebar col-lg-4 hidden-sm">
                    <!-- main card -->
                    <div class="trm-main-card-frame trm-sidebar">
    <div class="trm-main-card"> 
        <!-- card header -->
<div class="trm-mc-header">
    <div class="trm-avatar-frame trm-mb-20">
        <img alt="Avatar" class="trm-avatar" src="/img/avatar.jpg">
    </div>
    <h5 class="trm-name trm-mb-15">
        Adream
    </h5>
    
        <div class="trm-label">
            I`m
            <span class="trm-typed-text">
                <!-- Words for theme.user.typedText -->
            </span>
        </div>
    
</div>
<!-- card header end -->
        <!-- sidebar social -->

<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<div class="trm-social">
    
        <a href="https://github.com/chne-lun-hao" title="Github" rel="nofollow" target="_blank">
            <svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-github"></use>
</svg>
        </a>
    
        <a href="https://gitee.com/lunhao2023" title="Gitee" rel="nofollow" target="_blank">
            <svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-gitee"></use>
</svg>
        </a>
    
        <a href="/atom.xml" title="RSS" rel="nofollow" target="_blank">
            <svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-rss"></use>
</svg>
        </a>
    
</div>

<!-- sidebar social end -->
        <!-- info -->
<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<ul class="trm-table trm-mb-20">
    
        <li>
            <div class="trm-label">
                居住地:
            </div>
            <div class="trm-label trm-label-light">
                广州
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                城市:
            </div>
            <div class="trm-label trm-label-light">
                广州
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                年龄:
            </div>
            <div class="trm-label trm-label-light">
                21
            </div>
        </li>
    
</ul>
<!-- info end -->

        
    <div class="trm-divider trm-mb-40 trm-mt-40"></div>
    <!-- action button -->
    <div class="text-center">
        <a href="mailto:2085127827chen@gmail.com" class="trm-btn">
            联系我
            <svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-email"></use>
</svg>
        </a>
    </div>
    <!-- action button end -->

    </div>
</div>
                    <!-- main card end -->
                </div>
            
            <div class="trm-page-content col-lg-8">
                <div id="trm-content" class="trm-content">
                    <div class="trm-post-info row hidden-sm">
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <svg class="symbol-icon trm-icon" aria-hidden="true">
    <use xlink:href="#icon-rili"></use>
</svg><br>
            06/12
        </div>
    </div>
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <svg class="symbol-icon trm-icon" aria-hidden="true">
    <use xlink:href="#icon-shijian"></use>
</svg><br>
            23:20
        </div>
    </div>
    <div class="col-sm-4">
        <div id="post-author" class="trm-card trm-label trm-label-light text-center">
            <svg class="symbol-icon trm-icon" aria-hidden="true">
    <use xlink:href="#icon-yonghu"></use>
</svg><br>
            Adream
        </div>
    </div>
</div>
<div class="trm-card ">
    <article id="article-container" class="trm-publication">
    <h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><span id="more"></span>

<h2 id="1、决策树概述"><a href="#1、决策树概述" class="headerlink" title="1、决策树概述"></a>1、决策树概述</h2><p>决策树是属于有监督机器学习的一种，起源非常早，符合直觉并且非常直观，模仿人类做决策的过程，早期人工智能模型中有很多应用，现在更多的是使用基于决策树的一些集成学习的算法。这一章我们把决策树算法理解透彻了，非常有利于后面去学习集成学习。</p>
<h3 id="1-1、示例一"><a href="#1-1、示例一" class="headerlink" title="1.1、示例一"></a>1.1、示例一</h3><p>我们有如下数据：</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>拥有房产（是&#x2F;否）</th>
<th>婚姻[单身，已婚，离婚]</th>
<th>年收入（单位：千元）</th>
<th>无法偿还债务（是&#x2F;否）</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>是</td>
<td>单身</td>
<td>125</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>否</td>
<td>已婚</td>
<td>100</td>
<td>否</td>
</tr>
<tr>
<td>3</td>
<td>否</td>
<td>单身</td>
<td>70</td>
<td>否</td>
</tr>
<tr>
<td>4</td>
<td>是</td>
<td>已婚</td>
<td>120</td>
<td>否</td>
</tr>
<tr>
<td>5</td>
<td>否</td>
<td>离婚</td>
<td>95</td>
<td>是</td>
</tr>
<tr>
<td>6</td>
<td>否</td>
<td>已婚</td>
<td>60</td>
<td>否</td>
</tr>
<tr>
<td>7</td>
<td>是</td>
<td>离婚</td>
<td>220</td>
<td>否</td>
</tr>
<tr>
<td>8</td>
<td>否</td>
<td>单身</td>
<td>85</td>
<td>是</td>
</tr>
<tr>
<td>9</td>
<td>否</td>
<td>已婚</td>
<td>75</td>
<td>否</td>
</tr>
<tr>
<td>10</td>
<td>否</td>
<td>单身</td>
<td>90</td>
<td>是</td>
</tr>
</tbody></table>
<p>上表根据历史数据，记录已有的用户是否可以偿还债务，以及相关的信息。通过该数据，构建的决策树如下：</p>
<p><img src="/../img/post/DecisionTree-Classification/1-%E5%86%B3%E7%AD%96%E6%A0%91.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>比如新来一个用户：无房产，单身，年收入 55K，那么根据上面的决策树，可以预测他无法偿还债务（蓝色虚线路径）。从上面的决策树，还可以知道是否拥有房产可以很大的决定用户是否可以偿还债务，对借贷业务具有指导意义。</p>
<h3 id="1-2、示例二"><a href="#1-2、示例二" class="headerlink" title="1.2、示例二"></a>1.2、示例二</h3><p>女孩母亲要给她介绍对象，年龄是多少，母亲说 24。长得帅吗？挺帅的。收入高吗？中等收入。是公务员吗？母亲说，是的。女孩：好，我去见见。</p>
<p>根据<strong>实力</strong>构建决策树：</p>
<p><img src="/../img/post/DecisionTree-Classification/2-%E7%9B%B8%E4%BA%B2.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>问题：图片是二叉树吗？</p>
<p>决策树是标准的二叉树，每个节点只有两个分支~</p>
<ul>
<li>上面那棵树中，属性：绿色的节点（年龄、长相、收入、是否是公务员）<ul>
<li>属性叫做，data，数据，一般使用 X 表示</li>
<li>跟属性对应，目标值（橘色节点），一般使用 y 表示</li>
</ul>
</li>
<li>构建这棵树时，先后顺序，每个人，标准不同，树结构不同</li>
<li>计算机，构建树，标准一致的，构建出来的树，一致</li>
</ul>
<h3 id="1-3、决策树算法特点"><a href="#1-3、决策树算法特点" class="headerlink" title="1.3、决策树算法特点"></a>1.3、决策树算法特点</h3><ul>
<li>可以处理非线性的问题</li>
<li>可解释性强，没有方程系数 $\theta$</li>
<li>模型简单，模型预测效率高 if else</li>
</ul>
<h2 id="2、DecisionTreeClassifier-使用"><a href="#2、DecisionTreeClassifier-使用" class="headerlink" title="2、DecisionTreeClassifier 使用"></a>2、DecisionTreeClassifier 使用</h2><h3 id="2-1、算例介绍"><a href="#2-1、算例介绍" class="headerlink" title="2.1、算例介绍"></a>2.1、算例介绍</h3><p><img src="/img/post/DecisionTree-Classification/3-%E8%B4%A6%E5%8F%B7%E7%9C%9F%E4%BC%AA.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>其中 s、m 和 l 分别表示小、中和大。</p>
<p>账号是否真实跟属性：<strong>日志密度、好友密度、是否使用真实头像</strong>有关系~</p>
<h3 id="2-2、构建决策树并可视化"><a href="#2-2、构建决策树并可视化" class="headerlink" title="2.2、构建决策树并可视化"></a>2.2、构建决策树并可视化</h3><p>数据创建</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">y = np.array(<span class="built_in">list</span>(<span class="string">&#x27;NYYYYYNYYN&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line">X = pd.DataFrame(&#123;<span class="string">&#x27;日志密度&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;sslmlmmlms&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;好友密度&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;slmmmlsmss&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;真实头像&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;NYYYYNYYYY&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;真实用户&#x27;</span>:y&#125;)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>

<p>模型训练（报错，原因：数据类型是字符串）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">model = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line">model.fit(X,y)</span><br></pre></td></tr></table></figure>

<p>数据修改（map 函数，进行数据转换）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X[<span class="string">&#x27;日志密度&#x27;</span>] = X[<span class="string">&#x27;日志密度&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;s&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;m&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;l&#x27;</span>:<span class="number">2</span>&#125;)</span><br><span class="line">X[<span class="string">&#x27;好友密度&#x27;</span>] = X[<span class="string">&#x27;好友密度&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;s&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;m&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;l&#x27;</span>:<span class="number">2</span>&#125;)</span><br><span class="line">X[<span class="string">&#x27;真实头像&#x27;</span>] = X[<span class="string">&#x27;真实头像&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;N&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;Y&#x27;</span>:<span class="number">1</span>&#125;)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>

<p>模型训练可视化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 使用信息熵，作为分裂标准</span></span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;STKaiti&#x27;</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">16</span>))</span><br><span class="line">fn = X.columns</span><br><span class="line">_ = tree.plot_tree(model,filled = <span class="literal">True</span>,feature_names=fn)</span><br><span class="line">plt.savefig(<span class="string">&#x27;./iris.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure>

<img src="/img/post/DecisionTree-Classification/4-account.jpg" style="zoom:50%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/>

<p>数据可视化另一种方式，<a target="_blank" rel="noopener" href="https://blog.csdn.net/Soft_Po/article/details/118899477">安装教程</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line">dot_data = tree.export_graphviz(model, out_file=<span class="literal">None</span>,</span><br><span class="line">                            feature_names= X.columns,<span class="comment"># 特征名</span></span><br><span class="line">                            class_names=np.unique(y),<span class="comment"># 类别名</span></span><br><span class="line">                            filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                            rounded=<span class="literal">True</span>) <span class="comment"># 圆角</span></span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;Account&#x27;</span>,<span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>修改中文乱码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 打开 dot_data.dot，修改 fontname=&quot;支持的中文字体&quot;</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;Account&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./Account2&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(re.sub(<span class="string">r&#x27;fontname=helvetica&#x27;</span>, <span class="string">&#x27;fontname=Fangsong&#x27;</span>, f.read()))</span><br><span class="line">f.close()</span><br><span class="line"><span class="comment"># 从文件中加载，展示</span></span><br><span class="line">graph = graphviz.Source.from_file(<span class="string">&#x27;./Account2&#x27;</span>)</span><br><span class="line">graph.render(<span class="string">&#x27;Account&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/img/post/DecisionTree-Classification/5-Account.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="2-3、信息熵"><a href="#2-3、信息熵" class="headerlink" title="2.3、信息熵"></a>2.3、信息熵</h3><ul>
<li><p>构建好一颗树，数据变的有顺序了（构建前，一堆数据，杂乱无章；构建一颗，整整齐齐，顺序），用什么度量衡表示，数据是否有顺序：信息熵</p>
</li>
<li><p>物理学，热力学第二定律（熵），描述的是封闭系统的混乱程度</p>
<p><img src="/img/post/DecisionTree-Classification/6-entropy.gif" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
</li>
<li><p>信息熵，和物理学中熵类似的</p>
<img src="/img/post/DecisionTree-Classification/7-entropy.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/>
</li>
<li><p><code>&lt;font size = 5&gt;</code>$H(x) &#x3D; -\sum\limits_{i &#x3D; 1}^n p(x)log_2p(x)$<code>&lt;/font&gt;</code></p>
</li>
<li><p><code>&lt;font size = 5&gt;</code>$H(x) &#x3D; \sum\limits_{i &#x3D; 1}^n p(x)log_2\frac{1}{p(x)}$<code>&lt;/font&gt;</code></p>
</li>
</ul>
<h3 id="2-4、信息增益"><a href="#2-4、信息增益" class="headerlink" title="2.4、信息增益"></a>2.4、信息增益</h3><p>信息增益是知道了某个条件后，事件的不确定性下降的程度。写作 g(X,Y)。它的计算方式为熵减去条件熵，如下</p>
<p>$g(X,y) \rm &#x3D; H(Y) - H(Y|X)$</p>
<p>表示的是，知道了某个条件后，原来事件不确定性降低的幅度。</p>
<h3 id="2-5、手动计算实现决策树分类"><a href="#2-5、手动计算实现决策树分类" class="headerlink" title="2.5、手动计算实现决策树分类"></a>2.5、手动计算实现决策树分类</h3><p>数据整合</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X[<span class="string">&#x27;真实用户&#x27;</span>] = y</span><br><span class="line">X</span><br></pre></td></tr></table></figure>

<p>计算未划分信息熵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = X[<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">p = s.value_counts()/s.size</span><br><span class="line">(p * np.log2(<span class="number">1</span>/p)).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>

<p>按照日志密度进行划分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = X[<span class="string">&#x27;日志密度&#x27;</span>].unique()</span><br><span class="line">x.sort()</span><br><span class="line"><span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">    split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">    cond = X[<span class="string">&#x27;日志密度&#x27;</span>] &lt;= split</span><br><span class="line">    <span class="comment"># 概率分布</span></span><br><span class="line">    p = cond.value_counts()/cond.size</span><br><span class="line">    <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">    indexs =p.index</span><br><span class="line">    entropy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">        user = X[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">        p_user = user.value_counts()/user.size</span><br><span class="line">        entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">    <span class="built_in">print</span>(split,entropy)</span><br></pre></td></tr></table></figure>

<p>筛选最佳划分条件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">columns = [<span class="string">&#x27;日志密度&#x27;</span>,<span class="string">&#x27;好友密度&#x27;</span>,<span class="string">&#x27;真实头像&#x27;</span>]</span><br><span class="line">lower_entropy = <span class="number">1</span></span><br><span class="line">condition = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">    x = X[col].unique()</span><br><span class="line">    x.sort()</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line">    <span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">        split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">        cond = X[col] &lt;= split</span><br><span class="line">        <span class="comment"># 概率分布</span></span><br><span class="line">        p = cond.value_counts()/cond.size</span><br><span class="line">        <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">        indexs =p.index</span><br><span class="line">        entropy = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">            user = X[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">            p_user = user.value_counts()/user.size</span><br><span class="line">            entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">        <span class="built_in">print</span>(col,split,entropy)</span><br><span class="line">        <span class="keyword">if</span> entropy &lt; lower_entropy:</span><br><span class="line">            condition.clear()</span><br><span class="line">            lower_entropy = entropy</span><br><span class="line">            condition[col] = split</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最佳列分条件是：&#x27;</span>,condition)</span><br></pre></td></tr></table></figure>

<img src="/img/post/DecisionTree-Classification/8-Account.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/>

<p>进一步列分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cond = X[<span class="string">&#x27;好友密度&#x27;</span>] &lt; <span class="number">0.5</span></span><br><span class="line">X_ = X[cond]</span><br><span class="line">columns = [<span class="string">&#x27;日志密度&#x27;</span>,<span class="string">&#x27;真实头像&#x27;</span>]</span><br><span class="line">lower_entropy = <span class="number">1</span></span><br><span class="line">condition = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">    x = X_[col].unique()</span><br><span class="line">    x.sort()</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line">    <span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">        split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">        cond = X_[col] &lt;= split</span><br><span class="line">        <span class="comment"># 概率分布</span></span><br><span class="line">        p = cond.value_counts()/cond.size</span><br><span class="line">        <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">        indexs =p.index</span><br><span class="line">        entropy = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">            user = X_[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">            p_user = user.value_counts()/user.size</span><br><span class="line">            entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">        <span class="built_in">print</span>(col,split,entropy)</span><br><span class="line">        <span class="keyword">if</span> entropy &lt; lower_entropy:</span><br><span class="line">            condition.clear()</span><br><span class="line">            lower_entropy = entropy</span><br><span class="line">            condition[col] = split</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最佳列分条件是：&#x27;</span>,condition)</span><br></pre></td></tr></table></figure>

<img src="/img/post/DecisionTree-Classification/9-Account.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/>

<h2 id="3、决策树分裂指标"><a href="#3、决策树分裂指标" class="headerlink" title="3、决策树分裂指标"></a>3、决策树分裂指标</h2><p>常用的分裂条件时：</p>
<ul>
<li>信息增益</li>
<li>Gini 系数</li>
<li>信息增益率</li>
<li>MSE（回归问题）</li>
</ul>
<h3 id="3-1、信息熵（ID3）"><a href="#3-1、信息熵（ID3）" class="headerlink" title="3.1、信息熵（ID3）"></a>3.1、信息熵（ID3）</h3><p>在信息论里熵叫作信息量，即熵是对不确定性的度量。从控制论的角度来看，应叫不确定性。信息论的创始人香农在其著作《通信的数学理论》中提出了建立在概率统计模型上的信息度量。他把信息定义为“用来消除不确定性的东西”。在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。还是举例说明，假设 Dammi 在买衣服的时候有颜色，尺寸，款式以及设计年份四种要求，而 Sara 只有颜色和尺寸的要求，那么在购买衣服这个层面上 Dammi 由于选择更多因而不确定性因素更大，最终 Dammi 所获取的信息更多，也就是熵更大。所以信息量&#x3D;熵&#x3D;不确定性，通俗易懂。在叙述决策树时我们用熵表示不纯度（Impurity）。</p>
<p>对应公式如下：</p>
<p><font size = 5>$H(x) &#x3D; -\sum\limits_{i &#x3D; 1}^n p(x)log_2p(x)$<code>&lt;/font&gt;</code></p>
<p>熵的变化越大，说明划分越纯，信息增益越大~</p>
<h3 id="3-2、Gini-系数（CART）"><a href="#3-2、Gini-系数（CART）" class="headerlink" title="3.2、Gini 系数（CART）"></a>3.2、Gini 系数（CART）</h3><p>基尼系数是指国际上通用的、用以衡量一个国家或地区居民收入差距的常用指标。</p>
<p>基尼系数最大为“1”，最小等于“0”。基尼系数越接近 0 表明收入分配越是趋向平等。国际惯例把 0.2 以下视为收入绝对平均，0.2-0.3 视为收入比较平均；0.3-0.4 视为收入相对合理；0.4-0.5 视为收入差距较大，当基尼系数达到 0.5 以上时，则表示收入悬殊。</p>
<p>基尼系数的实际数值只能介于 0 ～ 1 之间，基尼系数越小收入分配越平均，基尼系数越大收入分配越不平均。国际上通常把 0.4 作为贫富差距的警戒线，大于这一数值容易出现社会动荡。</p>
<p>Gini 系数越小，代表集合中的数据越纯，所有我们可以计算分裂前的值在按照某个维度对数据集进行划分，然后可以去计算多个节点的 Gini 系数。</p>
<p>对应公式如下：</p>
<p><font size = 5>$\rm gini &#x3D; \sum\limits_{i &#x3D; 1}^np_i(1 - p_i)$<code>&lt;/font&gt;</code></p>
<p>在对数据进行分类是 gini 系数的变化越大，说明划分越纯，效果越好~</p>
<h3 id="3-3、信息增益率"><a href="#3-3、信息增益率" class="headerlink" title="3.3、信息增益率"></a>3.3、信息增益率</h3><p>大学期末的数学考试只有单选题。对于一个完全没有学习过的学生。该如何过关呢？</p>
<p>4 个选项是正确选项的概率都是 1&#x2F;4。那么单项选择题的答案的熵就是：</p>
<p>$H(Y) \rm &#x3D; -0.25log_2(0.25) \times 4 &#x3D; 2bit$</p>
<p>在学霸圈做单项选择题有一个秘籍：三长一短选最短，三短一长选最长。姑且假设学霸的秘籍一般都是正确的。</p>
<p>如果在某场考试中，有 10%的单项选题是三长一短，10%的选题是三短一长。计算该考试单项选题的关于长短题的条件熵：</p>
<table>
<thead>
<tr>
<th align="center">题目类型</th>
<th align="center">答案概率</th>
<th align="center">题目概率</th>
</tr>
</thead>
<tbody><tr>
<td align="center">三长一短</td>
<td align="center">(1,0,0,0)熵是 0，结果确定！</td>
<td align="center">10%</td>
</tr>
<tr>
<td align="center">三短一长</td>
<td align="center">(1,0,0,0)熵是 0</td>
<td align="center">10%</td>
</tr>
<tr>
<td align="center">一样长</td>
<td align="center">(0.25,0.25,0.25,0.25)熵是 2</td>
<td align="center">80%</td>
</tr>
</tbody></table>
<p>计算条件熵（条件就是：题目不同类型）</p>
<p>$H(Y|X) \rm &#x3D; 0.1\times 0 + 0.1 \times 0 + 0.8 \times 2 &#x3D; 1.6bit$</p>
<p>那么信息增益是：</p>
<p>$g(X,Y) \rm &#x3D; H(Y) - H(Y|X) &#x3D; 2 - 1.6 &#x3D; 0.4bit$</p>
<p><strong>信息增益率</strong>在信息增益的基础上增加了惩罚项，惩罚项是特征的固有值。</p>
<p>写作 gr(X,Y)。定义为信息增益除以特征的固有值，如下：</p>
<p><font size = 5>$gr(X,Y) &#x3D; \frac{g(X,Y)}{Info(X)}$<code>&lt;/font&gt;</code></p>
<p><font size = 5>$Info(X) &#x3D; -\sum\limits_{v \in values(X)}\frac{num(v)}{num(X)}log_2{\frac{num(v)}{num(X)}}$<code>&lt;/font&gt;</code></p>
<p>计算上面单选题题目长短案例的信息增益率：</p>
<p><font size = 5>$Info(X) &#x3D; -(0.1 \times log_20.1 \times 2 + 0.8 \times log_20.8) &#x3D; 0.92$<code>&lt;/font&gt;</code></p>
<p><font size = 5>$gr(X,Y) &#x3D; \frac{g(X,Y)}{Info(X)} &#x3D; \frac{0.4}{0.92} &#x3D; 0.43$<code>&lt;/font&gt;</code></p>
<p>对于取值多的属性，尤其一些连续型数值，这个单独的属性就可以划分所有的样本，使得所有分支下的样本集合都是“纯的”（最极端的情况是每个叶子节点只有一个样本）。<br>一个属性的信息增益越大，表明属性对样本的熵减少的能力更强，这个属性使得数据由不确定性变成确定性的能力越强。<br>所以如果是取值更多的属性，更容易使得数据更“纯”（尤其是连续型数值），其信息增益更大，决策树会首先挑选这个属性作为树的顶点。结果训练出来的形状是一棵庞大且深度很浅的树，这样的划分是极为不合理的。</p>
<p><img src="/img/post/DecisionTree-Classification/10-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>C4.5 使用了信息增益率，在信息增益的基础上除了一项 split information,来惩罚值更多的属性。从而使划分更加合理！</p>
<h3 id="3-4、MSE"><a href="#3-4、MSE" class="headerlink" title="3.4、MSE"></a>3.4、MSE</h3><p>用于回归树，后面章节具体介绍</p>
<p><img src="/img/post/DecisionTree-Classification/11-%E5%9B%9E%E5%BD%92%E6%A0%91.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h2 id="4、鸢尾花分类代码实战"><a href="#4、鸢尾花分类代码实战" class="headerlink" title="4、鸢尾花分类代码实战"></a>4、鸢尾花分类代码实战</h2><h3 id="4-1、决策树分类鸢尾花数据集"><a href="#4-1、决策树分类鸢尾花数据集" class="headerlink" title="4.1、决策树分类鸢尾花数据集"></a>4.1、决策树分类鸢尾花数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X,y = datasets.load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth调整树深度：剪枝操作</span></span><br><span class="line"><span class="comment"># max_depth默认，深度最大，延伸到将数据完全划分开为止。</span></span><br><span class="line">model = DecisionTreeClassifier(max_depth=<span class="literal">None</span>,criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X_train,y_train)</span><br><span class="line">y_ = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;算法预测是：&#x27;</span>,y_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率是：&#x27;</span>,model.score(X_test,y_test))</span><br><span class="line"><span class="comment"># 决策树提供了predict_proba这个方法，发现这个方法，返回值要么是0，要么是1</span></span><br><span class="line">model.predict_proba(X_test)</span><br></pre></td></tr></table></figure>

<h3 id="4-2、决策树可视化"><a href="#4-2、决策树可视化" class="headerlink" title="4.2、决策树可视化"></a>4.2、决策树可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="comment"># 导出数据</span></span><br><span class="line">dot_data = tree.export_graphviz(model,feature_names=fn,</span><br><span class="line">                     class_names=iris[<span class="string">&#x27;target_names&#x27;</span>],<span class="comment"># 类别名</span></span><br><span class="line">                     filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                     rounded=<span class="literal">True</span>,)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;iris&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/img/post/DecisionTree-Classification/12-iris.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="4-3、决策树剪枝"><a href="#4-3、决策树剪枝" class="headerlink" title="4.3、决策树剪枝"></a>4.3、决策树剪枝</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置图片的尺寸</span></span><br><span class="line"><span class="comment"># 鸢尾花4个属性</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">fn = iris[<span class="string">&#x27;feature_names&#x27;</span>]</span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth调整树深度：剪枝操作</span></span><br><span class="line"><span class="comment"># max_depth默认，深度最大，延伸到将数据完全划分开为止。</span></span><br><span class="line"><span class="comment"># min_impurity_decrease（节点划分最小不纯度）如果某节点的不纯度(基尼系数，信息增益，均方差)小于这个阈值，则该节点不再生成子节点</span></span><br><span class="line"><span class="comment"># max_depth（决策树最大深度）；min_samples_split（内部节点再划分所需最小样本数）</span></span><br><span class="line"><span class="comment"># min_samples_leaf（叶子节点最少样本数）；max_leaf_nodes（最大叶子节点数）</span></span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>,min_impurity_decrease=<span class="number">0.2</span>)</span><br><span class="line">model.fit(X_train,y_train)</span><br><span class="line">y_ = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;算法预测是：&#x27;</span>,y_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率是：&#x27;</span>,model.score(X_test,y_test))</span><br><span class="line"><span class="comment"># 导出数据</span></span><br><span class="line">dot_data = tree.export_graphviz(model,feature_names=fn,</span><br><span class="line">                     class_names=iris[<span class="string">&#x27;target_names&#x27;</span>],<span class="comment"># 类别名</span></span><br><span class="line">                     filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                     rounded=<span class="literal">True</span>,)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;./13-iris-裁剪&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/img/post/DecisionTree-Classification/13-iris-%E5%89%AA%E6%9E%9D.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="4-4、选择合适的超参数并可视化"><a href="#4-4、选择合适的超参数并可视化" class="headerlink" title="4.4、选择合适的超参数并可视化"></a>4.4、选择合适的超参数并可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X,y = datasets.load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line">depth = np.arange(<span class="number">1</span>,<span class="number">16</span>)</span><br><span class="line">err = []</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> depth:</span><br><span class="line">    model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>,max_depth=d)</span><br><span class="line">    model.fit(X_train,y_train)</span><br><span class="line">    score = model.score(X_test,y_test)</span><br><span class="line">    err.append(<span class="number">1</span> - score)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;错误率为%0.3f%%&#x27;</span> % (<span class="number">100</span> * (<span class="number">1</span> - score)))</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;STKaiti&#x27;</span></span><br><span class="line">plt.plot(depth,err,<span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;决策树深度&#x27;</span>,fontsize = <span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;错误率&#x27;</span>,fontsize = <span class="number">18</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;筛选合适决策树深度&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.savefig(<span class="string">&#x27;./14-筛选超参数.png&#x27;</span>,dpi = <span class="number">200</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/img/post/DecisionTree-Classification/14-%E7%AD%9B%E9%80%89%E8%B6%85%E5%8F%82%E6%95%B0.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="4-5、决策树副产物"><a href="#4-5、决策树副产物" class="headerlink" title="4.5、决策树副产物"></a>4.5、决策树副产物</h3><ul>
<li><p>特征重要性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure></li>
</ul>

</article>
    
    

<ul class="trm-post-copyright">
    <li class="trm-post-copyright-author">
        <strong>本文作者：</strong>
        Adream
    </li>
    <li class="trm-post-copyright-link">
        <strong>本文链接：</strong>
        <a id="original-link" href="https://www.adream.icu/2021/06/12/DecisionTree-Classification/" title="决策树分类算法原理">https://www.adream.icu/2021/06/12/DecisionTree-Classification/</a>
    </li>
    <li class="trm-post-copyright-license">
        <strong>版权声明：</strong>
        本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 ">CC BY-NC-SA 4.0</a> 许可协议。
    </li>
</ul>


</div>
<div class="trm-post-next-prev row">
    <div class="col-lg-12">
        <!-- title -->
        <h5 class="trm-title-with-divider">
            其他文章
            <span data-number="02"></span>
        </h5>
    </div>
    
        <div class="col-lg-6">
    <div class="trm-older-publications-card trm-scroll-animation trm-active-el">
        <div class="trm-older-publication">
            
            <a class="trm-op-top trm-anima-link" href="/2022/09/21/hello-world/">
                <span class="trm-op-cover">
                    <img alt="cover" class="no-fancybox" src="https://hexo-theme-async.imalun.com/imgs/demo2.png">
                </span>
                <h6 class="trm-op-title">Hello Theme Async</h6>
            </a>
            <div class="trm-divider trm-mb-15 trm-mt-20"></div>
            <ul class="trm-card-data trm-label">
                <li>22/09/21</li>
                <li>15:08</li>
                <li>未分类</li>
            </ul>
        </div>
    </div>
</div>
    
    
</div>

    



                    <div class="trm-divider footer-divider"></div>

                    <!-- footer -->
                    <footer class="trm-scroll-animation">

    

    
        <div class="trm-footer-item">
            <span>© 2021- 2024</span>
            <span class="footer-separator"data-separator=" · "></span>
            <span class="trm-accent-color">Adream</span>
        </div>
    

    
        <div class="trm-footer-item">
            <span>
                由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v7.1.1
            </span>
            <span class="footer-separator" data-separator=" | "></span>
            <span> 
                主题 - 
                <a rel="noopener" href='https://github.com/MaLuns/hexo-theme-async' target='_blank'>Async</a>
                v2.1.10
            </span>
        </div>
      

    
        <div class="trm-footer-item blog-run-long"></div>
     

     
</footer>
                    <!-- footer end -->

                </div>
            </div>
        </div>
    </div>
</div>
            <!-- body end -->

            

    <div id="post-toc" class="trm-post-toc">
      <div class="trm-post-toc-header">
        目录导航
				<span id="post-toc-top">
					置顶
				</span>
      </div>
      <div class="trm-post-toc-content">
        <ol class="trm-toc"><li class="trm-toc-item trm-toc-level-1" title="决策树"><a rel="nofollow" class="trm-toc-link" href="#决策树"><span class="trm-toc-text">决策树</span></a><ol class="trm-toc-child"><li class="trm-toc-item trm-toc-level-2" title="1、决策树概述"><a rel="nofollow" class="trm-toc-link" href="#1、决策树概述"><span class="trm-toc-text">1、决策树概述</span></a><ol class="trm-toc-child"><li class="trm-toc-item trm-toc-level-3" title="1.1、示例一"><a rel="nofollow" class="trm-toc-link" href="#1-1、示例一"><span class="trm-toc-text">1.1、示例一</span></a></li><li class="trm-toc-item trm-toc-level-3" title="1.2、示例二"><a rel="nofollow" class="trm-toc-link" href="#1-2、示例二"><span class="trm-toc-text">1.2、示例二</span></a></li><li class="trm-toc-item trm-toc-level-3" title="1.3、决策树算法特点"><a rel="nofollow" class="trm-toc-link" href="#1-3、决策树算法特点"><span class="trm-toc-text">1.3、决策树算法特点</span></a></li></ol></li><li class="trm-toc-item trm-toc-level-2" title="2、DecisionTreeClassifier 使用"><a rel="nofollow" class="trm-toc-link" href="#2、DecisionTreeClassifier-使用"><span class="trm-toc-text">2、DecisionTreeClassifier 使用</span></a><ol class="trm-toc-child"><li class="trm-toc-item trm-toc-level-3" title="2.1、算例介绍"><a rel="nofollow" class="trm-toc-link" href="#2-1、算例介绍"><span class="trm-toc-text">2.1、算例介绍</span></a></li><li class="trm-toc-item trm-toc-level-3" title="2.2、构建决策树并可视化"><a rel="nofollow" class="trm-toc-link" href="#2-2、构建决策树并可视化"><span class="trm-toc-text">2.2、构建决策树并可视化</span></a></li><li class="trm-toc-item trm-toc-level-3" title="2.3、信息熵"><a rel="nofollow" class="trm-toc-link" href="#2-3、信息熵"><span class="trm-toc-text">2.3、信息熵</span></a></li><li class="trm-toc-item trm-toc-level-3" title="2.4、信息增益"><a rel="nofollow" class="trm-toc-link" href="#2-4、信息增益"><span class="trm-toc-text">2.4、信息增益</span></a></li><li class="trm-toc-item trm-toc-level-3" title="2.5、手动计算实现决策树分类"><a rel="nofollow" class="trm-toc-link" href="#2-5、手动计算实现决策树分类"><span class="trm-toc-text">2.5、手动计算实现决策树分类</span></a></li></ol></li><li class="trm-toc-item trm-toc-level-2" title="3、决策树分裂指标"><a rel="nofollow" class="trm-toc-link" href="#3、决策树分裂指标"><span class="trm-toc-text">3、决策树分裂指标</span></a><ol class="trm-toc-child"><li class="trm-toc-item trm-toc-level-3" title="3.1、信息熵（ID3）"><a rel="nofollow" class="trm-toc-link" href="#3-1、信息熵（ID3）"><span class="trm-toc-text">3.1、信息熵（ID3）</span></a></li><li class="trm-toc-item trm-toc-level-3" title="3.2、Gini 系数（CART）"><a rel="nofollow" class="trm-toc-link" href="#3-2、Gini-系数（CART）"><span class="trm-toc-text">3.2、Gini 系数（CART）</span></a></li><li class="trm-toc-item trm-toc-level-3" title="3.3、信息增益率"><a rel="nofollow" class="trm-toc-link" href="#3-3、信息增益率"><span class="trm-toc-text">3.3、信息增益率</span></a></li><li class="trm-toc-item trm-toc-level-3" title="3.4、MSE"><a rel="nofollow" class="trm-toc-link" href="#3-4、MSE"><span class="trm-toc-text">3.4、MSE</span></a></li></ol></li><li class="trm-toc-item trm-toc-level-2" title="4、鸢尾花分类代码实战"><a rel="nofollow" class="trm-toc-link" href="#4、鸢尾花分类代码实战"><span class="trm-toc-text">4、鸢尾花分类代码实战</span></a><ol class="trm-toc-child"><li class="trm-toc-item trm-toc-level-3" title="4.1、决策树分类鸢尾花数据集"><a rel="nofollow" class="trm-toc-link" href="#4-1、决策树分类鸢尾花数据集"><span class="trm-toc-text">4.1、决策树分类鸢尾花数据集</span></a></li><li class="trm-toc-item trm-toc-level-3" title="4.2、决策树可视化"><a rel="nofollow" class="trm-toc-link" href="#4-2、决策树可视化"><span class="trm-toc-text">4.2、决策树可视化</span></a></li><li class="trm-toc-item trm-toc-level-3" title="4.3、决策树剪枝"><a rel="nofollow" class="trm-toc-link" href="#4-3、决策树剪枝"><span class="trm-toc-text">4.3、决策树剪枝</span></a></li><li class="trm-toc-item trm-toc-level-3" title="4.4、选择合适的超参数并可视化"><a rel="nofollow" class="trm-toc-link" href="#4-4、选择合适的超参数并可视化"><span class="trm-toc-text">4.4、选择合适的超参数并可视化</span></a></li><li class="trm-toc-item trm-toc-level-3" title="4.5、决策树副产物"><a rel="nofollow" class="trm-toc-link" href="#4-5、决策树副产物"><span class="trm-toc-text">4.5、决策树副产物</span></a></li></ol></li></ol></li></ol>
      </div>
    </div>

            <div class="trm-fixed-container"><div class="trm-fixed-btn post-toc-btn" data-title="目录"><svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-liebiao"></use>
</svg></div><div class="trm-fixed-btn" id="trm-search-btn" data-title="查询"><svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-chaxun"></use>
</svg></div><div class="trm-fixed-btn" data-title="切换主题模式" onclick="asyncFun.switchThemeMode(document.documentElement.classList.contains('dark')?'style-light':'style-dark')"><i class="fas fa-sun"></i></div><div class="trm-fixed-btn" data-title="阅读模式" onclick="asyncFun.switchReadMode()"><svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-yuedu"></use>
</svg></div><div class="trm-fixed-btn hidden-md" data-title="单栏和双栏切换" onclick="asyncFun.switchSingleColumn()"><svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-arrows-h"></use>
</svg></div><div class="trm-fixed-btn" id="trm-back-top" data-title="回到顶部"><svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-backtop"></use>
</svg></div></div>
        </div>
      </div>
      <!-- scroll container end -->
  </div>
  <!-- app wrapper end -->

  
    <div class="trm-search-popup">
        <div class="trm-search-wrapper">
            <div class="form trm-search-form">
                <div class="trm-search-input-icon">
                    <svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-chaxun"></use>
</svg>
                </div>
                <input class="trm-search-input" type="text" placeholder="搜索文章...">
                <div class="trm-search-btn-close">
                    <svg class="symbol-icon " aria-hidden="true">
    <use xlink:href="#icon-guanbi"></use>
</svg>
                </div>
            </div>
            <div class="trm-search-result-container">
                <div class="trm-search-empty">
                    请输入关键词进行搜索
                </div>
            </div>
            <div class="trm-search-footer">
                <div class="trm-search-stats"></div>
                <ul class="trm-search-commands">
                    <li>
                        <kbd class="command-palette-commands-key">
                            <svg width="15" height="15" aria-label="Escape key" role="img">
                                <g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"
                                    stroke-width="1.2">
                                    <path
                                        d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993 0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016.8634 0 1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5c.032.5663-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864 0 1.6425 1.031 1.5443 2.2492h-2.956">
                                    </path>
                                </g>
                            </svg>
                        </kbd>
                        <span class="command-palette-Label">to close</span>
                    </li>
                </ul>
            </div>
        </div>
    </div>

  <!-- Plugin -->




    
<script src="https://npm.elemecdn.com/swup@2.0.19/dist/swup.min.js"></script>

    
<script src="https://npm.elemecdn.com/@fancyapps/ui@4.0/dist/fancybox.umd.js"></script>

    

    
        <script src="/js/plugins/typing.js?v=2.1.10"></script>
    

    
        
<script src="https://npm.elemecdn.com/hexo-generator-searchdb@1.4.0/dist/search.js"></script>

        <script src="/js/plugins/local_search.js?v=2.1.10"></script>
    

    <!-- 数学公式 -->
    
        
<script src="https://npm.elemecdn.com/katex@latest/dist/katex.min.js" data-swup-reload-script></script>

        
            
<script src="https://npm.elemecdn.com/katex@latest/dist/contrib/copy-tex.min.js" data-swup-reload-script></script>

        
        
<script src="https://npm.elemecdn.com/katex@latest/dist/contrib/auto-render.min.js" data-swup-reload-script></script>

        <script data-swup-reload-script>
              window.renderMathInElement(document.body, {
                delimiters: [
                    { left: '$$', right: '$$', display: true },
                    { left: '$', right: '$', display: false },
                    { left: '\\(', right: '\\)', display: false },
                    { left: '\\[', right: '\\]', display: true },
                ],
                ...{},
            })
        </script>
    

    <!-- 评论插件 -->
    
        

        
    



<!-- CDN -->


    

    

    




    <!-- Service Worker -->
    
    <!-- baidu push -->
    


<script id="async-script" src="/js/main.js?v=2.1.10"></script>

</body>

</html>