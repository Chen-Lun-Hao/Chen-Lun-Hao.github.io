<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>决策树分类算法原理</title>
    <url>/2021/06/12/DecisionTree-Classification/</url>
    <content><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><span id="more"></span>

<h2 id="1、决策树概述"><a href="#1、决策树概述" class="headerlink" title="1、决策树概述"></a>1、决策树概述</h2><p>决策树是属于有监督机器学习的一种，起源非常早，符合直觉并且非常直观，模仿人类做决策的过程，早期人工智能模型中有很多应用，现在更多的是使用基于决策树的一些集成学习的算法。这一章我们把决策树算法理解透彻了，非常有利于后面去学习集成学习。</p>
<h3 id="1-1、示例一"><a href="#1-1、示例一" class="headerlink" title="1.1、示例一"></a>1.1、示例一</h3><p>我们有如下数据：</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>拥有房产（是&#x2F;否）</th>
<th>婚姻[单身，已婚，离婚]</th>
<th>年收入（单位：千元）</th>
<th>无法偿还债务（是&#x2F;否）</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>是</td>
<td>单身</td>
<td>125</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>否</td>
<td>已婚</td>
<td>100</td>
<td>否</td>
</tr>
<tr>
<td>3</td>
<td>否</td>
<td>单身</td>
<td>70</td>
<td>否</td>
</tr>
<tr>
<td>4</td>
<td>是</td>
<td>已婚</td>
<td>120</td>
<td>否</td>
</tr>
<tr>
<td>5</td>
<td>否</td>
<td>离婚</td>
<td>95</td>
<td>是</td>
</tr>
<tr>
<td>6</td>
<td>否</td>
<td>已婚</td>
<td>60</td>
<td>否</td>
</tr>
<tr>
<td>7</td>
<td>是</td>
<td>离婚</td>
<td>220</td>
<td>否</td>
</tr>
<tr>
<td>8</td>
<td>否</td>
<td>单身</td>
<td>85</td>
<td>是</td>
</tr>
<tr>
<td>9</td>
<td>否</td>
<td>已婚</td>
<td>75</td>
<td>否</td>
</tr>
<tr>
<td>10</td>
<td>否</td>
<td>单身</td>
<td>90</td>
<td>是</td>
</tr>
</tbody></table>
<p>上表根据历史数据，记录已有的用户是否可以偿还债务，以及相关的信息。通过该数据，构建的决策树如下：</p>
<p><img src="/../img/post/DecisionTree-Classification/1-%E5%86%B3%E7%AD%96%E6%A0%91.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>比如新来一个用户：无房产，单身，年收入 55K，那么根据上面的决策树，可以预测他无法偿还债务（蓝色虚线路径）。从上面的决策树，还可以知道是否拥有房产可以很大的决定用户是否可以偿还债务，对借贷业务具有指导意义。</p>
<h3 id="1-2、示例二"><a href="#1-2、示例二" class="headerlink" title="1.2、示例二"></a>1.2、示例二</h3><p>女孩母亲要给她介绍对象，年龄是多少，母亲说 24。长得帅吗？挺帅的。收入高吗？中等收入。是公务员吗？母亲说，是的。女孩：好，我去见见。</p>
<p>根据<strong>实力</strong>构建决策树：</p>
<p><img src="/../img/post/DecisionTree-Classification/2-%E7%9B%B8%E4%BA%B2.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>问题：图片是二叉树吗？</p>
<p>决策树是标准的二叉树，每个节点只有两个分支~</p>
<ul>
<li>上面那棵树中，属性：绿色的节点（年龄、长相、收入、是否是公务员）<ul>
<li>属性叫做，data，数据，一般使用 X 表示</li>
<li>跟属性对应，目标值（橘色节点），一般使用 y 表示</li>
</ul>
</li>
<li>构建这棵树时，先后顺序，每个人，标准不同，树结构不同</li>
<li>计算机，构建树，标准一致的，构建出来的树，一致</li>
</ul>
<h3 id="1-3、决策树算法特点"><a href="#1-3、决策树算法特点" class="headerlink" title="1.3、决策树算法特点"></a>1.3、决策树算法特点</h3><ul>
<li>可以处理非线性的问题</li>
<li>可解释性强，没有方程系数 $\theta$</li>
<li>模型简单，模型预测效率高 if else</li>
</ul>
<h2 id="2、DecisionTreeClassifier-使用"><a href="#2、DecisionTreeClassifier-使用" class="headerlink" title="2、DecisionTreeClassifier 使用"></a>2、DecisionTreeClassifier 使用</h2><h3 id="2-1、算例介绍"><a href="#2-1、算例介绍" class="headerlink" title="2.1、算例介绍"></a>2.1、算例介绍</h3><p><img src="/img/post/DecisionTree-Classification/3-%E8%B4%A6%E5%8F%B7%E7%9C%9F%E4%BC%AA.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>其中 s、m 和 l 分别表示小、中和大。</p>
<p>账号是否真实跟属性：<strong>日志密度、好友密度、是否使用真实头像</strong>有关系~</p>
<h3 id="2-2、构建决策树并可视化"><a href="#2-2、构建决策树并可视化" class="headerlink" title="2.2、构建决策树并可视化"></a>2.2、构建决策树并可视化</h3><p>数据创建</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">y = np.array(<span class="built_in">list</span>(<span class="string">&#x27;NYYYYYNYYN&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line">X = pd.DataFrame(&#123;<span class="string">&#x27;日志密度&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;sslmlmmlms&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;好友密度&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;slmmmlsmss&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;真实头像&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;NYYYYNYYYY&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;真实用户&#x27;</span>:y&#125;)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>

<p>模型训练（报错，原因：数据类型是字符串）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">model = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line">model.fit(X,y)</span><br></pre></td></tr></table></figure>

<p>数据修改（map 函数，进行数据转换）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X[<span class="string">&#x27;日志密度&#x27;</span>] = X[<span class="string">&#x27;日志密度&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;s&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;m&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;l&#x27;</span>:<span class="number">2</span>&#125;)</span><br><span class="line">X[<span class="string">&#x27;好友密度&#x27;</span>] = X[<span class="string">&#x27;好友密度&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;s&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;m&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;l&#x27;</span>:<span class="number">2</span>&#125;)</span><br><span class="line">X[<span class="string">&#x27;真实头像&#x27;</span>] = X[<span class="string">&#x27;真实头像&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;N&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;Y&#x27;</span>:<span class="number">1</span>&#125;)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>

<p>模型训练可视化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 使用信息熵，作为分裂标准</span></span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;STKaiti&#x27;</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">16</span>))</span><br><span class="line">fn = X.columns</span><br><span class="line">_ = tree.plot_tree(model,filled = <span class="literal">True</span>,feature_names=fn)</span><br><span class="line">plt.savefig(<span class="string">&#x27;./iris.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure>

<img src="/img/post/DecisionTree-Classification/4-account.jpg" style="zoom:50%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/>

<p>数据可视化另一种方式，<a href="https://blog.csdn.net/Soft_Po/article/details/118899477">安装教程</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line">dot_data = tree.export_graphviz(model, out_file=<span class="literal">None</span>,</span><br><span class="line">                            feature_names= X.columns,<span class="comment"># 特征名</span></span><br><span class="line">                            class_names=np.unique(y),<span class="comment"># 类别名</span></span><br><span class="line">                            filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                            rounded=<span class="literal">True</span>) <span class="comment"># 圆角</span></span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;Account&#x27;</span>,<span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>修改中文乱码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 打开 dot_data.dot，修改 fontname=&quot;支持的中文字体&quot;</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;Account&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./Account2&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(re.sub(<span class="string">r&#x27;fontname=helvetica&#x27;</span>, <span class="string">&#x27;fontname=Fangsong&#x27;</span>, f.read()))</span><br><span class="line">f.close()</span><br><span class="line"><span class="comment"># 从文件中加载，展示</span></span><br><span class="line">graph = graphviz.Source.from_file(<span class="string">&#x27;./Account2&#x27;</span>)</span><br><span class="line">graph.render(<span class="string">&#x27;Account&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/img/post/DecisionTree-Classification/5-Account.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="2-3、信息熵"><a href="#2-3、信息熵" class="headerlink" title="2.3、信息熵"></a>2.3、信息熵</h3><ul>
<li><p>构建好一颗树，数据变的有顺序了（构建前，一堆数据，杂乱无章；构建一颗，整整齐齐，顺序），用什么度量衡表示，数据是否有顺序：信息熵</p>
</li>
<li><p>物理学，热力学第二定律（熵），描述的是封闭系统的混乱程度</p>
<p><img src="/img/post/DecisionTree-Classification/6-entropy.gif" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
</li>
<li><p>信息熵，和物理学中熵类似的</p>
<img src="/img/post/DecisionTree-Classification/7-entropy.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/>

<p><font size = 5>$H(x) &#x3D; -\sum\limits_{i &#x3D; 1}^n p(x)log_2p(x)$</font></p>
</li>
<li><p><font size = 5>$H(x) &#x3D; \sum\limits_{i &#x3D; 1}^n p(x)log_2\frac{1}{p(x)}$</font></p>
</li>
</ul>
<h3 id="2-4、信息增益"><a href="#2-4、信息增益" class="headerlink" title="2.4、信息增益"></a>2.4、信息增益</h3><p>信息增益是知道了某个条件后，事件的不确定性下降的程度。写作 g(X,Y)。它的计算方式为熵减去条件熵，如下</p>
<p>$g(X,y) \rm &#x3D; H(Y) - H(Y|X)$</p>
<p>表示的是，知道了某个条件后，原来事件不确定性降低的幅度。</p>
<h3 id="2-5、手动计算实现决策树分类"><a href="#2-5、手动计算实现决策树分类" class="headerlink" title="2.5、手动计算实现决策树分类"></a>2.5、手动计算实现决策树分类</h3><p>数据整合</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X[<span class="string">&#x27;真实用户&#x27;</span>] = y</span><br><span class="line">X</span><br></pre></td></tr></table></figure>

<p>计算未划分信息熵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = X[<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">p = s.value_counts()/s.size</span><br><span class="line">(p * np.log2(<span class="number">1</span>/p)).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>

<p>按照日志密度进行划分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = X[<span class="string">&#x27;日志密度&#x27;</span>].unique()</span><br><span class="line">x.sort()</span><br><span class="line"><span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">    split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">    cond = X[<span class="string">&#x27;日志密度&#x27;</span>] &lt;= split</span><br><span class="line">    <span class="comment"># 概率分布</span></span><br><span class="line">    p = cond.value_counts()/cond.size</span><br><span class="line">    <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">    indexs =p.index</span><br><span class="line">    entropy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">        user = X[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">        p_user = user.value_counts()/user.size</span><br><span class="line">        entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">    <span class="built_in">print</span>(split,entropy)</span><br></pre></td></tr></table></figure>

<p>筛选最佳划分条件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">columns = [<span class="string">&#x27;日志密度&#x27;</span>,<span class="string">&#x27;好友密度&#x27;</span>,<span class="string">&#x27;真实头像&#x27;</span>]</span><br><span class="line">lower_entropy = <span class="number">1</span></span><br><span class="line">condition = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">    x = X[col].unique()</span><br><span class="line">    x.sort()</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line">    <span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">        split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">        cond = X[col] &lt;= split</span><br><span class="line">        <span class="comment"># 概率分布</span></span><br><span class="line">        p = cond.value_counts()/cond.size</span><br><span class="line">        <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">        indexs =p.index</span><br><span class="line">        entropy = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">            user = X[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">            p_user = user.value_counts()/user.size</span><br><span class="line">            entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">        <span class="built_in">print</span>(col,split,entropy)</span><br><span class="line">        <span class="keyword">if</span> entropy &lt; lower_entropy:</span><br><span class="line">            condition.clear()</span><br><span class="line">            lower_entropy = entropy</span><br><span class="line">            condition[col] = split</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最佳列分条件是：&#x27;</span>,condition)</span><br></pre></td></tr></table></figure>

<img src="/img/post/DecisionTree-Classification/8-Account.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/>

<p>进一步列分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cond = X[<span class="string">&#x27;好友密度&#x27;</span>] &lt; <span class="number">0.5</span></span><br><span class="line">X_ = X[cond]</span><br><span class="line">columns = [<span class="string">&#x27;日志密度&#x27;</span>,<span class="string">&#x27;真实头像&#x27;</span>]</span><br><span class="line">lower_entropy = <span class="number">1</span></span><br><span class="line">condition = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">    x = X_[col].unique()</span><br><span class="line">    x.sort()</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line">    <span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">        split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">        cond = X_[col] &lt;= split</span><br><span class="line">        <span class="comment"># 概率分布</span></span><br><span class="line">        p = cond.value_counts()/cond.size</span><br><span class="line">        <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">        indexs =p.index</span><br><span class="line">        entropy = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">            user = X_[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">            p_user = user.value_counts()/user.size</span><br><span class="line">            entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">        <span class="built_in">print</span>(col,split,entropy)</span><br><span class="line">        <span class="keyword">if</span> entropy &lt; lower_entropy:</span><br><span class="line">            condition.clear()</span><br><span class="line">            lower_entropy = entropy</span><br><span class="line">            condition[col] = split</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最佳列分条件是：&#x27;</span>,condition)</span><br></pre></td></tr></table></figure>

<img src="/img/post/DecisionTree-Classification/9-Account.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/>

<h2 id="3、决策树分裂指标"><a href="#3、决策树分裂指标" class="headerlink" title="3、决策树分裂指标"></a>3、决策树分裂指标</h2><p>常用的分裂条件时：</p>
<ul>
<li>信息增益</li>
<li>Gini 系数</li>
<li>信息增益率</li>
<li>MSE（回归问题）</li>
</ul>
<h3 id="3-1、信息熵（ID3）"><a href="#3-1、信息熵（ID3）" class="headerlink" title="3.1、信息熵（ID3）"></a>3.1、信息熵（ID3）</h3><p>在信息论里熵叫作信息量，即熵是对不确定性的度量。从控制论的角度来看，应叫不确定性。信息论的创始人香农在其著作《通信的数学理论》中提出了建立在概率统计模型上的信息度量。他把信息定义为“用来消除不确定性的东西”。在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。还是举例说明，假设 Dammi 在买衣服的时候有颜色，尺寸，款式以及设计年份四种要求，而 Sara 只有颜色和尺寸的要求，那么在购买衣服这个层面上 Dammi 由于选择更多因而不确定性因素更大，最终 Dammi 所获取的信息更多，也就是熵更大。所以信息量&#x3D;熵&#x3D;不确定性，通俗易懂。在叙述决策树时我们用熵表示不纯度（Impurity）。</p>
<p>对应公式如下：</p>
<p><font size = 5>$H(x) &#x3D; -\sum\limits_{i &#x3D; 1}^n p(x)log_2p(x)$</font></p>
<p>熵的变化越大，说明划分越纯，信息增益越大~</p>
<h3 id="3-2、Gini-系数（CART）"><a href="#3-2、Gini-系数（CART）" class="headerlink" title="3.2、Gini 系数（CART）"></a>3.2、Gini 系数（CART）</h3><p>基尼系数是指国际上通用的、用以衡量一个国家或地区居民收入差距的常用指标。</p>
<p>基尼系数最大为“1”，最小等于“0”。基尼系数越接近 0 表明收入分配越是趋向平等。国际惯例把 0.2 以下视为收入绝对平均，0.2-0.3 视为收入比较平均；0.3-0.4 视为收入相对合理；0.4-0.5 视为收入差距较大，当基尼系数达到 0.5 以上时，则表示收入悬殊。</p>
<p>基尼系数的实际数值只能介于 0 ～ 1 之间，基尼系数越小收入分配越平均，基尼系数越大收入分配越不平均。国际上通常把 0.4 作为贫富差距的警戒线，大于这一数值容易出现社会动荡。</p>
<p>Gini 系数越小，代表集合中的数据越纯，所有我们可以计算分裂前的值在按照某个维度对数据集进行划分，然后可以去计算多个节点的 Gini 系数。</p>
<p>对应公式如下：</p>
<p><font size = 5>$\rm gini &#x3D; \sum\limits_{i &#x3D; 1}^np_i(1 - p_i)$</font></p>
<p>在对数据进行分类是 gini 系数的变化越大，说明划分越纯，效果越好~</p>
<h3 id="3-3、信息增益率"><a href="#3-3、信息增益率" class="headerlink" title="3.3、信息增益率"></a>3.3、信息增益率</h3><p>大学期末的数学考试只有单选题。对于一个完全没有学习过的学生。该如何过关呢？</p>
<p>4 个选项是正确选项的概率都是 1&#x2F;4。那么单项选择题的答案的熵就是：</p>
<p>$H(Y) \rm &#x3D; -0.25log_2(0.25) \times 4 &#x3D; 2bit$</p>
<p>在学霸圈做单项选择题有一个秘籍：三长一短选最短，三短一长选最长。姑且假设学霸的秘籍一般都是正确的。</p>
<p>如果在某场考试中，有 10%的单项选题是三长一短，10%的选题是三短一长。计算该考试单项选题的关于长短题的条件熵：</p>
<table>
<thead>
<tr>
<th align="center">题目类型</th>
<th align="center">答案概率</th>
<th align="center">题目概率</th>
</tr>
</thead>
<tbody><tr>
<td align="center">三长一短</td>
<td align="center">(1,0,0,0)熵是 0，结果确定！</td>
<td align="center">10%</td>
</tr>
<tr>
<td align="center">三短一长</td>
<td align="center">(1,0,0,0)熵是 0</td>
<td align="center">10%</td>
</tr>
<tr>
<td align="center">一样长</td>
<td align="center">(0.25,0.25,0.25,0.25)熵是 2</td>
<td align="center">80%</td>
</tr>
</tbody></table>
<p>计算条件熵（条件就是：题目不同类型）</p>
<p>$H(Y|X) \rm &#x3D; 0.1\times 0 + 0.1 \times 0 + 0.8 \times 2 &#x3D; 1.6bit$</p>
<p>那么信息增益是：</p>
<p>$g(X,Y) \rm &#x3D; H(Y) - H(Y|X) &#x3D; 2 - 1.6 &#x3D; 0.4bit$</p>
<p><strong>信息增益率</strong>在信息增益的基础上增加了惩罚项，惩罚项是特征的固有值。</p>
<p>写作 gr(X,Y)。定义为信息增益除以特征的固有值，如下：</p>
<p><font size = 5>$gr(X,Y) &#x3D; \frac{g(X,Y)}{Info(X)}$</font></p>
<p><font size = 5>$Info(X) &#x3D; -\sum\limits_{v \in values(X)}\frac{num(v)}{num(X)}log_2{\frac{num(v)}{num(X)}}$</font></p>
<p>计算上面单选题题目长短案例的信息增益率：</p>
<p><font size = 5>$Info(X) &#x3D; -(0.1 \times log_20.1 \times 2 + 0.8 \times log_20.8) &#x3D; 0.92$</font></p>
<p><font size = 5>$gr(X,Y) &#x3D; \frac{g(X,Y)}{Info(X)} &#x3D; \frac{0.4}{0.92} &#x3D; 0.43$</font></p>
<p>对于取值多的属性，尤其一些连续型数值，这个单独的属性就可以划分所有的样本，使得所有分支下的样本集合都是“纯的”（最极端的情况是每个叶子节点只有一个样本）。<br>一个属性的信息增益越大，表明属性对样本的熵减少的能力更强，这个属性使得数据由不确定性变成确定性的能力越强。<br>所以如果是取值更多的属性，更容易使得数据更“纯”（尤其是连续型数值），其信息增益更大，决策树会首先挑选这个属性作为树的顶点。结果训练出来的形状是一棵庞大且深度很浅的树，这样的划分是极为不合理的。</p>
<p><img src="/img/post/DecisionTree-Classification/10-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>C4.5 使用了信息增益率，在信息增益的基础上除了一项 split information,来惩罚值更多的属性。从而使划分更加合理！</p>
<h3 id="3-4、MSE"><a href="#3-4、MSE" class="headerlink" title="3.4、MSE"></a>3.4、MSE</h3><p>用于回归树，后面章节具体介绍</p>
<p><img src="/img/post/DecisionTree-Classification/11-%E5%9B%9E%E5%BD%92%E6%A0%91.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h2 id="4、鸢尾花分类代码实战"><a href="#4、鸢尾花分类代码实战" class="headerlink" title="4、鸢尾花分类代码实战"></a>4、鸢尾花分类代码实战</h2><h3 id="4-1、决策树分类鸢尾花数据集"><a href="#4-1、决策树分类鸢尾花数据集" class="headerlink" title="4.1、决策树分类鸢尾花数据集"></a>4.1、决策树分类鸢尾花数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X,y = datasets.load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth调整树深度：剪枝操作</span></span><br><span class="line"><span class="comment"># max_depth默认，深度最大，延伸到将数据完全划分开为止。</span></span><br><span class="line">model = DecisionTreeClassifier(max_depth=<span class="literal">None</span>,criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X_train,y_train)</span><br><span class="line">y_ = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;算法预测是：&#x27;</span>,y_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率是：&#x27;</span>,model.score(X_test,y_test))</span><br><span class="line"><span class="comment"># 决策树提供了predict_proba这个方法，发现这个方法，返回值要么是0，要么是1</span></span><br><span class="line">model.predict_proba(X_test)</span><br></pre></td></tr></table></figure>

<h3 id="4-2、决策树可视化"><a href="#4-2、决策树可视化" class="headerlink" title="4.2、决策树可视化"></a>4.2、决策树可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="comment"># 导出数据</span></span><br><span class="line">dot_data = tree.export_graphviz(model,feature_names=fn,</span><br><span class="line">                     class_names=iris[<span class="string">&#x27;target_names&#x27;</span>],<span class="comment"># 类别名</span></span><br><span class="line">                     filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                     rounded=<span class="literal">True</span>,)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;iris&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/img/post/DecisionTree-Classification/12-iris.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="4-3、决策树剪枝"><a href="#4-3、决策树剪枝" class="headerlink" title="4.3、决策树剪枝"></a>4.3、决策树剪枝</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置图片的尺寸</span></span><br><span class="line"><span class="comment"># 鸢尾花4个属性</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">fn = iris[<span class="string">&#x27;feature_names&#x27;</span>]</span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth调整树深度：剪枝操作</span></span><br><span class="line"><span class="comment"># max_depth默认，深度最大，延伸到将数据完全划分开为止。</span></span><br><span class="line"><span class="comment"># min_impurity_decrease（节点划分最小不纯度）如果某节点的不纯度(基尼系数，信息增益，均方差)小于这个阈值，则该节点不再生成子节点</span></span><br><span class="line"><span class="comment"># max_depth（决策树最大深度）；min_samples_split（内部节点再划分所需最小样本数）</span></span><br><span class="line"><span class="comment"># min_samples_leaf（叶子节点最少样本数）；max_leaf_nodes（最大叶子节点数）</span></span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>,min_impurity_decrease=<span class="number">0.2</span>)</span><br><span class="line">model.fit(X_train,y_train)</span><br><span class="line">y_ = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;算法预测是：&#x27;</span>,y_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率是：&#x27;</span>,model.score(X_test,y_test))</span><br><span class="line"><span class="comment"># 导出数据</span></span><br><span class="line">dot_data = tree.export_graphviz(model,feature_names=fn,</span><br><span class="line">                     class_names=iris[<span class="string">&#x27;target_names&#x27;</span>],<span class="comment"># 类别名</span></span><br><span class="line">                     filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                     rounded=<span class="literal">True</span>,)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;./13-iris-裁剪&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/img/post/DecisionTree-Classification/13-iris-%E5%89%AA%E6%9E%9D.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="4-4、选择合适的超参数并可视化"><a href="#4-4、选择合适的超参数并可视化" class="headerlink" title="4.4、选择合适的超参数并可视化"></a>4.4、选择合适的超参数并可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X,y = datasets.load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line">depth = np.arange(<span class="number">1</span>,<span class="number">16</span>)</span><br><span class="line">err = []</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> depth:</span><br><span class="line">    model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>,max_depth=d)</span><br><span class="line">    model.fit(X_train,y_train)</span><br><span class="line">    score = model.score(X_test,y_test)</span><br><span class="line">    err.append(<span class="number">1</span> - score)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;错误率为%0.3f%%&#x27;</span> % (<span class="number">100</span> * (<span class="number">1</span> - score)))</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;STKaiti&#x27;</span></span><br><span class="line">plt.plot(depth,err,<span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;决策树深度&#x27;</span>,fontsize = <span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;错误率&#x27;</span>,fontsize = <span class="number">18</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;筛选合适决策树深度&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.savefig(<span class="string">&#x27;./14-筛选超参数.png&#x27;</span>,dpi = <span class="number">200</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/img/post/DecisionTree-Classification/14-%E7%AD%9B%E9%80%89%E8%B6%85%E5%8F%82%E6%95%B0.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="4-5、决策树副产物"><a href="#4-5、决策树副产物" class="headerlink" title="4.5、决策树副产物"></a>4.5、决策树副产物</h3><ul>
<li><p>特征重要性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>学习记录类</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>逻辑回归二分类</title>
    <url>/2021/06/11/LogisticRegression/</url>
    <content><![CDATA[<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h2 id="1、广义线性回归到逻辑回归"><a href="#1、广义线性回归到逻辑回归" class="headerlink" title="1、广义线性回归到逻辑回归"></a>1、广义线性回归到逻辑回归</h2><h3 id="1-1、什么是逻辑回归"><a href="#1-1、什么是逻辑回归" class="headerlink" title="1.1、什么是逻辑回归"></a>1.1、什么是逻辑回归</h3><p>&emsp;&emsp;逻辑回归<strong>不是</strong>一个回归的算法，逻辑回归是一个<strong>分类</strong>的算法，好比卡巴斯基不是司机，红烧狮子头没有狮子头一样。 那为什么逻辑回归不叫逻辑分类？因为逻辑回归算法是基于多元线性回归的算法。而正因为此，逻辑回归这个分类算法是线性的分类器。未来我们要学的基于决策树的一系列算法，基于神经网络的算法等那些是非线性的算法。SVM 支持向量机的本质是线性的，但是也可以通过内部的核函数升维来变成非线性的算法。</p>
<p>&emsp;&emsp;逻辑回归中对应一条非常重要的曲线 S 型曲线，对应的函数是 Sigmoid 函数：</p>
<p><font size = 6>$f(x) &#x3D; \frac{1}{1 + e^{-x}}$</font></p>
<p>它有一个非常棒的特性，其导数可以用其自身表示：</p>
<p><font size = 6>$f’(x) &#x3D; \frac{e^{-x}}{(1 + e^{-x})^2} &#x3D;f(x) * \frac{1 + e^{-x} - 1}{1 + e^{-x}} &#x3D; f(x) * (1 - f(x))$</font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-x))</span><br><span class="line">x = np.linspace(-<span class="number">5</span>,<span class="number">5</span>,<span class="number">100</span>)</span><br><span class="line">y = sigmoid(x)</span><br><span class="line">plt.plot(x,y,color = <span class="string">&#x27;green&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/LogisticRegression/1-S%E5%9E%8B%E6%9B%B2%E7%BA%BF.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="1-2、Sigmoid-函数介绍"><a href="#1-2、Sigmoid-函数介绍" class="headerlink" title="1.2、Sigmoid 函数介绍"></a>1.2、Sigmoid 函数介绍</h3><p>&emsp;&emsp;逻辑回归就是在多元线性回归基础上把结果缩放到 0 ~ 1 之间。 $h_{\theta}(x)$ 越接近 1 越是正例，$h_{\theta}(x)$ 越接近 0 越是负例，根据中间 0.5 将数据分为二类。其中$h_{\theta}(x)$ 就是概率函数~</p>
<p><font size = 8>$h_{\theta}(x) &#x3D; g(\theta^Tx) &#x3D; \frac{1}{1 + e^{-\theta^Tx}}$</font></p>
<p>&emsp;&emsp;我们知道分类器的本质就是要找到分界，所以当我们把 0.5 作为分类边界时，我们要找的就是$\hat{y} &#x3D; h_{\theta}(x) &#x3D; \frac{1}{1 + e^{-\theta^Tx}} &#x3D; 0.5$ ，即 $z &#x3D; \theta^Tx &#x3D; 0$ 时，$\theta$ 的解~</p>
<p><img src="/../img/post/LogisticRegression/2-sigmoid.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>求解过程如下：</p>
<p><img src="/../img/post/LogisticRegression/3-Sigmoid.jpeg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>&emsp;&emsp;什么事情，都要做到知其然，知其所以然，我们知道二分类有个特点就是正例的概率 + 负例的概率 &#x3D; 1。一个非常简单的试验是只有两种可能结果的试验，比如正面或反面，成功或失败，有缺陷或没有缺陷，病人康复或未康复等等。为方便起见，记这两个可能的结果为 0 和 1，下面的定义就是建立在这类试验基础之上的。 如果随机变量 x 只取 0 和 1 两个值，并且相应的概率为：</p>
<ul>
<li>$Pr(x &#x3D; 1) &#x3D; p; Pr(x &#x3D; 0) &#x3D; 1-p; 0 &lt; p &lt; 1$</li>
</ul>
<p>&emsp;&emsp;则称随机变量 x 服从参数为 p 的<strong>Bernoulli</strong>伯努利分布( 0-1 分布)，则 x 的概率函数可写：</p>
<ul>
<li>$f(x | p) &#x3D; \begin{cases}p^x(1 - p)^{1-x}, &amp;x &#x3D;  1、0\0,&amp; x \neq 1、0\end{cases}$</li>
</ul>
<p>&emsp;&emsp;逻辑回归二分类任务会把正例的 label 设置为 1，负例的 label 设置为 0，对于上面公式就是 x &#x3D; 0、1。</p>
<h2 id="2、逻辑回归公式推导"><a href="#2、逻辑回归公式推导" class="headerlink" title="2、逻辑回归公式推导"></a>2、逻辑回归公式推导</h2><h3 id="2-1、损失函数推导"><a href="#2-1、损失函数推导" class="headerlink" title="2.1、损失函数推导"></a>2.1、损失函数推导</h3><p>&emsp;&emsp;这里我们依然会用到最大似然估计思想，根据若干已知的 X,y(训练集) 找到一组 $\theta$ 使得 X 作为已知条件下 y 发生的概率最大。</p>
<p><font size = 6>$P(y|x;\theta) &#x3D; \begin{cases}h_{\theta}(x), &amp;y &#x3D;  1\1-h_{\theta}(x),&amp; y &#x3D;  0\end{cases}$ </font></p>
<p><strong>整合到一起（二分类就两种情况：1、0）得到<font color = 'green'>逻辑回归表达式</font>：</strong></p>
<p><font size = 6 color = 'green'>$P(y|x;\theta) &#x3D; (h_{\theta}(x))^{y}(1 - h_{\theta}(x))^{1-y}$</font></p>
<p>我们假设训练样本相互独立，那么似然函数表达式为:</p>
<p><font size = 6>$L(\theta) &#x3D; \prod\limits_{i &#x3D; 1}^nP(y^{(i)}|x^{(i)};\theta)$</font></p>
<p><font size = 6>$L(\theta) &#x3D; \prod\limits_{i&#x3D;1}^n(h_{\theta}(x^{(i)}))^{y^{(i)}}(1 - h_{\theta}(x^{(i)}))^{1-y^{(i)}}$</font></p>
<p><font color = red size = 6>对数转换，自然底数为底</font></p>
<p><font size = 5>$l(\theta) &#x3D; \ln{L(\theta)} &#x3D;\ln( \prod\limits_{i&#x3D;1}^n({h_{\theta}(x^{(i)}))^{y^{(i)}}}{(1 - h_{\theta}(x^{(i)}))^{1-y^{(i)}}})$​​</font></p>
<p>化简，累乘变累加：</p>
<p><font size = 5>$l(\theta) &#x3D; \ln{L(\theta)} &#x3D; \sum\limits_{i &#x3D; 1}^n(y^{(i)}\ln(h_{\theta}(x^{(i)})) + (1-y^{(i)})\ln(1-h_{\theta}(x^{(i)})))$</font></p>
<p>&emsp;&emsp;<strong>总结</strong>，得到了逻辑回归的表达式，下一步跟线性回归类似，构建似然函数，然后最大似然估计，最终推导出 $\theta$ 的迭代更新表达式。只不过这里用的不是梯度下降，而是梯度上升，因为这里是最大化似然函数。通常我们一提到损失函数，往往是求最小，这样我们就可以用<strong>梯度下降</strong>来求解。最终损失函数就是上面公式加负号的形式:</p>
<p><font size = 5 color = 'green'>$J(\theta) &#x3D; -l(\theta) &#x3D; -\sum\limits_{i &#x3D; 1}^n[y^{(i)}\ln(h_{\theta}(x^{(i)})) + (1-y^{(i)})\ln(1-h_{\theta}(x^{(i)}))]$</font></p>
<h3 id="2-2、立体化呈现"><a href="#2-2、立体化呈现" class="headerlink" title="2.2、立体化呈现"></a>2.2、立体化呈现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> scale <span class="comment"># 数据标准化Z-score</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、加载乳腺癌数据</span></span><br><span class="line">data = datasets.load_breast_cancer()</span><br><span class="line">X, y = scale(data[<span class="string">&#x27;data&#x27;</span>][:, :<span class="number">2</span>]), data[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、求出两个维度对应的数据在逻辑回归算法下的最优解</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、分别把两个维度所对应的参数W1和W2取出来</span></span><br><span class="line">w1 = lr.coef_[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">w2 = lr.coef_[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(w1, w2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、已知w1和w2的情况下，传进来数据的X，返回数据的y_predict</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">X, w1, w2</span>):</span><br><span class="line">    z = w1*X[<span class="number">0</span>] + w2*X[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、传入一份已知数据的X，y，如果已知w1和w2的情况下，计算对应这份数据的Loss损失</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_function</span>(<span class="params">X, y, w1, w2</span>):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历数据集中的每一条样本，并且计算每条样本的损失，加到loss身上得到整体的数据集损失</span></span><br><span class="line">    <span class="keyword">for</span> x_i, y_i <span class="keyword">in</span> <span class="built_in">zip</span>(X, y):</span><br><span class="line">        <span class="comment"># 这是计算一条样本的y_predict，即概率</span></span><br><span class="line">        p = sigmoid(x_i, w1, w2)</span><br><span class="line">        loss += -<span class="number">1</span>*y_i*np.log(p)-(<span class="number">1</span>-y_i)*np.log(<span class="number">1</span>-p)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、参数w1和w2取值空间</span></span><br><span class="line">w1_space = np.linspace(w1-<span class="number">2</span>, w1+<span class="number">2</span>, <span class="number">100</span>)</span><br><span class="line">w2_space = np.linspace(w2-<span class="number">2</span>, w2+<span class="number">2</span>, <span class="number">100</span>)</span><br><span class="line">loss1_ = np.array([loss_function(X, y, i, w2) <span class="keyword">for</span> i <span class="keyword">in</span> w1_space])</span><br><span class="line">loss2_ = np.array([loss_function(X, y, w1, i) <span class="keyword">for</span> i <span class="keyword">in</span> w2_space])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7、数据可视化</span></span><br><span class="line">fig1 = plt.figure(figsize=(<span class="number">12</span>, <span class="number">9</span>))</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(w1_space, loss1_)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(w2_space, loss2_)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">w1_grid, w2_grid = np.meshgrid(w1_space, w2_space)</span><br><span class="line">loss_grid = loss_function(X, y, w1_grid, w2_grid)</span><br><span class="line">plt.contour(w1_grid, w2_grid, loss_grid,<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.contourf(w1_grid, w2_grid, loss_grid,<span class="number">20</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;../img/post/LogisticRegression/4-损失函数可视化.png&#x27;</span>,dpi = <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8、3D立体可视化</span></span><br><span class="line">fig2 = plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">ax = Axes3D(fig2)</span><br><span class="line">ax.plot_surface(w1_grid, w2_grid, loss_grid,cmap = <span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;w1&#x27;</span>,fontsize = <span class="number">20</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;w2&#x27;</span>,fontsize = <span class="number">20</span>)</span><br><span class="line">ax.view_init(<span class="number">30</span>,-<span class="number">30</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;../img/post/LogisticRegression/5-损失函数可视化.png&#x27;</span>,dpi = <span class="number">200</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/LogisticRegression/4-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%AF%E8%A7%86%E5%8C%96.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p><img src="/../img/post/LogisticRegression/5-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%AF%E8%A7%86%E5%8C%96.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h2 id="3、逻辑回归迭代公式"><a href="#3、逻辑回归迭代公式" class="headerlink" title="3、逻辑回归迭代公式"></a>3、逻辑回归迭代公式</h2><h3 id="3-1、函数特性"><a href="#3-1、函数特性" class="headerlink" title="3.1、函数特性"></a>3.1、函数特性</h3><p>&emsp;&emsp;逻辑回归参数更新规则和，线性回归一模一样！</p>
<p><font size = 6>$\theta_j^{t + 1} &#x3D; \theta_j^t - \alpha\frac{\partial}{\partial_{\theta_j}}J(\theta)$</font></p>
<ul>
<li>$\alpha$ 表示学习率</li>
</ul>
<p>逻辑回归函数：</p>
<p><font size = 6>$h_{\theta}(x) &#x3D; g(\theta^Tx) &#x3D; g(z) &#x3D; \frac{1}{1 + e^{-z}}$</font></p>
<ul>
<li>$z &#x3D; \theta^Tx$</li>
</ul>
<p>逻辑回归函数求导时有一个特性，这个特性将在下面的推导中用到，这个特性为：</p>
<p><font size = 4>$\begin{aligned} g’(z) &amp;&#x3D; \frac{\partial}{\partial z}\frac{1}{1 + e^{-z}} \\&amp;&#x3D; \frac{e^{-z}}{(1 + e^{-z})^2}\\&amp; &#x3D; \frac{1}{(1 + e^{-z})^2}\cdot e^{-z}\\&amp;&#x3D;\frac{1}{1 + e^{-z}} \cdot (1 - \frac{1}{1 + e^{-z}})\\&amp;&#x3D;g(z)\cdot (1 - g(z))\end{aligned}$</font></p>
<p>回到逻辑回归损失函数求导：</p>
<p><font size = 4>$J(\theta) &#x3D;  -\sum\limits_{i &#x3D; 1}^n(y^{(i)}\ln(h_{\theta}(x^{i})) + (1-y^{(i)})\ln(1-h_{\theta}(x^{(i)})))$</font></p>
<h3 id="3-2、求导过程"><a href="#3-2、求导过程" class="headerlink" title="3.2、求导过程"></a>3.2、求导过程</h3><p><font size = 4>$\begin{aligned} \frac{\partial}{\partial{\theta_j}}J(\theta) &amp;&#x3D; -\sum\limits_{i &#x3D; 1}^n(y^{(i)}\frac{1}{h_{\theta}(x^{(i)})}\frac{\partial}{\partial_{\theta_j}}h_{\theta}(x^{i}) + (1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})}\frac{\partial}{\partial_{\theta_j}}(1-h_{\theta}(x^{(i)}))) \\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)}\frac{1}{h_{\theta}(x^{(i)})}\frac{\partial}{\partial_{\theta_j}}h_{\theta}(x^{(i)}) - (1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})}\frac{\partial}{\partial_{\theta_j}}h_{\theta}(x^{(i)}))\\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)}\frac{1}{h_{\theta}(x^{(i)})} - (1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})})\frac{\partial}{\partial_{\theta_j}}h_{\theta}(x^{(i)})\\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)}\frac{1}{h_{\theta}(x^{(i)})} - (1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})})h_{\theta}(x^{(i)})(1-h_{\theta}(x^{(i)}))\frac{\partial}{\partial_{\theta_j}}\theta^Tx\\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)}(1-h_{\theta}(x^{(i)})) - (1-y^{(i)})h_{\theta}(x^{(i)}))\frac{\partial}{\partial_{\theta_j}}\theta^Tx\\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)} - h_{\theta}(x^{(i)}))\frac{\partial}{\partial_{\theta_j}}\theta^Tx\\&amp;&#x3D;\sum\limits_{i &#x3D; 1}^n(h_{\theta}(x^{(i)}) -y^{(i)})x_j^{(i)}\end{aligned}$</font></p>
<p>求导最终的公式：</p>
<p><font color = 'red' size = 6>$\frac{\partial}{\partial{\theta_j}}J(\theta) &#x3D; \sum\limits_{i &#x3D; 1}^n(h_{\theta}(x^{(i)}) -y^{(i)})x_j^{(i)}$</font></p>
<p>这里我们发现导函数的形式和多元线性回归一样~</p>
<p>逻辑回归参数迭代更新公式：</p>
<p><font size = 6 color = 'green'>$\theta_j^{t+1} &#x3D; \theta_j^t - \alpha \cdot \sum\limits_{i&#x3D;1}^{n}(h_{\theta}(x^{(i)}) -y^{(i)})x_j^{(i)}$</font></p>
<h3 id="3-3、代码实战"><a href="#3-3、代码实战" class="headerlink" title="3.3、代码实战"></a>3.3、代码实战</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、数据加载</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据提取与筛选</span></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">cond = y != <span class="number">2</span></span><br><span class="line">X = X[cond]</span><br><span class="line">y = y[cond]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、数据拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、模型训练</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、模型预测</span></span><br><span class="line">y_predict = lr.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据保留类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测类别是：&#x27;</span>,y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测概率是：\n&#x27;</span>,lr.predict_proba(X_test))</span><br></pre></td></tr></table></figure>

<p><strong>结论：</strong></p>
<ul>
<li>通过数据提取与筛选，创建二分类问题</li>
<li>类别的划分，通过概率比较大小完成了</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 线性回归方程</span></span><br><span class="line">b = lr.intercept_</span><br><span class="line">w = lr.coef_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = 1 概率</span></span><br><span class="line">z = X_test.dot(w.T) + b</span><br><span class="line">p_1 = sigmoid(z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = 0 概率</span></span><br><span class="line">p_0 = <span class="number">1</span> - p_1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终结果</span></span><br><span class="line">p = np.concatenate([p_0,p_1],axis = <span class="number">1</span>)</span><br><span class="line">p</span><br></pre></td></tr></table></figure>

<p><strong>结论：</strong></p>
<ul>
<li>线性方程，对应方程 $z$</li>
<li>sigmoid 函数，将线性方程转变为概率</li>
<li>自己求解概率和直接使用 LogisticRegression 结果一样，可知计算流程正确</li>
</ul>
<h2 id="4、逻辑回归做多分类"><a href="#4、逻辑回归做多分类" class="headerlink" title="4、逻辑回归做多分类"></a>4、逻辑回归做多分类</h2><h3 id="4-1、One-Vs-Rest-思想"><a href="#4-1、One-Vs-Rest-思想" class="headerlink" title="4.1、One-Vs-Rest 思想"></a>4.1、One-Vs-Rest 思想</h3><p>&emsp;&emsp;在上面，我们主要使用逻辑回归解决二分类的问题，那对于多分类的问题，也可以用逻辑回归来解决！</p>
<p>多分类问题：</p>
<ul>
<li>将邮件分为不同类别&#x2F;标签：工作(y&#x3D;1)，朋友(y&#x3D;2)，家庭(y&#x3D;3)，爱好(y&#x3D;4)</li>
<li>天气分类：晴天(y&#x3D;1)，多云天(y&#x3D;2)，下雨天(y&#x3D;3)，下雪天(y&#x3D;4)</li>
<li>医学图示：没生病(y&#x3D;1)，感冒(y&#x3D;2)，流感(y&#x3D;3)</li>
<li>……</li>
</ul>
<p>上面都是多分类问题。</p>
<p>假设我们要解决一个分类问题，该分类问题有三个类别，分别用 △，□ 和 × 表示，每个实例有两个属性，如果把属性 1 作为 X 轴，属性 2 作为 Y 轴，训练集的分布可以表示为下图：</p>
<p><img src="/../img/post/LogisticRegression/6-ovr%E5%A4%9A%E5%88%86%E7%B1%BB.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>&emsp;&emsp;One-Vs-Rest（ovr）的思想是把一个多分类的问题变成多个二分类的问题。转变的思路就如同方法名称描述的那样，选择其中一个类别为正类（Positive），使其他所有类别为负类（Negative）。比如第一步，我们可以将 △ 所代表的实例全部视为正类，其他实例全部视为负类，得到的分类器如图：</p>
<p><img src="/../img/post/LogisticRegression/7-ovr%E5%A4%9A%E5%88%86%E7%B1%BB.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>同理我们把 × 视为正类，其他视为负类，可以得到第二个分类器：</p>
<p><img src="/../img/post/LogisticRegression/8-ovr%E5%A4%9A%E5%88%86%E7%B1%BB.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>最后，第三个分类器是把 □ 视为正类，其余视为负类：</p>
<p><img src="/../img/post/LogisticRegression/9-ovr%E5%A4%9A%E5%88%86%E7%B1%BB.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>&emsp;&emsp;对于一个三分类问题，我们最终得到 3 个二元分类器。在预测阶段，每个分类器可以根据测试样本，得到当前类别的概率。即 P(y &#x3D; i | x; θ)，i &#x3D; 1, 2, 3。选择计算结果最高的分类器，其所对应类别就可以作为预测结果。</p>
<p>One-Vs-Rest 作为一种常用的二分类拓展方法，其优缺点也十分明显：</p>
<ul>
<li><p>优点：普适性还比较广，可以应用于能输出值或者概率的分类器，同时效率相对较好，有多少个类别就训练多少个分类器。</p>
</li>
<li><p>缺点：很容易造成训练集样本数量的不平衡（Unbalance），尤其在类别较多的情况下，经常容易出现正类样本的数量远远不及负类样本的数量，这样就会造成分类器的偏向性。</p>
</li>
</ul>
<h3 id="4-2、代码实战"><a href="#4-2、代码实战" class="headerlink" title="4.2、代码实战"></a>4.2、代码实战</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、数据加载</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据提取</span></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、数据拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、模型训练</span></span><br><span class="line">lr = LogisticRegression(multi_class = <span class="string">&#x27;ovr&#x27;</span>)</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、模型预测</span></span><br><span class="line">y_predict = lr.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据保留类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测类别是：&#x27;</span>,y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测概率是：\n&#x27;</span>,lr.predict_proba(X_test))</span><br></pre></td></tr></table></figure>

<p><strong>结论：</strong></p>
<ul>
<li>通过数据提取，创建三分类问题</li>
<li>类别的划分，通过概率比较大小完成了</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 线性回归方程，3个方程</span></span><br><span class="line">b = lr.intercept_</span><br><span class="line">w = lr.coef_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算三个方程的概率</span></span><br><span class="line">z = X_test.dot(w.T) + b</span><br><span class="line">p = sigmoid(z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化处理，概率求和为1</span></span><br><span class="line">p = p/p.<span class="built_in">sum</span>(axis = <span class="number">1</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">p</span><br></pre></td></tr></table></figure>

<p><strong>结论：</strong></p>
<ul>
<li>线性方程，对应方程 $z$ ，此时对应三个方程</li>
<li>sigmoid 函数，将线性方程转变为概率，并进行标准化处理</li>
<li>自己求解概率和直接使用 LogisticRegression 结果一样</li>
</ul>
<h2 id="5、多分类-Softmax-回归"><a href="#5、多分类-Softmax-回归" class="headerlink" title="5、多分类 Softmax 回归"></a>5、多分类 Softmax 回归</h2><h3 id="5-1、多项分布指数分布族形式"><a href="#5-1、多项分布指数分布族形式" class="headerlink" title="5.1、多项分布指数分布族形式"></a>5.1、多项分布指数分布族形式</h3><p>&emsp;&emsp;Softmax 回归是另一种做多分类的算法。从名字中大家是不是可以联想到广义线性回归，Softmax 回归是假设多项分布的，多项分布可以理解为二项分布的扩展。投硬币是二项分布，掷骰子是多项分布。</p>
<p>&emsp;&emsp;我们知道，对于伯努利分布，我们采用 Logistic 回归建模。那么我们应该如何处理多分类问题？对于这种多项分布我们使用 softmax 回归建模。</p>
<p>y 有多个可能的分类： $y \in {1,2,3,……,k}$，</p>
<p>每种分类对应的概率： $\phi_1,\phi_2……\phi_k$ ，由于 $\sum\limits_{i &#x3D; 1}^k\phi_i &#x3D; 1$ ，所以一般用 k-1 个参数$\phi_1,\phi_2……\phi_{k-1}$ 。其中：</p>
<ul>
<li>$p(y &#x3D; i;\phi) &#x3D; \phi_i$</li>
<li>$p(y &#x3D; k;\phi) &#x3D; 1 - \sum\limits_{i &#x3D; 1}^{k -1}\phi_i$ 。</li>
</ul>
<p>为了将多项分布表达为指数族分布，做一下工作：</p>
<ul>
<li><p>定义 ，$T(y) \in R^{k-1}$它不再是一个数而是一个变量</p>
<p><img src="/../img/post/LogisticRegression/9-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%88%86%E5%B8%83.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
</li>
<li><p>引进指示函数：$I{\cdot}$为$I{True} &#x3D; 1$，$I{False} &#x3D; 0$</p>
<p>$E(T(y)_i) &#x3D; p(y &#x3D; i) &#x3D; \phi_i$</p>
</li>
</ul>
<p>得到它的指数分布族形式：</p>
<p><font size = 4>$\begin{aligned}p(y;\phi) &amp;&#x3D; \phi_1^{I{y &#x3D; 1}}\phi_2^{I{y &#x3D; 2}}…\phi_k^{I{y &#x3D; k}}\\&amp;&#x3D;\phi_1^{I{y &#x3D; 1}}\phi_2^{I{y &#x3D; 2}}…\phi_k^{1 - \sum\limits_{i&#x3D;1}^{k-1}I{y &#x3D; i}}\\&amp;&#x3D;\phi_1^{(T(y))_1}\phi_2^{(T(y))<em>2}…\phi_k^{1 - \sum\limits</em>{i &#x3D; 1}^{k-1}(T(y))_i}\\&amp;&#x3D;\exp((T(y))_1\log(\phi_1) + (T(y))<em>2\log(\phi_2)…+(1 - \sum\limits</em>{i &#x3D; 1}^{k-1}(T(y))_i)\log(\phi_k))\\&amp;&#x3D;\exp((T(y))<em>1\log\frac{\phi_1}{\phi_k} + (T(y))<em>2\log\frac{\phi_2}{\phi_k} + … + (T(y))</em>{k-1}\log\frac {\phi</em>{k-1}}{\phi_k} + \log(\phi_k))\end{aligned}$</font></p>
<p>指数分布族标准表达式如下：</p>
<p><font size = 6>$p(y;\eta) &#x3D; b(y)\exp(\eta T(y) - \alpha(\eta))$</font></p>
<p><strong>得到对应模型参数：</strong></p>
<p>$ \eta &#x3D; \left{ \begin{aligned} &amp;\log(\phi<em>1&#x2F;\phi_k) \ &amp;\log(\phi_2&#x2F;\phi_k) \ &amp;…\&amp;\log(\phi</em>{k-1}&#x2F;\phi_k) \end{aligned} \right.$</p>
<p>$\alpha(\eta) &#x3D; -\log(\phi_k)$</p>
<p>$b(y) &#x3D; 1$</p>
<h3 id="5-2、广义线性模型推导-Softmax-回归"><a href="#5-2、广义线性模型推导-Softmax-回归" class="headerlink" title="5.2、广义线性模型推导 Softmax 回归"></a>5.2、广义线性模型推导 Softmax 回归</h3><p>&emsp;&emsp;证明了多项分布属于指数分布族后，接下来求取由它推导出的概率函数 Softmax</p>
<ul>
<li><p><font size = 5>$\eta_i &#x3D; \log\frac{\phi_i}{\phi_k}$   —&gt;   $e^{\eta_i} &#x3D; \frac{\phi_i}{\phi_k}$   —&gt;   $\phi_ke^{\eta_i} &#x3D; \phi_i$</font></p>
</li>
<li><p><font size = 5>$\phi_k\sum\limits_{i &#x3D; 1}^k e^{\eta_i} &#x3D; \sum\limits_{i &#x3D; 1}^k &#x3D; 1$</font></p>
</li>
<li><p><font size = 5>$\phi_k &#x3D; \frac{1}{\sum\limits_{i &#x3D; 1}^ke^{\eta_i}}$</font></p>
</li>
<li><p><font size = 5 color = 'red'>$\phi_i &#x3D; \frac{e^{\eta_i}}{\sum\limits_{j &#x3D; 1}^ke^{\eta_j}}$</font></p>
</li>
</ul>
<p>上面这个函数，就叫做 Softmax 函数。</p>
<p>引用广义线性模型的<strong>假设 3</strong>，即 $\eta$ 是 x 的线性函数，带入 Softmax 函数可以得到：</p>
<p><font size = 5>$\begin{aligned}p(y &#x3D; i|x;\theta) &amp;&#x3D; \phi_i \\ &amp;&#x3D;\frac{e^{\eta_i}}{\sum\limits_{j &#x3D; 1}^ke^{\eta_j}} \\&amp;&#x3D;\frac{e^{\theta_i^Tx}}{\sum\limits_{j &#x3D; 1}^ke^{\theta_j^Tx}}\end{aligned}$</font></p>
<p>这个模型被应用到 y &#x3D; {1, 2, …, k}就称作<strong>Softmax 回归</strong>，是逻辑回归的推广。最终可以得到它的假设函数 $h_{\theta}(x)$：</p>
<p><font size = 5>$ h*{\theta}(x) &#x3D; \left{ \begin{aligned} &amp;\frac{e^{\theta_1^Tx}}{\sum\limits*{j &#x3D; 1}^ke^{\theta<em>j^Tx}} , y &#x3D; 1\ &amp;\frac{e^{\theta_2^Tx}}{\sum\limits</em>{j &#x3D; 1}^ke^{\theta<em>j^Tx}} , y &#x3D; 2\ &amp;…\&amp;\frac{e^{\theta_k^Tx}}{\sum\limits</em>{j &#x3D; 1}^ke^{\theta_j^Tx}}, y &#x3D; k \end{aligned} \right.$</font></p>
<p>举例说明：</p>
<p><img src="/../img/post/LogisticRegression/10-softmax.jpeg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="5-3、代码实战"><a href="#5-3、代码实战" class="headerlink" title="5.3、代码实战"></a>5.3、代码实战</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、数据加载</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据提取</span></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、数据拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、模型训练，使用multinomial分类器，表示多分类</span></span><br><span class="line">lr = LogisticRegression(multi_class = <span class="string">&#x27;multinomial&#x27;</span>,max_iter=<span class="number">5000</span>)</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、模型预测</span></span><br><span class="line">y_predict = lr.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据保留类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测类别是：&#x27;</span>,y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测概率是：\n&#x27;</span>,lr.predict_proba(X_test))</span><br></pre></td></tr></table></figure>

<p><strong>结论：</strong></p>
<ul>
<li>通过数据提取，创建三分类问题</li>
<li>参数 multi_class 设置成 multinomial 表示多分类，使用交叉熵作为损失函数</li>
<li>类别的划分，通过概率比较大小完成了</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 线性回归方程，3个方程</span></span><br><span class="line">b = lr.intercept_</span><br><span class="line">w = lr.coef_</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(z)/np.exp(z).<span class="built_in">sum</span>(axis = <span class="number">1</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算三个方程的概率</span></span><br><span class="line">z = X_test.dot(w.T) + b</span><br><span class="line">p = softmax(z)</span><br><span class="line">p</span><br></pre></td></tr></table></figure>

<p><strong>结论：</strong></p>
<ul>
<li>线性方程，对应方程 $z$ ，多分类，此时对应三个方程</li>
<li>softmax 函数，将线性方程转变为概率</li>
<li>自己求解概率和直接使用 LogisticRegression 结果一样</li>
</ul>
<h2 id="6、逻辑回归与-Softmax-回归对比"><a href="#6、逻辑回归与-Softmax-回归对比" class="headerlink" title="6、逻辑回归与 Softmax 回归对比"></a>6、逻辑回归与 Softmax 回归对比</h2><h3 id="6-1、逻辑回归是-Softmax-回归特例证明"><a href="#6-1、逻辑回归是-Softmax-回归特例证明" class="headerlink" title="6.1、逻辑回归是 Softmax 回归特例证明"></a>6.1、逻辑回归是 Softmax 回归特例证明</h3><p>逻辑回归可以看成是 Softmax 回归的特例，当 k &#x3D; 2 时，softmax 回归退化为逻辑回归，softmax 回归的假设函数为：</p>
<p><font size = 5>$h_{\theta}(x) &#x3D; \frac{1}{e^{\theta_1^Tx} + e^{\theta_2^Tx}} \Bigg[\begin{aligned}e^{\theta_1^Tx}\e^{\theta_2^Tx} \end{aligned}\Bigg]$</font></p>
<p>利用 softmax 回归参数冗余的特点，我们令$\psi &#x3D; \theta_1$并且从两个参数向量中都减去向量 $\theta_1$ ，得到:</p>
<p><font size = 5>$h_{\theta}(x) &#x3D; \frac{1}{e^{\vec{0}^Tx}   + e^{(\theta_2 - \theta_1)^Tx}} \Bigg[\begin{aligned}&amp;e^{\vec{0}^Tx}\&amp;e^{(\theta_2 - \theta_1)^Tx} \end{aligned}\Bigg]$</font></p>
<p>展开：</p>
<p><font size = 5>$\frac{e^{\vec{0}^Tx} }{e^{\vec{0}^Tx}   + e^{(\theta_2 - \theta_1)^Tx}}$</font> —&gt; <font size = 5>$\frac{1}{1   + e^{(\theta_2 - \theta_1)^Tx}}$</font></p>
<p><font size =5>$\frac{ e^{(\theta_2 - \theta_1)^Tx} }{e^{\vec{0}^Tx}   + e^{(\theta_2 - \theta_1)^Tx}}$</font> —&gt; <font size =5>$\frac{ e^{(\theta_2 - \theta_1)^Tx} }{1   + e^{(\theta_2 - \theta_1)^Tx}}$</font></p>
<p>因此，用$\theta$ 来表示 $\theta_2 - \theta_1$：</p>
<p><font size = 5>$\frac{1}{1   + e^{\theta^Tx}}$</font></p>
<p><font size =5>$\frac{ e^{\theta^Tx} }{1   + e^{\theta^Tx}}$</font> —&gt;<font size =5>$\frac{ 1 }{1   + e^{-\theta^Tx}}$</font> （这就是逻辑回归公式）</p>
<h3 id="6-2、Softmax-损失函数"><a href="#6-2、Softmax-损失函数" class="headerlink" title="6.2、Softmax 损失函数"></a>6.2、Softmax 损失函数</h3><p>求极大似然：</p>
<p><font size = 5>$L(\theta) &#x3D; \prod\limits_{i &#x3D; 1}^np(y^{(i)}|x^{(i)};\theta) &#x3D; \prod\limits_{i &#x3D; 1}^n\prod\limits_{j &#x3D; 1}^k\phi_j^{I&lt;!–swig￼8–&gt;}$</font></p>
<p>求对数：</p>
<p><font size = 5>$\begin{aligned}l(\theta) &amp;&#x3D; \sum\limits_{i &#x3D; 1}^n\log p(y^{(i)}|x^{(i)};\theta) \ \&amp;&#x3D;\sum\limits_{i &#x3D; 1}^n\log\prod\limits_{j &#x3D; 1}^k\phi_j^{I&lt;!–swig￼9–&gt;}\\&amp;&#x3D; \sum\limits_{i &#x3D; 1}^n\log\prod\limits_{j &#x3D; 1}^k(\frac{e^{\theta_j^Tx^{(i)}}}{\sum\limits_{l &#x3D; 1}^ke^{\theta_l^Tx^{(i)}}})^{I&lt;!–swig￼10–&gt;}\end{aligned}$</font></p>
<p>取反，损失函数是：</p>
<p><font size = 5>$\begin{aligned}J(\theta) &amp;&#x3D; -\sum\limits*{i &#x3D; 1}^n\log\prod\limits*{j &#x3D; 1}^k(\frac{e^{\theta<em>j^Tx^{(i)}}}{\sum\limits</em>{l &#x3D; 1}^ke^{\theta<em>l^Tx^{(i)}}})^{I&lt;!–swig￼11–&gt;}\\ &amp;&#x3D; \sum\limits</em>{i &#x3D; 1}^n\sum\limits*{j &#x3D; 1}^kI&lt;!–swig￼12–&gt;\log\frac{e^{\theta_j^Tx^{(i)}}}{\sum\limits*{l &#x3D; 1}^ke^{\theta_l^Tx^{(i)}}}\end{aligned} $</font></p>
<p>上面公式对应着<strong>交叉熵</strong>！</p>
<p>对比百度百科给出的交叉熵定义公式，H(p,q)称之为交叉熵（p 为真实分布，q 为非真实分布即预测概率）：</p>
<p><font size =5>$H(p,q) &#x3D; \sum\limits_ip(i)\cdot log(\frac{1}{q(i)})$</font></p>
]]></content>
      <categories>
        <category>学习记录类</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>频率滤波</title>
    <url>/2021/06/12/Digitalimageprocessing-Frequencydomainfiltering/</url>
    <content><![CDATA[<h1 id="频域滤波"><a href="#频域滤波" class="headerlink" title="频域滤波"></a>频域滤波</h1><span id="more"></span>

<ul>
<li>法国数学家傅里叶在 <code>《热分析理论》</code>中指出：任何周期函数都可以分解为不同频率的正弦或余弦级数的形式，即傅里叶级数。该方法从本质上完成了空间信息到频域信息的变换，通过变换将空间域信号处理问题转换成频域信号处理问题。</li>
<li>傅里叶变换可以将任何周期函数，分解为不同频率的信号成分。</li>
<li>频域变换为信号处理提供了不同的思路，有时在空间域无法处理的问题，通过频域变换却非常容易。</li>
<li>为了更加有效的对数字图像进行处理，常常需要将原始图像，以某种方式变换到另一个空间，并利用图像在变换空间中特有的性质，对图像信息进行加工，然后再转换回图像空间，就可以得到所需的效果。</li>
<li>图像变换是双向的，一般将从图像空间转换到其他空间的操作称为正变换，由其他空间转换到图像空间称为逆变换。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture1.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>傅里叶变换将图像看作二维信号，其水平方向和垂直方向作为二维空间的坐标轴，将图像本身所在的域称为空间域。</li>
<li>图像灰度值随空间坐标变换的节奏可以通过频率度量，称为空间频率或者频域。</li>
<li>针对数字图像的傅里叶变换是将原始图像通过傅里叶变换转换到频域，然后再频域中对图像进行处理的方法。</li>
<li>基于傅里叶变换的数字图像频域处理过程：首先通过正向傅里叶变换将原始图像从空间域转换到频域，然后使用频域滤波器将某些频率过滤，保留某些特定频率，最后使用傅里叶逆变换将滤波后的频域图像重新转换到空间域，得到处理后的图像。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture2.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>相对于空间域图像处理，频域图像处理有以下优点。<br>① 频域图像处理可以通过频域成分的特殊性质，完成一些空间域图像处理难以完成的任务。<br>② 频域图像处理更有利于图像处理的解释，可以对滤波过程中产生的某些效果做出比较直观的解释。<br>③ 频域滤波器可以作为空间滤波器设计的指导，通过傅里叶逆变换可以将频域滤波器转换为空间域变换的操作。通过频域滤波做前期设计，然后在实施阶段，用空间域滤波实现。</li>
</ul>
<h2 id="1-傅里叶变换"><a href="#1-傅里叶变换" class="headerlink" title="1 傅里叶变换"></a>1 傅里叶变换</h2><ul>
<li>傅里叶变换是一种常见的正交数学变换，可以将一维信号或函数分解为具有不同频率、不同幅度的正弦信号或余弦信号的组合</li>
<li>傅里叶变换的核心贡献在于：如何求出每种正弦波或余弦波的比例或频率，给定每种正弦波或余弦波的频率可以恢复原始信号。</li>
<li>一种简单的傅里叶变换<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture3.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="1-1-一维傅里叶变换"><a href="#1-1-一维傅里叶变换" class="headerlink" title="1.1 一维傅里叶变换"></a>1.1 一维傅里叶变换</h3><ul>
<li>傅里叶变换中，一般要求要求函数 <code>f(x)</code>满足狄力克雷条件（在周期内存在有限个间断点）、有限极值条件、绝对可积条件<br>( $\int_{-∞}^{∞}|f(x)|dx&lt;+\infty$ )<br>只有满足这 3 个条件，函数的傅里叶变换才是存在的。</li>
<li>一个函数的傅里叶变换可以表示为<br>$F(u)&#x3D;\int_{-∞}^{0}f(x)e^{-j2 \pi ux}dx$<br>其对应的傅里叶逆变换表示为<br>$f(u)&#x3D;\int_{-∞}^{0}F(u)e^{-j2 \pi ux}du$<br>其中 j &#x3D; − 1 , u j&#x3D;\sqrt{-1},u j=−1 ,u 为频率分量</li>
<li>傅里叶变换中基函数的物理意义非常明确，每个基函数都是一个单频率谐波，对应的系数（又称频谱）表明了原函数在此基函数上投影的大小，或者也可以看作是原函数中此种频率谐波成分的比重。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show</span>(<span class="params">ori_func, sampling_period=<span class="number">5</span></span>):</span><br><span class="line">    n = <span class="built_in">len</span>(ori_func)</span><br><span class="line">    interval = sampling_period / n</span><br><span class="line">    <span class="comment"># 绘制原始函数</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    plt.plot(np.arange(<span class="number">0</span>, sampling_period, interval), ori_func, <span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;时间&#x27;</span>), plt.ylabel(<span class="string">&#x27;振幅&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;原始信号&#x27;</span>)</span><br><span class="line">    <span class="comment"># 绘制变换后的函数</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    frequency = np.arange(n / <span class="number">2</span>) / (n * interval)</span><br><span class="line">    nfft = <span class="built_in">abs</span>(ft[<span class="built_in">range</span>(<span class="built_in">int</span>(n / <span class="number">2</span>))] / n)</span><br><span class="line">    plt.plot(frequency, nfft, <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;频率（Hz）&#x27;</span>), plt.ylabel(<span class="string">&#x27;频谱&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;傅里叶变换&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成频率为1，角速度为2*pi的正弦波</span></span><br><span class="line">time = np.arange(<span class="number">0</span>, <span class="number">5</span>, <span class="number">.005</span>)</span><br><span class="line">x = np.sin(<span class="number">2</span> * np.pi * <span class="number">1</span> * time)</span><br><span class="line">y = np.fft.fft(x)</span><br><span class="line">show(x, y)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>单一正弦波傅里叶变换结果<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture4.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="1-2-二维傅里叶变换"><a href="#1-2-二维傅里叶变换" class="headerlink" title="1.2 二维傅里叶变换"></a>1.2 二维傅里叶变换</h3><ul>
<li>二维傅里叶变换本质上是将一维傅里叶变换情形向二维进行简单扩展。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture5.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>对应二维傅里叶变换的逆变换可以表示为：<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture6.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img = data.camera()</span><br><span class="line"><span class="comment">#img = data.checkerboard()</span></span><br><span class="line"><span class="comment"># 快速傅里叶变换得到频率分布</span></span><br><span class="line">f = np.fft.fft2(img)</span><br><span class="line"><span class="comment"># 默认结果中心点的位置是左上角，转移到中间位置</span></span><br><span class="line">fshift = np.fft.fftshift(f)</span><br><span class="line"><span class="comment"># fft结果是复数，求绝对值结果才是振幅</span></span><br><span class="line">fimg = np.log(np.<span class="built_in">abs</span>(fshift))</span><br><span class="line"><span class="comment"># 展示结果</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>), plt.imshow(img, <span class="string">&#x27;gray&#x27;</span>), plt.title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), plt.imshow(fimg, <span class="string">&#x27;gray&#x27;</span>), plt.title(<span class="string">&#x27;傅里叶频谱&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture7.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<ul>
<li>棋盘图像对应的傅里叶变换<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture8.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>图像经傅里叶变换后，直流分量与图像均值成正比，高频分量则表明了图像中目标边缘的强度及方向。</li>
</ul>
<h2 id="2-傅里叶变换的性质"><a href="#2-傅里叶变换的性质" class="headerlink" title="2 傅里叶变换的性质"></a>2 傅里叶变换的性质</h2><h3 id="2-1-傅里叶变换的基本性质"><a href="#2-1-傅里叶变换的基本性质" class="headerlink" title="2.1 傅里叶变换的基本性质"></a>2.1 傅里叶变换的基本性质</h3><p>① 线性特性。傅里叶变换的线性特性可以表示为：若 <code>f1(t)↔F1(Ω)</code>，<code>f2(t)↔F2(Ω)</code>，则　<code>af1(t)+bf2(t)↔aF1(Ω)+bF2(Ω)</code>。其中 <code>a</code>、<code>b</code>为任意常数，利用傅里叶变换的线性特性，可以将待求信号分解为若干基本信号之和。② 时延特性。时延（移位）特性说明波形在时间轴上时延，并不会改变信号幅度，仅使信号增加 <code>-Ωt0</code>线性相位。</p>
<ul>
<li>时延移位对傅里叶频谱的影响。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture9.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<p>③ 频移特性。频移（调制）特性表明信号在时域中与复因子相乘，则在频域中将使整个频谱搬移 <code>Ω0</code>。④ 尺度变换。尺度特性说明，信号在时域中压缩，在频域中扩展；反之，信号在时域中扩展，在频域中就一定压缩，即信号的脉宽与频宽成反比。一般来说，时宽有限的信号，其频宽无限，反之亦然。</p>
<ul>
<li>针对门限函数的尺度变换及其傅里叶变换结果。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture10.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><br>⑤ 时域微分特性。<br>⑥ 频域微分特性。<br>⑦ 对称性。<br>⑧ 时域卷积定理。<br>⑨ 频域卷积定理。</li>
</ul>
<h3 id="2-2-二维傅里叶变换的性质"><a href="#2-2-二维傅里叶变换的性质" class="headerlink" title="2.2 二维傅里叶变换的性质"></a>2.2 二维傅里叶变换的性质</h3><p>相较于一维傅里叶变换，二维傅里叶变换还具有可分离性，平移特性，旋转特性等。<br>① 可分离性。<br>二维离散傅里叶变换（DFT），可视为由沿着 x、y 方向的两个一维傅里叶变换所构成。这一性质可有效降低二维傅里叶变换的计算复杂性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img_rgb = data.coffee()</span><br><span class="line">img = color.rgb2gray(img_rgb)</span><br><span class="line"><span class="comment"># 在X方向实现傅里叶变换</span></span><br><span class="line">m, n = img.shape</span><br><span class="line">fx = img</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    fx[:, x] = np.fft.fft(img[:, x])</span><br><span class="line"><span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">    fx[y, :] = np.fft.fft(img[y, :])</span><br><span class="line"><span class="comment"># 默认结果中心点位于左上角，转移到中间位置</span></span><br><span class="line">fshift = np.fft.fftshift(fx)</span><br><span class="line"><span class="comment"># fft结果是复数，求绝对值结果才是振幅</span></span><br><span class="line">fimg = np.log(np.<span class="built_in">abs</span>(fshift))</span><br><span class="line"><span class="comment"># 展示结果</span></span><br><span class="line">plt.subplot(<span class="number">121</span>), plt.imshow(img_rgb, <span class="string">&#x27;gray&#x27;</span>), plt.title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">122</span>), plt.imshow(fimg, <span class="string">&#x27;gray&#x27;</span>), plt.title(<span class="string">&#x27;两次一维傅里叶变换的图像&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture11.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><br>② 平移特性。<br><code>f(x,y)</code>在空间平移了，相当于把傅里叶变换与一个指数相乘。<code>f(x,y)</code>在空间与一个指数项相乘，相当于平移其傅里叶变换。<br>③ 旋转特性。<br>对 <code>f(x,y)</code>旋转一定角度，相当于将其傅里叶变换 <code>F(u,v)</code>旋转一定角度。</p>
<h2 id="3-快速傅里叶变换"><a href="#3-快速傅里叶变换" class="headerlink" title="3 快速傅里叶变换"></a>3 快速傅里叶变换</h2><ul>
<li>离散傅里叶变换已成为数字信号处理的重要工具，然而其计算量大，运算时间长，使用不够广泛。</li>
<li>快速算法大大提高了其运算速度，在某些应用场合已经可以做实时处理，并且应用在控制系统中。</li>
<li>快速傅里叶变换不是一种新的变换，是离散傅里叶变换的一种算法，是在分析离散傅里叶变换多余运算的基础上，消除这些重复工作的思想指导下得到的。</li>
</ul>
<h3 id="3-1-快速傅里叶变换的原理"><a href="#3-1-快速傅里叶变换的原理" class="headerlink" title="3.1 快速傅里叶变换的原理"></a>3.1 快速傅里叶变换的原理</h3><ul>
<li>离散傅里叶变换的计算时间主要由乘法决定，分解后所需的乘法次数大大减少。</li>
<li>利用周期性和分解运算，从而减少乘法运算次数是实现快速运算的关键。</li>
</ul>
<h3 id="3-2-快速傅里叶变换的实现"><a href="#3-2-快速傅里叶变换的实现" class="headerlink" title="3.2 快速傅里叶变换的实现"></a>3.2 快速傅里叶变换的实现</h3><ul>
<li>快速傅里叶变换的基本思想：快速傅里叶变换（FFT）基于逐次倍乘法（Successive Doubling Method）</li>
<li>这个方法的主要思想是利用傅里叶变换（基底）的性质，将 2M 个数据的傅里叶变换转化为 2 组 M 个数据的傅里叶变换。这样，原来 <code>4*M*M</code>的运算量就降低到 <code>2*M*M</code>的运算量了。</li>
<li>这样就可以将原来比较复杂的傅里叶运算，分解为两个计算较简单的傅里叶运算。且还可以继续分解，如此循环推到下去，直到最后剩下若干组两个点对。</li>
</ul>
<h2 id="4-图像的频域滤波"><a href="#4-图像的频域滤波" class="headerlink" title="4 图像的频域滤波"></a>4 图像的频域滤波</h2><ul>
<li>图像变换是对图像信息进行变换，使能量保持但重新分配，以利于加工处理，滤除噪声等不必要的信息，加强、提取感兴趣的部分或特征。</li>
<li>傅里叶变换在图像分析、滤波、增强、压缩等处理中有非常重要的应用。</li>
<li>假定原图像 <code>f(x,y)</code>经傅里叶变换为 <code>F(u,v)</code>，频域增强就是选择合适的滤波器函数 <code>H(u,v)</code>对 <code>F(u,v)</code>的频谱成分进行调整，然后经傅里叶逆变换得到增强的图像 <code>g(x,y)</code><br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture12.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>可以选择合适的频域传递函数 <code>H(u,v)</code>突出 f(x,y)某方面的特征，从而得到需要的图像 <code>g(x,y)</code>.例如，利用传递函数突出高频分量，以增强图像的边缘信息，即高通滤波。如果突出低频分量，就可以使图像显得比较平滑，即低通滤波。</li>
<li>频域滤波的基本步骤如下。（1）对原始原图像 <code>f(x,y)</code>进行傅里叶变换得到 <code>F(u,v)</code>（2）将 <code>F(u,v)</code>与传递函数 <code>H(u,v)</code>进行卷积运算得到 <code>G(u,v)</code>（3）将 <code>G(u,v)</code>进行傅里叶逆变换得到增强图像 <code>g(x,y)</code></li>
<li>频域滤波的核心在于如何确定传递函数。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture13.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="4-1-低通滤波"><a href="#4-1-低通滤波" class="headerlink" title="4.1 低通滤波"></a>4.1 低通滤波</h3><ul>
<li>图像从空间域变换到频域后，其低频分量对应图像中灰度值变化比较缓慢的区域，高频分量表征物体的边缘和随机噪声等信息。</li>
<li>低频滤波是指保留低频分量，而通过滤波器函数 H(u,v)减弱或抑制高频分量，在频域进行滤波。</li>
<li>低通滤波与空间域中的平滑滤波器一样，可以消除图像中的随机噪声，减弱边缘效应，起到平滑图像的作用。</li>
</ul>
<h4 id="第一种-理想低通滤波器"><a href="#第一种-理想低通滤波器" class="headerlink" title="第一种 理想低通滤波器"></a>第一种 理想低通滤波器</h4><ul>
<li>二维理想低通滤波器的传递函数如下。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture14.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>理想低通滤波器及其图像<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture15.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">D = <span class="number">10</span></span><br><span class="line">new_img = data.coffee()</span><br><span class="line">new_img = color.rgb2gray(new_img)</span><br><span class="line"><span class="comment"># 傅里叶变换</span></span><br><span class="line">f1 = np.fft.fft2(new_img)</span><br><span class="line"><span class="comment"># 使用np.fft.fftshift()函数实现平移，让直流分量输出图像的重心</span></span><br><span class="line">f1_shift = np.fft.fftshift(f1)</span><br><span class="line"><span class="comment"># 实现理想低通滤波器</span></span><br><span class="line">rows, cols = new_img.shape</span><br><span class="line">crow, ccol = <span class="built_in">int</span>(rows / <span class="number">2</span>), <span class="built_in">int</span>(cols / <span class="number">2</span>)  <span class="comment"># 计算频谱中心</span></span><br><span class="line">mask = np.zeros((rows, cols), dtype=<span class="string">&#x27;uint8&#x27;</span>)  <span class="comment"># 生成rows行，从cols列的矩阵，数据格式为uint8</span></span><br><span class="line"><span class="comment"># 将距离频谱中心距离小于D的低通信息部分设置为1，属于低通滤波</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">        <span class="keyword">if</span> np.sqrt(i * i + j * j) &lt;= D:</span><br><span class="line">            mask[crow - D:crow + D, ccol - D:ccol + D] = <span class="number">1</span></span><br><span class="line">f1_shift = f1_shift * mask</span><br><span class="line"><span class="comment"># 傅里叶逆变换</span></span><br><span class="line">f_ishift = np.fft.ifftshift(f1_shift)</span><br><span class="line">img_back = np.fft.ifft2(f_ishift)</span><br><span class="line">img_back = np.<span class="built_in">abs</span>(img_back)</span><br><span class="line">img_back = (img_back - np.amin(img_back)) / (np.amax(img_back) - np.amin(img_back))</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.imshow(new_img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.imshow(img_back, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;滤波后的图像&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>二维图像的理想低通滤波<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture16.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h4 id="第二种-Butterworth-低通滤波器"><a href="#第二种-Butterworth-低通滤波器" class="headerlink" title="第二种 Butterworth 低通滤波器"></a>第二种 Butterworth 低通滤波器</h4><ul>
<li>Butterworth 低通滤波器的传递函数为</li>
<li><img src="https://img-blog.csdnimg.cn/20210205134544186.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>。</li>
<li><code>D0</code>为截止频率，<code>n</code>为函数的阶。一般取使 <code>H(u,v)</code>最大值下降到最大值的一半时的 <code>D(u,v)</code>为截止频率 <code>D0</code>。</li>
<li>Butterworth 低通滤波器的截面<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture18.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>与理想低通滤波器相比，高低频之间过度较为平滑，用此滤波器后的输出图像振铃现象不明显。</li>
<li>n&#x3D;1 时，过度最平滑，即尾部包含大量的高频成分，所以一阶 Butterworth 低通滤波器没有振铃现象；但随着 n 的增加，振铃现象会越来越明显。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img = data.coffee()</span><br><span class="line">img = color.rgb2gray(img)</span><br><span class="line">f = np.fft.fft2(img)</span><br><span class="line">fshift = np.fft.fftshift(f)</span><br><span class="line"><span class="comment"># 取绝对值后将复数变化为实数</span></span><br><span class="line"><span class="comment"># 取对数的目的是将数据变换到0~255</span></span><br><span class="line">s1 = np.log(np.<span class="built_in">abs</span>(fshift))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ButterworthPassFilter</span>(<span class="params">image, d, n</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Butterworth低通滤波器</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    f = np.fft.fft2(image)</span><br><span class="line">    fshift = np.fft.fftshift(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_transform_matrix</span>(<span class="params">d</span>):</span><br><span class="line">        transform_matrix = np.zeros(image.shape)</span><br><span class="line">        center_point = <span class="built_in">tuple</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x - <span class="number">1</span>) / <span class="number">2</span>, s1.shape))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(transform_matrix.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(transform_matrix.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">def</span> <span class="title function_">cal_distance</span>(<span class="params">pa, pb</span>):</span><br><span class="line">                    <span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line">                    dis = sqrt((pa[<span class="number">0</span>] - pb[<span class="number">0</span>]) ** <span class="number">2</span> + (pa[<span class="number">1</span>] - pb[<span class="number">1</span>]) ** <span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">return</span> dis</span><br><span class="line"></span><br><span class="line">                dis = cal_distance(center_point, (i, j))</span><br><span class="line">                transform_matrix[i, j] = <span class="number">1</span> / (<span class="number">1</span> + (dis / d) ** (<span class="number">2</span> * n))</span><br><span class="line">        <span class="keyword">return</span> transform_matrix</span><br><span class="line"></span><br><span class="line">    d_matrix = make_transform_matrix(d)</span><br><span class="line">    new_img = np.<span class="built_in">abs</span>(np.fft.ifft2(np.fft.ifftshift(fshift * d_matrix)))</span><br><span class="line">    <span class="keyword">return</span> new_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=100 n=1&#x27;</span>)</span><br><span class="line">butter_100_1 = ButterworthPassFilter(img, <span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(butter_100_1, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=30 n=1&#x27;</span>)</span><br><span class="line">butter_30_1 = ButterworthPassFilter(img, <span class="number">30</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(butter_30_1, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=30 n=5&#x27;</span>)</span><br><span class="line">butter_30_5 = ButterworthPassFilter(img, <span class="number">30</span>, <span class="number">5</span>)</span><br><span class="line">plt.imshow(butter_30_5, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture19.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="4-2-高通滤波"><a href="#4-2-高通滤波" class="headerlink" title="4.2 高通滤波"></a>4.2 高通滤波</h3><ul>
<li>图像的边缘、细节主要在高频，图像模糊的原因是高频成分较弱。</li>
<li>为了消除模糊，突出边缘，可以采取高通滤波的方法，使低频分量得到抑制，从而达到增强高频分量，使图像的边缘或线条变得清晰，实现图像的锐化。</li>
</ul>
<h4 id="第一种-理想高通滤波"><a href="#第一种-理想高通滤波" class="headerlink" title="第一种 理想高通滤波"></a>第一种 理想高通滤波</h4><ul>
<li>理想高通滤波器的形状与低通滤波器的形状正好相反。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture20.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>理想高通滤波器及其图像<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture21.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">D = <span class="number">10</span></span><br><span class="line">new_img = data.coffee()</span><br><span class="line">new_img = color.rgb2gray(new_img)</span><br><span class="line"><span class="comment"># numpy 中的傅里叶变换</span></span><br><span class="line">f1 = np.fft.fft2(new_img)</span><br><span class="line">f1_shift = np.fft.fftshift(f1)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">实现理想高通滤波器 start</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">rows, cols = new_img.shape</span><br><span class="line"><span class="comment"># 计算频谱中心</span></span><br><span class="line">crow, ccol = <span class="built_in">int</span>(rows / <span class="number">2</span>), <span class="built_in">int</span>(cols / <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 生成rows，cols列的矩阵，数据格式为uint8</span></span><br><span class="line">mask = np.zeros((rows, cols), dtype=<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line"><span class="comment"># 将距离频谱中心距离小于D的低通信息部分设置为1，属于低通滤波</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">        <span class="keyword">if</span> np.sqrt(i * i + j * j) &lt;= D:</span><br><span class="line">            mask[crow - D:crow + D, ccol - D:ccol + D] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">mask = <span class="number">1</span> - mask</span><br><span class="line">f1_shift = f1_shift * mask</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">实现理想高通滤波器 end</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 傅里叶逆变换</span></span><br><span class="line">f_ishift = np.fft.ifftshift(f1_shift)</span><br><span class="line">img_back = np.fft.ifft2(f_ishift)</span><br><span class="line">img_back = np.<span class="built_in">abs</span>(img_back)</span><br><span class="line">img_back = (img_back - np.amin(img_back)) / (np.amax(img_back) - np.amin(img_back))</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(new_img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(img_back, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;过滤后的图像&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>二维图像的理想高通滤波<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture22.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h4 id="第二种-Butterworth-高通滤波"><a href="#第二种-Butterworth-高通滤波" class="headerlink" title="第二种 Butterworth 高通滤波"></a>第二种 Butterworth 高通滤波</h4><ul>
<li>Butterworth 高通滤波器的形状与 Butterworth 低通滤波器的形状相反，因为高低频率间平滑过渡，因此振铃现象不明显。<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture23.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img = data.coffee()</span><br><span class="line">img = color.rgb2gray(img)</span><br><span class="line">f = np.fft.fft2(img)</span><br><span class="line">fshift = np.fft.fftshift(f)</span><br><span class="line"><span class="comment"># 取绝对值后将复数变化为实数</span></span><br><span class="line"><span class="comment"># 取对数的目的是将数据变换到0~255</span></span><br><span class="line">s1 = np.log(np.<span class="built_in">abs</span>(fshift))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ButterworthPassFilter</span>(<span class="params">image, d, n</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Butterworth 高通滤波器</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    f = np.fft.fft2(image)</span><br><span class="line">    fshift = np.fft.fftshift(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_transform_matrix</span>(<span class="params">d</span>):</span><br><span class="line">        transform_matrix = np.zeros(image.shape)</span><br><span class="line">        center_point = <span class="built_in">tuple</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x - <span class="number">1</span>) / <span class="number">2</span>, s1.shape))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(transform_matrix.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(transform_matrix.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">def</span> <span class="title function_">cal_distance</span>(<span class="params">pa, pb</span>):</span><br><span class="line">                    <span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line">                    dis = sqrt((pa[<span class="number">0</span>] - pb[<span class="number">0</span>]) ** <span class="number">2</span> + (pa[<span class="number">1</span>] - pb[<span class="number">1</span>]) ** <span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">return</span> dis</span><br><span class="line"></span><br><span class="line">                dis = cal_distance(center_point, (i, j))</span><br><span class="line">                transform_matrix[i, j] = <span class="number">1</span> / (<span class="number">1</span> + (dis / d) ** (<span class="number">2</span> * n))</span><br><span class="line">        <span class="keyword">return</span> transform_matrix</span><br><span class="line"></span><br><span class="line">    d_matrix = make_transform_matrix(d)</span><br><span class="line">    d_matrix = <span class="number">1</span> - d_matrix</span><br><span class="line">    new_img = np.<span class="built_in">abs</span>(np.fft.ifft2(np.fft.ifftshift(fshift * d_matrix)))</span><br><span class="line">    <span class="keyword">return</span> new_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=100 n=1&#x27;</span>)</span><br><span class="line">butter_100_1 = ButterworthPassFilter(img, <span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(butter_100_1, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=30 n=1&#x27;</span>)</span><br><span class="line">butter_30_1 = ButterworthPassFilter(img, <span class="number">30</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(butter_30_1, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=30 n=5&#x27;</span>)</span><br><span class="line">butter_30_5 = ButterworthPassFilter(img, <span class="number">30</span>, <span class="number">5</span>)</span><br><span class="line">plt.imshow(butter_30_5, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture24.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h4 id="第三种-高频增强滤波器"><a href="#第三种-高频增强滤波器" class="headerlink" title="第三种 高频增强滤波器"></a>第三种 高频增强滤波器</h4><ul>
<li>高频滤波将低频分量滤掉，导致增强图像中的边缘得到加强，但平坦区域灰度很暗，接近黑色。</li>
<li>高频增强滤波器对频域里的高通滤波器的转移函数加一个常数，将一些低频分量加回去，保持光滑区域的灰度，又改善边缘区域的对比度。</li>
<li>高频增强转移函数为 <code>He(u,v)</code>=<code>k*H(u,v)</code>+<code>c</code></li>
<li>这样就可以做到在原始图像的基础上叠加一些高频成分，既保留了原图的灰度层次，又锐化了边缘</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img = data.coffee()</span><br><span class="line">img = color.rgb2gray(img)</span><br><span class="line">f = np.fft.fft2(img)</span><br><span class="line">fshift = np.fft.fftshift(f)</span><br><span class="line"><span class="comment"># 取绝对值后将复数变化为实数</span></span><br><span class="line"><span class="comment"># 取对数的目的是将数据变换到0~255</span></span><br><span class="line">s1 = np.log(np.<span class="built_in">abs</span>(fshift))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ButterworthPassFilter</span>(<span class="params">image, d, n</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Butterworth 高通滤波器</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    f = np.fft.fft2(image)</span><br><span class="line">    fshift = np.fft.fftshift(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_transform_matrix</span>(<span class="params">d</span>):</span><br><span class="line">        transform_matrix = np.zeros(image.shape)</span><br><span class="line">        center_point = <span class="built_in">tuple</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x - <span class="number">1</span>) / <span class="number">2</span>, s1.shape))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(transform_matrix.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(transform_matrix.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">def</span> <span class="title function_">cal_distance</span>(<span class="params">pa, pb</span>):</span><br><span class="line">                    <span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line">                    dis = sqrt((pa[<span class="number">0</span>] - pb[<span class="number">0</span>]) ** <span class="number">2</span> + (pa[<span class="number">1</span>] - pb[<span class="number">1</span>]) ** <span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">return</span> dis</span><br><span class="line"></span><br><span class="line">                dis = cal_distance(center_point, (i, j))</span><br><span class="line">                transform_matrix[i, j] = <span class="number">1</span> / (<span class="number">1</span> + (dis / d) ** (<span class="number">2</span> * n))</span><br><span class="line">        <span class="keyword">return</span> transform_matrix</span><br><span class="line"></span><br><span class="line">    d_matrix = make_transform_matrix(d)</span><br><span class="line">    d_matrix = d_matrix+<span class="number">0.5</span></span><br><span class="line">    new_img = np.<span class="built_in">abs</span>(np.fft.ifft2(np.fft.ifftshift(fshift * d_matrix)))</span><br><span class="line">    <span class="keyword">return</span> new_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=100 n=1&#x27;</span>)</span><br><span class="line">butter_100_1 = ButterworthPassFilter(img, <span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(butter_100_1, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=30 n=1&#x27;</span>)</span><br><span class="line">butter_30_1 = ButterworthPassFilter(img, <span class="number">30</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(butter_30_1, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Butter D=30 n=5&#x27;</span>)</span><br><span class="line">butter_30_5 = ButterworthPassFilter(img, <span class="number">30</span>, <span class="number">5</span>)</span><br><span class="line">plt.imshow(butter_30_5, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>二维图像的高频增强滤波结果<br><img src="/../img/post/Digitalimageprocessing-Frequencydomainfiltering/picture25.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
]]></content>
      <categories>
        <category>学习记录类</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>空间滤波</title>
    <url>/2021/06/12/Digitalimageprocessing-Spatialfiltering/</url>
    <content><![CDATA[<h1 id="空间滤波"><a href="#空间滤波" class="headerlink" title="空间滤波"></a>空间滤波</h1><span id="more"></span>

<ul>
<li>空间滤波是在图像平面本身上逐像素的移动空间模板，同时空间模板与其覆盖的图像像素灰度值按预定义的关系进行运算。模板也称空间滤波器、核、掩膜或窗口。</li>
<li>空间滤波器一般用于去除图像噪声或增强图像细节，突出感兴趣信息，抑制无效信息，改善人类的视觉效果，或是图像更适合于机器感知或分析。</li>
<li>空间滤波主要分为平滑处理和锐化处理两大类。</li>
<li>平滑处理主要用于处理图像中一些不重要的细节，并减小噪声。</li>
<li>锐化处理主要为了突出图像中的细节，增强图像边缘。</li>
<li>为了达到满意的图像增强效果，通常使用多种互补的滤波技术。</li>
</ul>
<h2 id="1-空间滤波基础"><a href="#1-空间滤波基础" class="headerlink" title="1 空间滤波基础"></a>1 空间滤波基础</h2><ul>
<li>空间域指的是图像平面本身，是相对于变换域而言的。</li>
<li>空间域的图像处理是图像本身不进行频域变换，以图像中的像素为基础对图像进行处理。</li>
<li>空间域的图像处理是在像素的领域进行操作，如空间域平滑处理是通过像素的领域平滑图像，空间域锐化处理是通过像素的领域锐化图像。</li>
<li>频域的图像处理首先将图像变换到变换域，然后在频域进行处理，处理之后将其变换到空间域。</li>
<li>频域处理主要包括 <code>低通滤波</code>和 <code>高通滤波</code>。</li>
<li>低通滤波可以使低频信号正常通过，而高于所设定的临界值的高频信号被阻隔或者减弱，可用于去除图像的噪声，相当于空间域的平滑处理。</li>
<li>高通滤波可以使高频信号正常通过，而低于所设定的临界值的低频信号被阻隔或者减弱，可增强图像边缘轮廓等高频信号，相当于空间域的锐化处理。</li>
<li>在频域处理中，滤波是指过滤一些频率分量，即通过一些频率分量，同时拒绝一些频率分量的通过。</li>
<li>频域滤波器主要包括低通滤波器和高通滤波器。</li>
<li>滤波也可用于空间域即空间域滤波，在空间域上直接对图像进行处理，实现类似频域的平滑或锐化处理。</li>
</ul>
<h3 id="1-1-空间滤波的机理"><a href="#1-1-空间滤波的机理" class="headerlink" title="1.1 空间滤波的机理"></a>1.1 空间滤波的机理</h3><ul>
<li>空间滤波的机理就是在待处理的图像上逐像素的移动模板，在每个像素点，滤波器的响应通过事先定义的计算。</li>
<li>若滤波器在图像像素上执行的是线性操作，则称为线性滤波器，否则称为非线性滤波器。</li>
<li>均值滤波器求解的是模板内像素灰度值的平均值，是典型的线性滤波器。</li>
<li>统计排序滤波器是通过比较给定邻域内的灰度值大小实现的。原始数据与滤波结果是一种逻辑关系，如最大值滤波器，最小值滤波器，中值滤波器都是典型的非线性滤波器。</li>
<li>3*3 模板的线性空间滤波器的机理<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture1.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<ul>
<li>矩阵进行线性空间滤波处理的代码如下。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color, io</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corre12d</span>(<span class="params">img, window</span>):</span><br><span class="line">    m = window.shape[<span class="number">0</span>]</span><br><span class="line">    n = window.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 边界通过0灰度值填充扩展</span></span><br><span class="line">    img_border = np.zeros((img.shape[<span class="number">0</span>] + m - <span class="number">1</span>, img.shape[<span class="number">1</span>] + n - <span class="number">1</span>))</span><br><span class="line">    img_border[(m - <span class="number">1</span>) // <span class="number">2</span>:(img.shape[<span class="number">0</span>] + (m - <span class="number">1</span>) // <span class="number">2</span>), (n - <span class="number">1</span>) // <span class="number">2</span>:(img.shape[<span class="number">1</span>] + (n - <span class="number">1</span>) // <span class="number">2</span>)] = img</span><br><span class="line">    img_result = np.zeros(img.shape)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img_result.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(img_result.shape[<span class="number">1</span>]):</span><br><span class="line">            temp = img_border[i:i + m, j:j + n]</span><br><span class="line">            img_result[i, j] = np.<span class="built_in">sum</span>(np.multiply(temp, window))</span><br><span class="line">    <span class="keyword">return</span> img_border, img_result</span><br><span class="line"></span><br><span class="line"><span class="comment"># window表示滤波模板，img表示原始矩阵</span></span><br><span class="line">window = np.array([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>]])</span><br><span class="line">img = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                [<span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">                [<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># img_border表示边界填充后的矩阵，img_result表示空间滤波结果</span></span><br><span class="line">img_border, img_result = corre12d(img, window)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>矩阵的线性空间滤波过程<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture2.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="1-2-空间滤波器模板"><a href="#1-2-空间滤波器模板" class="headerlink" title="1.2 空间滤波器模板"></a>1.2 空间滤波器模板</h3><ul>
<li><code>m*n</code>的线性滤波器模板有 <code>m*n</code>个模板系数，这些系数决定了线性空间滤波器的功能。假设要实现 3x3 的平滑空间滤波器，较简单的方法是使得滤波器的系数均为 1&#x2F;9。</li>
<li>模板系数为 1&#x2F;9 的 3x3 线性空间滤波器模板如下：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[1/9, 1/9, 1/9]</span><br><span class="line">[1/9, 1/9, 1/9]</span><br><span class="line">[1/9, 1/9, 1/9]</span><br></pre></td></tr></table></figure>

<ul>
<li>模板系数为 1&#x2F;9 的 5x5 线性空间滤波器模板如下：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[1/25, 1/9, 1/25, 1/9, 1/25]</span><br><span class="line">[1/9, 1/9, 1/9, 1/9, 1/9]</span><br><span class="line">[1/25, 1/9, 1/25, 1/9, 1/25]</span><br><span class="line">[1/9, 1/9, 1/9, 1/9, 1/9]</span><br><span class="line">[1/25, 1/9, 1/25, 1/9, 1/25]</span><br></pre></td></tr></table></figure>

<h2 id="2-平滑处理"><a href="#2-平滑处理" class="headerlink" title="2 平滑处理"></a>2 平滑处理</h2><ul>
<li>平滑处理常用于模糊处理和降低噪声。</li>
<li>平滑滤波器使用给定邻域内像素的平均灰度值或逻辑运算值代替原始图像中像素的灰度值，这种处理降低了图像灰度的尖锐变化。</li>
<li>图像边缘也是由图像灰度尖锐变化带来的特性，因此平滑空间滤波器有边缘模糊化的负面效应。</li>
</ul>
<h3 id="2-1-平滑线性空间滤波器"><a href="#2-1-平滑线性空间滤波器" class="headerlink" title="2.1 平滑线性空间滤波器"></a>2.1 平滑线性空间滤波器</h3><ul>
<li>平滑线性空间滤波器的输出是给定邻域内的像素灰度值的简单平均值或加权平均值。</li>
<li>平滑线性空间滤波器有时也称均值滤波器，均值滤波器的一个重要应用就是降低图像中的噪声，还有去除图像的不相关细节，使不相关细节与背景糅合在一起，从而使感兴趣目标更加容易检测，此时模板的大小与不相关细节的尺寸有关。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> signal</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, io</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义二维灰度图像的空间滤波函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">correl2d</span>(<span class="params">img, window</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用滤波器实现图像的空间相关</span></span><br><span class="line"><span class="string">    mode=&#x27;same&#x27; 表示输出尺寸等于输入尺寸</span></span><br><span class="line"><span class="string">    boundary=‘fill’ 表示滤波前，用常量值填充原始图像的边缘，默认常量值为0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param img:</span></span><br><span class="line"><span class="string">    :param window:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    s = signal.correlate2d(img, window, mode=<span class="string">&#x27;same&#x27;</span>, boundary=<span class="string">&#x27;fill&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> s.astype(np.uint8)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img = data.camera()</span><br><span class="line"><span class="comment"># 3*3 盒状滤波模板</span></span><br><span class="line">window1 = np.ones((<span class="number">3</span>, <span class="number">3</span>)) / (<span class="number">3</span> ** <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 5*5 盒状滤波模板</span></span><br><span class="line">window2 = np.ones((<span class="number">5</span>, <span class="number">5</span>)) / (<span class="number">5</span> ** <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 9*9 盒状滤波模板</span></span><br><span class="line">window3 = np.ones((<span class="number">9</span>, <span class="number">9</span>)) / (<span class="number">9</span> ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成滤波结果</span></span><br><span class="line">img1 = correl2d(img, window1)</span><br><span class="line">img2 = correl2d(img, window2)</span><br><span class="line">img3 = correl2d(img, window3)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;3*3&#x27;</span>)</span><br><span class="line">plt.imshow(img1, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;5*5&#x27;</span>)</span><br><span class="line">plt.imshow(img2, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;9*9&#x27;</span>)</span><br><span class="line">plt.imshow(img3, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>盒状滤波结果比原始图像的湖面水波更加平滑，并且远处风景更加模糊，同时摄影师也被模糊了<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture3.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>高斯平滑滤波是一种应用较广泛的平滑空间滤波方法之一</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> signal</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, io</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义二维灰度图像的空间滤波函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">correl2d</span>(<span class="params">img, window</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用滤波器实现图像的空间相关</span></span><br><span class="line"><span class="string">    mode=&#x27;same&#x27; 表示输出尺寸等于输入尺寸</span></span><br><span class="line"><span class="string">    boundary=‘fill’ 表示滤波前，用常量值填充原始图像的边缘，默认常量值为0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param img:</span></span><br><span class="line"><span class="string">    :param window:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    s = signal.correlate2d(img, window, mode=<span class="string">&#x27;same&#x27;</span>, boundary=<span class="string">&#x27;fill&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> s.astype(np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义二维高斯函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gauss</span>(<span class="params">i, j, sigma</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">2</span> * math.pi * sigma ** <span class="number">2</span>) * math.exp(-(i ** <span class="number">2</span> + j ** <span class="number">2</span>) / (<span class="number">2</span> * sigma ** <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义radius*radius的高斯平滑模板</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gauss_window</span>(<span class="params">radius, sigma</span>):</span><br><span class="line">    window = np.zeros((radius * <span class="number">2</span> + <span class="number">1</span>, radius * <span class="number">2</span> + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(-radius, radius + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-radius, radius + <span class="number">1</span>):</span><br><span class="line">            window[i + radius][j + radius] = gauss(i, j, sigma)</span><br><span class="line">    <span class="keyword">return</span> window / np.<span class="built_in">sum</span>(window)</span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img = data.camera()</span><br><span class="line"><span class="comment"># 3*3 高斯平滑滤波模板</span></span><br><span class="line">window1 = gauss_window(<span class="number">3</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5*5 高斯平滑滤波模板</span></span><br><span class="line">window2 = gauss_window(<span class="number">5</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 9*9 高斯平滑滤波模板</span></span><br><span class="line">window3 = gauss_window(<span class="number">9</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成滤波结果</span></span><br><span class="line">img1 = correl2d(img, window1)</span><br><span class="line">img2 = correl2d(img, window2)</span><br><span class="line">img3 = correl2d(img, window3)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;3*3&#x27;</span>)</span><br><span class="line">plt.imshow(img1, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;5*5&#x27;</span>)</span><br><span class="line">plt.imshow(img2, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;9*9&#x27;</span>)</span><br><span class="line">plt.imshow(img3, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>使用相同尺寸的模板，高斯滤波后图像被平滑的程度较低。</li>
<li>高斯滤波的输出是邻域像素的加权，同时距离中心越近的像素权重越大。</li>
<li>与盒状滤波相比，高斯滤波的平滑效果更柔和，图像中感兴趣目标的细节保留更好。<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture4.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="2-2-统计排序滤波器"><a href="#2-2-统计排序滤波器" class="headerlink" title="2.2 统计排序滤波器"></a>2.2 统计排序滤波器</h3><ul>
<li>统计排序滤波器是典型的非线性平滑滤波器。首先对模板覆盖的灰度值进行排序，选择有代表性的灰度值，作为统计排序滤波器的响应。</li>
<li>典型的统计排序滤波器包括最大值滤波器、中值滤波器、最小值滤波器。</li>
<li>最大值滤波器用像素邻域内的最大值代替该像素的灰度值，主要用于寻找亮点。</li>
<li>中值滤波器用像素邻域内的中值代替该像素的灰度值，主要用于降噪。</li>
<li>最小值滤波器用像素邻域内的最小值代替该像素的灰度值，主要用于寻找最暗点。</li>
<li>对于一定类型的随机噪声，中值滤波器的降噪效果较好，比相同尺寸的均值滤波器模糊程度明显要低。</li>
<li>中值滤波器对处理脉冲噪声非常有效，因为中值滤波器取中值作为滤波结果，可以很好的去除滤波器覆盖的邻域中的一些黑点和白点。</li>
<li>中值滤波器使图像中突出的亮点或暗点更像周围的值，以消除孤立的亮点或暗点，从而实现对图像的平滑。</li>
<li>为观察中值滤波的降噪效果，首先对宇航员的图像加入脉冲噪声，然后使用 3*3 中值滤波器对图像进行中值滤波。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> util, data</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = data.astronaut()[:, :, <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 对图像加入脉冲噪声</span></span><br><span class="line">noise_img = util.random_noise(img, mode=<span class="string">&#x27;s&amp;p&#x27;</span>, seed=<span class="literal">None</span>, clip=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 中值滤波</span></span><br><span class="line">n = <span class="number">3</span></span><br><span class="line">new_img = ndimage.median_filter(noise_img, (n, n))</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示原始图像</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(noise_img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示加噪图像</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(new_img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示去噪图像</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>显示原始图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture5.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>显示加噪图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture6.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>显示去噪图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture7.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>对 RGB 图像的空间滤波，相当于分别对 3 个通道的图像进行空间滤波。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> util, data</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img = data.astronaut()</span><br><span class="line"></span><br><span class="line">noise_img = np.zeros(img.shape)</span><br><span class="line">new_img = np.zeros(img.shape)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    gray_img = img[:, :, i]</span><br><span class="line">    <span class="comment"># 对图像加入脉冲噪声</span></span><br><span class="line">    noise_img[:, :, i] = util.random_noise(gray_img, mode=<span class="string">&#x27;s&amp;p&#x27;</span>, seed=<span class="literal">None</span>, clip=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 中值滤波</span></span><br><span class="line">    n = <span class="number">3</span></span><br><span class="line">    new_img[:, :, i] = ndimage.median_filter(noise_img[:, :, i], (n, n))</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示原始图像</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(noise_img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示加噪图像</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(new_img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示去噪图像</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>原始图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture8.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>加噪图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture9.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>去噪图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture10.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>最大值滤波对于发现图像最亮点非常有效，可有效降低胡椒噪声</li>
<li>最小值滤波对于发现图像最暗点非常有效，可有效降低盐粒噪声</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> util, data</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img = data.astronaut()[:, :, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对图像加入胡椒噪声</span></span><br><span class="line">pepper_img = util.random_noise(img, mode=<span class="string">&#x27;pepper&#x27;</span>, seed=<span class="literal">None</span>, clip=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 对图像加入盐粒噪声</span></span><br><span class="line">salt_img = util.random_noise(img, mode=<span class="string">&#x27;salt&#x27;</span>, seed=<span class="literal">None</span>, clip=<span class="literal">True</span>)</span><br><span class="line">n = <span class="number">3</span></span><br><span class="line"><span class="comment"># 最大值滤波</span></span><br><span class="line">max_img = ndimage.maximum_filter(pepper_img, (n, n))</span><br><span class="line"><span class="comment"># 最小值滤波</span></span><br><span class="line">min_img = ndimage.minimum_filter(salt_img, (n, n))</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示原始图像</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(pepper_img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示加胡椒噪声图像</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(salt_img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示加盐粒噪声图像</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(max_img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示最大值滤波图像</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(min_img, cmap=<span class="string">&#x27;gray&#x27;</span>)  <span class="comment"># 显示最小值滤波图像</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>显示加胡椒噪声图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture11.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>显示加盐粒噪声图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture12.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>显示最大值滤波图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture13.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>显示最小值滤波图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture14.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h2 id="3-锐化处理"><a href="#3-锐化处理" class="headerlink" title="3 锐化处理"></a>3 锐化处理</h2><ul>
<li>锐化处理的目的就是增强图像中目标的细节、边缘、轮廓和其他灰度突变，削弱了灰度变化缓慢的区域。</li>
<li>由于微分是对函数的局部变化率的一种描述，因此图像锐化算法的实现可基于空间微分。</li>
<li>图像平滑处理有边缘和细节模糊的负面效应。</li>
<li>图像平滑和图像锐化在逻辑上是相反的操作，可以使用原始图像减去平滑处理后的图像实现锐化处理，称为反锐化掩蔽。</li>
</ul>
<h3 id="3-1-一阶微分算子"><a href="#3-1-一阶微分算子" class="headerlink" title="3.1 一阶微分算子"></a>3.1 一阶微分算子</h3><ul>
<li>对于任何一阶微分的定义都必须满足以下两点：① 在灰度不变的区域，微分值为 0；② 在灰度变化的区域微分值非 0.由于处理的是离散的情况，微分用差分近似。</li>
<li>根据罗伯特的观点，边缘探测器应具有以下特性：产生的边缘应清晰；背景尽可能减少噪声；边缘强度尽可能接近人类的感知。求罗伯特边缘图像和梯度图像的代码如下。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, filters</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = data.camera()</span><br><span class="line"><span class="comment"># 罗伯特交叉梯度算子</span></span><br><span class="line">img_robert_pos = filters.roberts_pos_diag(img)</span><br><span class="line">img_robert_neg = filters.roberts_neg_diag(img)</span><br><span class="line">img_robert = filters.roberts(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示原始图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示罗伯特正对角线边缘图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示罗伯特负对角线边缘图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示罗伯特梯度图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>原始图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture15.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>罗伯特正对角线边缘图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture16.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>罗伯特负对角线边缘图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture17.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>罗伯特梯度图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture18.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>求索贝尔边缘图像和梯度图像的代码如下。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, filters</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = data.camera()</span><br><span class="line"><span class="comment"># Sobel算子</span></span><br><span class="line">img_sobel_h = filters.sobel_h(img)</span><br><span class="line">img_sobel_v = filters.sobel_v(img)</span><br><span class="line">img_sobel = filters.sobel(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示原始图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示水平Sobel边缘图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img_sobel_h, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示竖直Sobel边缘图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img_sobel_v, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示Sobel梯度图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img_sobel, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>水平 Sobel 边缘图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture19.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>竖直 Sobel 边缘图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture20.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>Sobel 梯度图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture21.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="3-2-二阶微分算子"><a href="#3-2-二阶微分算子" class="headerlink" title="3.2 二阶微分算子"></a>3.2 二阶微分算子</h3><ul>
<li>任意二阶微分的定义都必须满足以下两点：在灰度不变的区域微分值为 0；在灰度台阶或者斜坡的起点处微分值非 0；沿着斜坡的微分值为 0。</li>
<li>对原始图像使用拉普拉斯算子进行空间滤波可得到拉普拉斯图像，将拉普拉斯图像以一定的比例叠加到该原始图像，该比例系数的符号与拉普拉斯模板中心系数的符号一致，可对原始图像进行拉普拉斯锐化增强，代码如下。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, filters</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = data.camera()</span><br><span class="line"><span class="comment"># laplace</span></span><br><span class="line">img_laplace = filters.laplace(img, ksize=<span class="number">3</span>, mask=<span class="literal">None</span>)</span><br><span class="line">img_enhance = img + img_laplace</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示原始图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示拉普拉斯图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img_laplace, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示锐化增强图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img_enhance, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>原始图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture22.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>拉普拉斯图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture23.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>锐化增强图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture24.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>一阶微分更加突出图像的边缘，二阶微分对灰度变化强烈的地方更敏感，更加突出图像的纹理结构。</li>
</ul>
<h3 id="3-3-反锐化掩蔽"><a href="#3-3-反锐化掩蔽" class="headerlink" title="3.3 反锐化掩蔽"></a>3.3 反锐化掩蔽</h3><ul>
<li>图像平滑处理有边缘和细节模糊的负面效应，因此可用原始图像减去平滑处理后的图像实现锐化处理，称为反锐化掩蔽。</li>
<li>反锐化掩蔽分为 3 个步骤：首先通过平滑滤波得到模糊图像，然后从原始图像中减去差值图像，最后将差值图像叠加到原始图像中。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, filters</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> signal</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">correlate2d</span>(<span class="params">img, window</span>):</span><br><span class="line">    s = signal.correlate2d(img, window, mode=<span class="string">&#x27;same&#x27;</span>, boundary=<span class="string">&#x27;fill&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = data.camera()</span><br><span class="line"><span class="comment"># 3*3 盒状滤波模板</span></span><br><span class="line">window = np.ones((<span class="number">3</span>, <span class="number">3</span>)) / (<span class="number">3</span> ** <span class="number">2</span>)</span><br><span class="line">img_blur = correlate2d(img, window)</span><br><span class="line">img_edge = img - img_blur</span><br><span class="line">img_enhance = img + img_edge</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示原始图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示模糊图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img_blur, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示差值图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img_edge, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示锐化增强图像</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img_enhance, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>模糊图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture25.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>差值图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture26.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>锐化增强图像<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture27.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h2 id="4-混合空间增强"><a href="#4-混合空间增强" class="headerlink" title="4 混合空间增强"></a>4 混合空间增强</h2><ul>
<li>混合空间增强就是利用平滑滤波器、锐化滤波器、灰度拉伸等对图像进行处理，得到更为理想的显示效果。</li>
<li>由于人体全身骨骼扫描图像的灰度动态范围很窄，并且有很大的噪声内容，因此使用单一的滤波器对其进行增强效果一般。</li>
<li>首先使用拉普拉斯锐化方法突出图像中的小细节，然后使用索贝尔梯度处理方法突出图像的边缘，并使用平滑的梯度图像用于掩蔽拉普拉斯锐化增强图像，最后使用灰度幂律变换增强图像的灰度动态范围。</li>
<li>人体全身骨骼扫描图像的混合空间增强流程。<br><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture28.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>具体流程描述如下：第一步，对原始图像进行拉普拉斯锐化，得到拉普拉斯锐化图像；第二步，将原始图像与拉普拉斯锐化图像相加，得到拉普拉斯锐化图像增强；第三步，对原始图像进行索贝尔算子梯度处理，得到索贝尔图像；第四步，使用 5*5 均值滤波器对索贝尔图像进行平滑，得到平滑的索贝尔图像；第五步，将拉普拉斯锐化增强图像与平滑索贝尔图像相乘，得到掩蔽图像；第六步，将原始图像与隐蔽图像相加，得到锐化增强图像；第七步，对锐化增强图像进行灰度幂律变换，得到最终结果。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, filters, io</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像空间滤波函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">correlate2d</span>(<span class="params">img, window</span>):</span><br><span class="line">    m = window.shape[<span class="number">0</span>]</span><br><span class="line">    n = window.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 边界通过0灰度值填充扩展</span></span><br><span class="line">    img1 = np.zeros((img.shape[<span class="number">0</span>] + m - <span class="number">1</span>, img.shape[<span class="number">1</span>] + n - <span class="number">1</span>))</span><br><span class="line">    img1[(m - <span class="number">1</span>) // <span class="number">2</span>:(img.shape[<span class="number">0</span>] + (m - <span class="number">1</span>) // <span class="number">2</span>), (n - <span class="number">1</span>) // <span class="number">2</span>:(img.shape[<span class="number">1</span>] + (n - <span class="number">1</span>) // <span class="number">2</span>)] = img</span><br><span class="line">    img2 = np.zeros(img.shape)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(img2.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(img2.shape[<span class="number">1</span>]):</span><br><span class="line">            temp = img1[i:i + m, j:j + n]</span><br><span class="line">            img2[i, j] = np.<span class="built_in">sum</span>(np.multiply(temp, window))</span><br><span class="line">    <span class="keyword">return</span> img2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = io.imread(<span class="string">&#x27;boneScan.jpg&#x27;</span>, as_gray=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># img_laplace为原始图像经过拉普拉斯变换后的结果</span></span><br><span class="line">window = np.array([[-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>], [-<span class="number">1</span>, <span class="number">8</span>, -<span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">img_laplace = correlate2d(img, window)</span><br><span class="line">img_laplace = <span class="number">255</span> * (img_laplace - img_laplace.<span class="built_in">min</span>()) / (img_laplace.<span class="built_in">max</span>() - img_laplace.<span class="built_in">min</span>())</span><br><span class="line"><span class="comment"># 将img与img_laplace相加得到锐化增强图像</span></span><br><span class="line">img_laplace_enhance = img + img_laplace</span><br><span class="line"><span class="comment"># img_sobel为原始图像img经sobel处理的结果</span></span><br><span class="line">img_sobel = filters.sobel(img)</span><br><span class="line"><span class="comment"># 使用5*5均值滤波器平滑后的Sobel图像</span></span><br><span class="line">window_mean = np.ones((<span class="number">5</span>, <span class="number">5</span>)) / (<span class="number">5</span> ** <span class="number">2</span>)</span><br><span class="line">img_sobel_mean = correlate2d(img_sobel, window_mean)</span><br><span class="line"><span class="comment"># 将img_laplace_enhance 与 img_sobel_mean相乘得到锐化结果</span></span><br><span class="line">img_mask = img_laplace_enhance * img_sobel_mean</span><br><span class="line"><span class="comment"># 将原图像img与锐化图像img_mask相加得到锐化增强图像</span></span><br><span class="line">img_sharp_enhance = img + img_mask</span><br><span class="line"><span class="comment"># 对img_sharp_enhance进行灰度幂律变换得到最终结果</span></span><br><span class="line">img_enhance = img_sharp_enhance ** <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图像</span></span><br><span class="line">imgList = [img, img_laplace, img_laplace_enhance, img_sobel, img_sobel_mean, img_mask, img_sharp_enhance, img_enhance]</span><br><span class="line"><span class="keyword">for</span> grayImg <span class="keyword">in</span> imgList:</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.imshow(grayImg, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/Digitalimageprocessing-Spatialfiltering/picture29.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
]]></content>
      <categories>
        <category>学习记录类</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>图像特征提取</title>
    <url>/2021/06/12/DigitalImageProcessing-FeatureExtraction/</url>
    <content><![CDATA[<h1 id="图像特征提取"><a href="#图像特征提取" class="headerlink" title="图像特征提取"></a>图像特征提取</h1><span id="more"></span>

<ul>
<li>图像特征是指可以对图像的内容或特点，进行表征的一系列数学的集合，主要包括图像的自然特征（如亮度、色彩、纹理等）和图像人为特征（如图像频谱、图像直方图等）。</li>
<li>图像特征提取可以视为广义上的图像变换，即将图像从原始属性空间转化到特征属性空间。</li>
<li>图像特征提取过程是指对图像包含的信息进行处理和分析，并将其中不易受随机因素干扰的信息，作为图像的特征提取出来，进而实现将图像的原始特征，表示为一组具有明显的物理意义或统计意义的特征。</li>
<li>图像特征提取之后，通常还会伴随图像特征的选择。图像特征选择过程是去除冗余信息的过程，其具有提高识别精度、减少运算量、提高运算速度等作用。</li>
<li>良好的图像特征通常具有以下 3 个特征。<br><strong>① 代表性或可区分性</strong>图像特征应能够对该类别的图像进行高效表达。不同类别的对象之间的特征差异越大越好，以满足相应任务的要求。如在区分乒乓球和足球时，纹理特征就是一个不错的特征，因为足球一般有六边形纹理结构，而乒乓球没有。在进行图像分割时，图像中的边缘突变就是一个很好的特征，因为可以明确表示图像的内容发生了改变。<br><strong>② 稳定性</strong>同一类别图像的特征应该具有类似的特征值，以保证类别内图像的相似度大于类别间图像的相似度。如在区分成熟苹果和不成熟苹果时，颜色是一个比较好的特征，因为不成熟的苹果通常呈青色，而成熟的苹果通常呈黄色或者红色，尺寸大小这个特征在区分苹果成熟与否时，不是一个稳定的特征。<br><strong>③ 独立性</strong>图像特征应该彼此独立，尽量减少彼此的关联性，因为图像特征之间的关联性较强，会影响图像内容的较好表达。如苹果的直径和重量就属于关联性较强的两个特征，因为他们都可以反映苹果的大小，因此同时使用大小和重量这两个特征就会显得冗余。</li>
<li>图像特征提取可以分为底层特征提取和高层语义特征提取。高层语义特征提取通常关注语义层次的特征，如识别任务中的人类识别，图像分类等。底层特征提取通常关注图像的颜色、纹理、形状等一般特征。底层特征提取很少关注图像的语义信息，通过底层特征提取获得的信息一般比较普遍。</li>
<li>高层语义特征提取通常需要关联语义，如人脸识别中很多语义特征与人脸的部件相关，这能够反映图像中是否存在某类对象。高层语义特征提取以底层特征提取为基础，辅以模式识别等方法，建立语义关联，进而形成语义特征。深度学习的出现为语义特征提取提供了新的思路，实现了底层特征提取和高层语义关联之间的衔接，极大地提升了图像语义分析的效果。</li>
<li>图像特征提取根据其相对尺度，可分为全局特征提取和局部特征提取。全局特征提取关注图像的整体表征。常见的全局特征包括颜色特征、纹理特征、形状特征、空间位置关系特征等。局部特征提取关注图像的某个局部区域的特殊性质。一幅图像中往往包含若干兴趣区域，从这些区域中可以提取出数量不等的若干个局部特征。和全局特征提取过程相比，局部特征提取过程首先需确定要描述的兴趣区域，然后再对兴趣区域进行特征描述。</li>
</ul>
<h2 id="1-图像颜色特征提取"><a href="#1-图像颜色特征提取" class="headerlink" title="1 图像颜色特征提取"></a>1 图像颜色特征提取</h2><ul>
<li>颜色特征是比较简单但是应用广泛的一种视觉特征。颜色特征往往和图像中包含的对象或场景相关。</li>
<li>与其他图像特征相比，颜色特征对图像的尺寸、方向、视角变化的依赖性较小，即相对于图像的尺寸、方向、视角变化具有较好的健壮性。颜色特征是一种全局特征，能够描述图像或图像区域对应的景物的表面性质。</li>
<li>目前主要使用的颜色特征主要包括颜色直方图、颜色矩、颜色集、颜色聚合向量以及颜色相关图。</li>
</ul>
<h3 id="1-1-颜色直方图"><a href="#1-1-颜色直方图" class="headerlink" title="1.1 颜色直方图"></a>1.1 颜色直方图</h3><ul>
<li>颜色直方图用于描述图像中像素颜色的数值分布情况，可以反映图像颜色的统计分布和图像基本色调。颜色直方图仅可表征图像中某一颜色值出现的频数，无法描述图像像素分布的空间位置信息。</li>
<li>任意一幅图像都能唯一给出一幅与它对应的颜色直方图，但是不同的图像可能有相同的颜色直方图，因此直方图与图像存在一对多的关系。如将图像划分为若干个子区域，所有子区域的颜色直方图之和等于全图的颜色直方图。</li>
<li>一般情况下，由于图像上的背景和前景物体的颜色分布明显不同，颜色直方图上会出现双峰，但背景和前景物体的颜色较为接近的图像，颜色直方图不具有这一特性。</li>
</ul>
<h4 id="一般颜色直方图"><a href="#一般颜色直方图" class="headerlink" title="一般颜色直方图"></a>一般颜色直方图</h4><ul>
<li>颜色直方图是基本的颜色特征，它反映的是图像中像素颜色值的组成分布，即出现了哪些颜色，以及各种颜色出现的概率。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, exposure</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img = data.coffee()</span><br><span class="line"><span class="comment"># 计算直方图</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;R通道直方图&#x27;</span>)</span><br><span class="line">plt.hist(img[:, :, <span class="number">0</span>].ravel(), bins=<span class="number">256</span>, color=<span class="string">&#x27;red&#x27;</span>, alpha=<span class="number">0.6</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;G通道直方图&#x27;</span>)</span><br><span class="line">plt.hist(img[:, :, <span class="number">1</span>].ravel(), bins=<span class="number">256</span>, color=<span class="string">&#x27;green&#x27;</span>, alpha=<span class="number">0.6</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;B通道直方图&#x27;</span>)</span><br><span class="line">plt.hist(img[:, :, <span class="number">2</span>].ravel(), bins=<span class="number">256</span>, color=<span class="string">&#x27;blue&#x27;</span>, alpha=<span class="number">0.6</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>彩色图像的一般颜色直方图<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture1.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>一般颜色直方图对图像的旋转、小幅平移、小幅缩放等变换不敏感，对图像质量的变化（如增加噪声也不敏感），所以一般颜色直方图法适用于对难以进行语义分割的图像和无需考虑空间位置的图像进行描述。</li>
<li>计算机的固有量化机制导致一般颜色直方图法会忽略颜色间的相似性。</li>
</ul>
<h4 id="全局累加直方图"><a href="#全局累加直方图" class="headerlink" title="全局累加直方图"></a>全局累加直方图</h4><ul>
<li>当图像中的颜色值不能取遍所有可能的颜色值时，一般颜色直方图中就会出现一些零值。这些零值的出现会影响相似性的度量，进而使计算出的相似度不能准确反映图像之间的颜色分布差异。</li>
<li>为了弥补一般颜色直方图的缺陷，再一般颜色直方图的基础上，通过对直方图颜色进行累加，消除零值影响，形成全局累加直方图。</li>
</ul>
<h4 id="主色调直方图"><a href="#主色调直方图" class="headerlink" title="主色调直方图"></a>主色调直方图</h4><ul>
<li>在一幅图像中，不同颜色值出现的概率不尽相同，且通常情况下少数几种颜色就能涵盖整幅图像的主色调。</li>
<li>基于该思想，主色调直方图会计算出图像中每种颜色出现的频率，选择出现频率最高的几种颜色并将其作为主色调。使用主色调直方图，不会降低颜色直方图匹配的效果，反而会抑制图像非主要成分的噪声，降低噪声对图像匹配的影响。</li>
</ul>
<p><strong>颜色直方图的优点和缺点如下。</strong></p>
<ul>
<li>优点：计算简单，对图像的平移和旋转变换不敏感，能简单描述图像中颜色的全局分布情况。</li>
<li>缺点：无法捕捉（即丢失）颜色组成之间的空间位置关系。</li>
</ul>
<h3 id="1-2-颜色矩"><a href="#1-2-颜色矩" class="headerlink" title="1.2 颜色矩"></a>1.2 颜色矩</h3><ul>
<li>矩是非常重要的统计量，用于表征数据分布的特点。在统计中，一阶矩表示数据的均值，二阶矩表示数据分布的方差，三阶矩表示数据分布的偏移度。</li>
<li>图像的颜色矩用于对图像内颜色分布进行表征，是重要的一种全局图像特征表示。数字图像中颜色分布的统计信息主要集中在低阶矩中。</li>
<li>图像的颜色矩特征提取时主要瞄准图像颜色矩中的一阶矩、二阶矩、三阶矩，对图像而言，这三种统计特征已经足以表达数字图像的颜色分布。</li>
<li>相对于颜色直方图特征提取，颜色矩特征提取的优点是无须对颜色特征进提前量化。</li>
<li>一阶矩可以表征该颜色通道的平均响应强度，二阶矩可以表示该颜色通道的响应方差，三阶矩可以表征该颜色通道数据分布的偏移度。针对彩色图像，图像的颜色矩一共有 9 个分量，每个颜色通道均有 3 个低阶矩。</li>
<li>颜色矩仅使用少数几个矩容易导致过多错误检出，因而其通常和其他的几个特征配合使用。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, exposure</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line"></span><br><span class="line">image = data.coffee()</span><br><span class="line"><span class="comment"># 求RGB图像的颜色矩特征，共9维特征</span></span><br><span class="line"><span class="comment"># 定义3*3数组，分别对RGB图像的三个通道求均值、方差、偏移量</span></span><br><span class="line">features = np.zeros(shape=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(image.shape[<span class="number">2</span>]):</span><br><span class="line">    mu = np.mean(image[:, :, k])  <span class="comment"># 求均值</span></span><br><span class="line">    delta = np.std(image[:, :, k])  <span class="comment"># 求方差</span></span><br><span class="line">    skew = np.mean(stats.skew(image[:, :, k]))  <span class="comment"># 求偏移量</span></span><br><span class="line">    features[<span class="number">0</span>, k] = mu</span><br><span class="line">    features[<span class="number">1</span>, k] = delta</span><br><span class="line">    features[<span class="number">2</span>, k] = skew</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="1-3-颜色集"><a href="#1-3-颜色集" class="headerlink" title="1.3 颜色集"></a>1.3 颜色集</h3><ul>
<li>颜色集又可以称为颜色索引集，是对颜色直方图的一种近似。</li>
<li>颜色集方法的步骤是：第一，将图像从 RGB 图像空间转换到 HSV 颜色空间等视觉均衡的颜色空间，并将颜色空间量化为若干个边长均等的小立方体。第二，使用基于颜色的自动分割技术，将图像划分为若干个子区域。第三，使用颜色量化空间中的某个颜色分类索引每个子区域，以将图像表示为一个二进制的颜色索引集。<br>① 像素矢量表示<br>② 颜色空间转换<br>③ 颜色集索引<br>④ 颜色集表示</li>
</ul>
<h3 id="1-4-颜色聚合向量"><a href="#1-4-颜色聚合向量" class="headerlink" title="1.4 颜色聚合向量"></a>1.4 颜色聚合向量</h3><ul>
<li>颜色聚合向量是在颜色直方图上做进一步运算，其核心思想就是将属于颜色直方图的每个颜色量化区间的像素分为两部分，如果该颜色量化区间中的某些像素，占据连续区域的面积大于指定阈值，则将该区域内的像素作为聚合像素，否则作为非聚合像素。</li>
<li>颜色聚合向量除了包含颜色频率信息外，也包含颜色的部分空间分布信息，因此其可以获得比颜色直方图过更好的效果。颜色聚合向量算法的具体步骤如下。<br><strong>① 量化</strong><br>颜色聚合向量算法的第一步与求普通的颜色直方图类似，即对图像进行量化处理。一般采用均匀量化方法，量化的目标是使图像中只保留有限个颜色空间。<br><strong>② 连通区域划分</strong><br>针对重新量化后的像素矩阵，根据像素间的连通性把图像划分为若干个连通区域。<br><strong>③ 判断聚合性</strong><br>统计每个连通区域中的像素数目，根据设定的阈值判断该区域中的像素的聚合性<br><strong>④ 聚合向量形成</strong></li>
</ul>
<h3 id="1-5-颜色相关图"><a href="#1-5-颜色相关图" class="headerlink" title="1.5 颜色相关图"></a>1.5 颜色相关图</h3><ul>
<li>颜色相关图不仅可以显示像素在图像中的占比，也可以反映不同颜色对间的空间位置的相关性。</li>
<li>颜色相关图利用颜色对间的相对距离分布来描述空间位置信息。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, exposure</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">isValid</span>(<span class="params">X, Y, point</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    判断某个像素是否超出图像空间范围</span></span><br><span class="line"><span class="string">    :param X:</span></span><br><span class="line"><span class="string">    :param Y:</span></span><br><span class="line"><span class="string">    :param point:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> point[<span class="number">0</span>] &lt; <span class="number">0</span> <span class="keyword">or</span> point[<span class="number">0</span>] &gt;= X:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> point[<span class="number">1</span>] &lt; <span class="number">0</span> <span class="keyword">or</span> point[<span class="number">1</span>] &gt;= Y:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getNeighbors</span>(<span class="params">X, Y, x, y, dist</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Find pixel neighbors according to various distances</span></span><br><span class="line"><span class="string">    :param X:</span></span><br><span class="line"><span class="string">    :param Y:</span></span><br><span class="line"><span class="string">    :param x:</span></span><br><span class="line"><span class="string">    :param y:</span></span><br><span class="line"><span class="string">    :param dist:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cn1 = (x + dist, y + dist)</span><br><span class="line">    cn2 = (x + dist, y)</span><br><span class="line">    cn3 = (x + dist, y - dist)</span><br><span class="line">    cn4 = (x, y - dist)</span><br><span class="line">    cn5 = (x - dist, y - dist)</span><br><span class="line">    cn6 = (x - dist, y)</span><br><span class="line">    cn7 = (x - dist, y + dist)</span><br><span class="line">    cn8 = (x, y + dist)</span><br><span class="line">    points = (cn1, cn2, cn3, cn4, cn5, cn6, cn7, cn8)</span><br><span class="line">    Cn = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> (isValid(X, Y, i)):</span><br><span class="line">            Cn.append(i)</span><br><span class="line">    <span class="keyword">return</span> Cn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corrlogram</span>(<span class="params">image, dist</span>):</span><br><span class="line">    XX, YY, tt = image.shape</span><br><span class="line">    cgram = np.zeros((<span class="number">256</span>, <span class="number">256</span>), dtype=np.<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(XX):</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(YY):</span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(tt):</span><br><span class="line">                color_i = image[x, y, t]</span><br><span class="line">                neighbors_i = getNeighbors(XX, YY, x, y, dist)</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> neighbors_i:</span><br><span class="line">                    j0 = j[<span class="number">0</span>]</span><br><span class="line">                    j1 = j[<span class="number">1</span>]</span><br><span class="line">                    color_j = image[j0, j1, t]</span><br><span class="line">                    cgram[color_i, color_j] = cgram[color_i, color_j] + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> cgram</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = data.coffee()</span><br><span class="line">dist = <span class="number">4</span></span><br><span class="line">cgram = corrlogram(img, dist)</span><br><span class="line">plt.imshow(cgram)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture2.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h2 id="2-图像纹理特征提取"><a href="#2-图像纹理特征提取" class="headerlink" title="2 图像纹理特征提取"></a>2 图像纹理特征提取</h2><ul>
<li>纹理是一种反映图像中同质现象的视觉特征，它体现了物体表面的具有重复性或周期性变化的表面结构组织排列属性。纹理有三大特点：重复性、周期性、同质性。<strong>① 重复性</strong>图像可以看作是某种局部元素在全局区域的不断重复出现。<strong>② 周期性</strong>图像中元素并非随机出现，而是按照一定的周期性重复出现。<strong>③ 同质性</strong>重复出现的元素在结构和尺寸上大致相同。</li>
<li>纹理是某种局部序列不断重复、非随机排列、在结构和尺寸上大致相同的统一体。<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture3.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>不同于灰度、颜色等图像特征，纹理特征通过像素及其周边空间域像素的灰度分布进行描述，也就是局部纹理信息。局部纹理的反复排布呈现出的重复性，就是所谓的全局纹理信息。</li>
<li>纹理信息在表现全局特征性质的同时，也体现了图像或图像所在区域对应景物的表面特性。纹理特征只是对物体表面特性进行描述，并不能反映物体的本质属性，即图像高层语义信息。</li>
<li>纹理特征提取过程是通过一定的图像处理技术抽取出纹理特征，从而获得纹理的定量或定性描述的过程。纹理特征提取的基本过程如下。<strong>① 纹理基元建模</strong>从像素出发，找出纹理基元（即纹理图像中辨识能力比较强的特征），并根据纹理基元的排列信息，建立起纹理基元模型。<strong>② 整体纹理模型构建</strong>利用纹理基元模型对纹理图像进行特征提取，以支持对图像的进一步分割、分类以及辨识，形成图像整体纹理模型。</li>
<li>常见的纹理特征提取方法可以分为如下 4 类。<br><strong>① 统计分析法</strong><br>统计分析法又称基于统计纹理特征的检测方法，该方法假设纹理图像在空间灰度分布上，存在某种重复性，通过对纹理图像的灰度空间分布进行计算，从而得到纹理特征，主要包括灰度直方图法、灰度共生矩阵法、灰度行程长度法、灰度差分统计、交叉对角矩阵、自相关函数法等。该类方法在木纹、沙地、草地之类的图像分析上很有效。其主要优势是：方法简单，易于实现，典型的代表方法是灰度共生矩阵法，被认为是比较有效的纹理分析方法。<br><strong>② 结构分析法</strong><br>结构分析法认为纹理基元之间存在某种结构规则关系，该类方法首先对图像中的纹理基元进行分离，然后基于纹理基元的特征和空间排列规则对纹理进行表征，主要包括偏心度、面积、方向等特征，其主要目标是通过图像结构特征和排列规则的描述，得到纹理特征的描述，此类算法主要适用于已知纹理基元的情况，对砖墙、纤维等纹理基元和排列规则都比较明显的图像有效。<br><strong>③ 模型分析法</strong><br>模型分析法基于像素及其邻域像素之间的关系建立模型，根据不同模型提取不同特征量，进行参数估计。典型的模型分析法包括自然回归法、马尔可夫条件随机场法以及分形法等。<br><strong>④ 频谱分析法</strong><br>频谱分析法又称为信号处理法和滤波方法。该方法将纹理图像从空间域变换到频域，然后通过计算峰值处的面积、峰值与原点的距离平方、峰值处的相位、两个峰值间的相角差等，获得在空间域不易获得的纹理特征，如周期、功率谱信息等，典型的频谱分析法有二维傅里叶（变换）滤波方法，Gabor（变换）滤波变换和小波方法等。</li>
</ul>
<h3 id="2-1-统计纹理分析方法"><a href="#2-1-统计纹理分析方法" class="headerlink" title="2.1 统计纹理分析方法"></a>2.1 统计纹理分析方法</h3><ul>
<li>统计纹理分析方法是较常用的纹理特征描述分析方法，通过统计图像的空间频率、边界频率以及空间灰度依赖关系等对纹理进行描述。</li>
<li>细致的纹理有较高的频率，例如，布匹的纹理是非常细致的纹理，其纹理基元较小，出现频率较高。粗糙的纹理结构具有较低的空间频率，如大理石纹理一般较粗糙，具有较大的纹理基元，出现频率较低。</li>
<li>纹理图像的空间频率可以作为纹理描述的一种方式。边界频率是另外一种基于统计的纹理图像描述方法，边界频率越高，表明纹理越精细。空间灰度依赖关系方法通过描述纹理结构之间的空间依赖关系描述纹理。</li>
<li>常用的统计纹理分析方法有自相关函数、边界频率、灰度共生矩阵等。统计纹理分析方法并不刻意精确描述纹理的结构。从统计学的角度看，纹理图像是一些复杂的模式，通常通过获得的统计特征集描述这些模式。</li>
<li>灰度共生矩阵法也称联合概率矩阵法。该方法基于图像中的灰度结构重复出现的概率，对图像纹理特征进行描述。该方法的本质是使用条件概率表征纹理特征，通过对空间上，具有某种位置关系的一对像素成对出现的概率进行统计，得到灰度共生矩阵，然后从灰度共生矩阵中提取有意义的统计特征对纹理进行描述。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage.feature <span class="keyword">import</span> greycomatrix, greycoprops</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">PATCH_SIZE = <span class="number">21</span></span><br><span class="line">image = data.camera()</span><br><span class="line"><span class="comment"># 选择图像中的草地区域</span></span><br><span class="line">grass_locations = [(<span class="number">474</span>, <span class="number">291</span>), (<span class="number">440</span>, <span class="number">433</span>), (<span class="number">466</span>, <span class="number">18</span>), (<span class="number">462</span>, <span class="number">236</span>)]</span><br><span class="line">grass_patches = []</span><br><span class="line"><span class="keyword">for</span> loc <span class="keyword">in</span> grass_locations:</span><br><span class="line">    grass_patches.append(image[loc[<span class="number">0</span>]:loc[<span class="number">0</span>] + PATCH_SIZE, loc[<span class="number">1</span>]:loc[<span class="number">1</span>] + PATCH_SIZE])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择图像中的天空区域</span></span><br><span class="line">sky_locations = [(<span class="number">54</span>, <span class="number">48</span>), (<span class="number">21</span>, <span class="number">233</span>), (<span class="number">90</span>, <span class="number">380</span>), (<span class="number">195</span>, <span class="number">330</span>)]</span><br><span class="line">sky_patches = []</span><br><span class="line"><span class="keyword">for</span> loc <span class="keyword">in</span> sky_locations:</span><br><span class="line">    sky_patches.append(image[loc[<span class="number">0</span>]:loc[<span class="number">0</span>] + PATCH_SIZE, loc[<span class="number">1</span>]:loc[<span class="number">1</span>] + PATCH_SIZE])</span><br><span class="line"><span class="comment"># 计算每个块中灰度共生矩阵属性</span></span><br><span class="line">xs = []</span><br><span class="line">ys = []</span><br><span class="line"><span class="keyword">for</span> patch <span class="keyword">in</span> (grass_patches + sky_patches):</span><br><span class="line">    glcm = greycomatrix(patch, [<span class="number">5</span>], [<span class="number">0</span>], <span class="number">256</span>, symmetric=<span class="literal">True</span>, normed=<span class="literal">True</span>)</span><br><span class="line">    xs.append(greycoprops(glcm, <span class="string">&#x27;dissimilarity&#x27;</span>)[<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">    ys.append(greycoprops(glcm, <span class="string">&#x27;correlation&#x27;</span>)[<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"><span class="comment"># 创建绘图</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line"><span class="comment"># 展现原始图像，以及图像块的位置</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">ax.imshow(image, cmap=plt.cm.gray, interpolation=<span class="string">&#x27;nearest&#x27;</span>, vmin=<span class="number">0</span>, vmax=<span class="number">255</span>)</span><br><span class="line"><span class="keyword">for</span> (y, x) <span class="keyword">in</span> grass_locations:</span><br><span class="line">    ax.plot(x + PATCH_SIZE / <span class="number">2</span>, y + PATCH_SIZE / <span class="number">2</span>, <span class="string">&#x27;gs&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> (y, x) <span class="keyword">in</span> sky_locations:</span><br><span class="line">    ax.plot(x + PATCH_SIZE / <span class="number">2</span>, y + PATCH_SIZE, <span class="string">&#x27;bs&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line">ax.set_xticks([])</span><br><span class="line">ax.set_yticks([])</span><br><span class="line">ax.axis(<span class="string">&#x27;image&#x27;</span>)</span><br><span class="line"><span class="comment"># 对于每个块，plot(dissimilarity,correlation)</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">ax.plot(xs[:<span class="built_in">len</span>(grass_patches)], ys[:<span class="built_in">len</span>(grass_patches)], <span class="string">&#x27;go&#x27;</span>, label=<span class="string">&#x27;Grass&#x27;</span>)</span><br><span class="line">ax.plot(xs[:<span class="built_in">len</span>(sky_patches)], ys[:<span class="built_in">len</span>(sky_patches)], <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Sky&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;灰度共生矩阵相似性&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;灰度共生矩阵相关度&#x27;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line"><span class="comment"># 展示图像</span></span><br><span class="line"><span class="keyword">for</span> i, patch <span class="keyword">in</span> <span class="built_in">enumerate</span>(grass_patches):</span><br><span class="line">    ax = fig.add_subplot(<span class="number">3</span>, <span class="built_in">len</span>(grass_patches), <span class="built_in">len</span>(grass_patches) * <span class="number">1</span> + i + <span class="number">1</span>)</span><br><span class="line">    ax.imshow(patch, cmap=plt.cm.gray, interpolation=<span class="string">&#x27;nearest&#x27;</span>, vmin=<span class="number">0</span>, vmax=<span class="number">255</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;Grass %d&#x27;</span> % (i + <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i, patch <span class="keyword">in</span> <span class="built_in">enumerate</span>(sky_patches):</span><br><span class="line">    ax = fig.add_subplot(<span class="number">3</span>, <span class="built_in">len</span>(sky_patches), <span class="built_in">len</span>(sky_patches) * <span class="number">2</span> + i + <span class="number">1</span>)</span><br><span class="line">    ax.imshow(patch, cmap=plt.cm.gray, interpolation=<span class="string">&#x27;nearest&#x27;</span>, vmin=<span class="number">0</span>, vmax=<span class="number">255</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;Sky %d&#x27;</span> % (i + <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 展示图像块并显示</span></span><br><span class="line">fig.suptitle(<span class="string">&#x27;Grey level co-occurrence matrix features&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>基于灰度共生矩阵的纹理描述方法<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture4.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="2-2-Laws-纹理能量测量法"><a href="#2-2-Laws-纹理能量测量法" class="headerlink" title="2.2 Laws 纹理能量测量法"></a>2.2 Laws 纹理能量测量法</h3><ul>
<li>Laws 纹理能量测量法是一种典型的一阶纹理分析方法，在纹理分析领域有一定影响。</li>
<li>Laws 纹理能力测量的基本思想是创建两个窗口：一个是微窗口，可为 3×3、5×5 或 7×7，常取 5×5 测量以像元为中心的小区域的灰度的不规则性，以形成属性，称为微窗口滤波；另一个是宏窗口，为 15×15 或 32×32，用来在更大的区域上求属性的一阶统计量（常为均值和标准偏差），称为能量变换。</li>
<li>整个纹理分析过程为：<code>f(x,y)</code>→ 微窗口滤波 →<code>F(x,y)</code>→ 能量转换 →<code>E(x,y)</code>→ 分类</li>
</ul>
<h3 id="2-3-Gabor-变换"><a href="#2-3-Gabor-变换" class="headerlink" title="2.3 Gabor 变换"></a>2.3 Gabor 变换</h3><ul>
<li>大量心理和生理学研究发现，在人类的低级视觉中，输入信号被一系列具有不同频率和方位的线性空间滤波器分解成一组频率和方位通道，Gabor 分解可以很好的描述这一信号分解过程。</li>
<li>Gabor 变换具有两个重要的特性。一是其良好的空间域与频域局部化性质。二是无论从空间域的起伏特性上，方位选择特性上，空间域与频域选择上，还是从正交相位的关系上，二维 Gabor 基函数具有与大多数哺乳动物的视觉表皮简单细胞的二维感知域模型相似的性质。</li>
<li>可以借鉴人类处理信号的特性，用包含多个 Gabor 滤波器的滤波器组，对图像进行不同中心频率和方位的滤波处理，从而提取不同频率成分和不同方位的特征，作为目标的非参数化特征，研究其不同分辨率目标的特征与图像分辨率的关系。</li>
<li>Gabor 滤波器滤波过程<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture5.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="2-4-局部二值模式"><a href="#2-4-局部二值模式" class="headerlink" title="2.4 局部二值模式"></a>2.4 局部二值模式</h3><ul>
<li>局部二值模式（Local Binary Pattern，LBP）的基本思想是将中心像素点的灰度值作为阈值，将其邻域内的像素点灰度值与阈值进行比较，从而得到二进制编码用以表述局部纹理特征。</li>
<li>LBP 表示方法不易受图像整体灰度线性变化的影响，当图像的灰度值发生线性均匀变化时，其 LBP 特征编码是不变的。</li>
<li>LBP 特征计算简单，表征能力强，在纹理特征描述上具有较好的效果。</li>
<li>基本 LBP 算子：3&#x2F;*3 的矩形块，有一个中心像素和 8 个邻域像素，分别对应 9 个灰度值。</li>
<li>特征值：以中心像素的灰度值为阈值，将其邻域的 8 个灰度值与阈值比较，大于中心灰度值的像素用 1 表示，反之用 0 表示。然后顺时针方向读出 8 个二进制值。<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture6.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>经阈值化后的二值矩阵，可以看出一个二值纹理模式，用来刻画邻域内，像素点的灰度相对中心点的变化。</li>
<li>因为人类视觉系统对纹理的感知与平均灰度（亮度无关），而局部二值模式方法注重像素灰度的变化，符合人类视觉对纹理感知的特点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> skimage.feature</span><br><span class="line"><span class="keyword">import</span> skimage.segmentation</span><br><span class="line"><span class="keyword">import</span> skimage.data</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">img = skimage.data.coffee()</span><br><span class="line"><span class="keyword">for</span> colour_channel <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">    img[:, :, colour_channel] = skimage.feature.local_binary_pattern(img[:, :, colour_channel], <span class="number">8</span>, <span class="number">1.0</span>, method=<span class="string">&#x27;var&#x27;</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture7.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h2 id="3-图像形状特征提取"><a href="#3-图像形状特征提取" class="headerlink" title="3 图像形状特征提取"></a>3 图像形状特征提取</h2><ul>
<li>形状和区域特征是图像中的另一类重要特征。不同于颜色、纹理等底层特征，对形状特征的描述必须以对图像中的物体或区域对象的分割为前提。</li>
<li>形状特征的表示方法可以分为两类：一是基于轮廓特征，典型方法是傅里叶描述符方法。二是基于区域特征，典型方法是形状无关矩法。轮廓特征中只用到物体的边界，而区域特征需要考虑整个形状区域。</li>
</ul>
<h3 id="3-1-简单形状特征"><a href="#3-1-简单形状特征" class="headerlink" title="3.1 简单形状特征"></a>3.1 简单形状特征</h3><ul>
<li>矩形度。反应物体对外接矩形的充满度，用物体的面积与其最小外接矩形的面积之比描述。<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture8.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>球状性。球状性既可以描述二维目标，也可描述三维目标。<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture9.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>圆形性。目标圆形性是指用目标区域 R 的所有边界点定义的特征量。</li>
</ul>
<h3 id="3-2-傅里叶描述符"><a href="#3-2-傅里叶描述符" class="headerlink" title="3.2 傅里叶描述符"></a>3.2 傅里叶描述符</h3><ul>
<li>傅里叶描述符是用于单封闭曲线形状特征描述的常用工具。傅里叶描述符将待描述目标曲线看组一维数值序列，使用傅里叶变换对该序列进行转换，得到描述该曲线的一系列傅里叶系数。</li>
<li>傅里叶描述符具有计算简单、描述清晰等优点。相较于其他复杂的描述方法，傅里叶描述符更加直观，易于理解。</li>
<li>傅里叶描述方法一般分为两步：首先，定义轮廓线的表示，把坐标的序列点看作复数，即 <code>s(k)</code>=<code>x(k)</code>+<code>jy(k)</code>，x 轴作为实轴，y 轴作为虚轴，边界的性质不变。这种表示方法的优点是将一个二维边缘描述问题，简化为一个一维序列描述问题。其次，对一维序列 s(k)进行傅里叶变换，并求得其傅里叶系数。</li>
</ul>
<h3 id="3-3-形状无关矩"><a href="#3-3-形状无关矩" class="headerlink" title="3.3 形状无关矩"></a>3.3 形状无关矩</h3><ul>
<li>由于图像区域的某些矩对于平移、旋转、尺度等几何变换具有一些不变的特性，使得矩的表示方法在物体的分类与识别方面具有重要的意义。</li>
</ul>
<h2 id="4-图像边缘特征提取"><a href="#4-图像边缘特征提取" class="headerlink" title="4 图像边缘特征提取"></a>4 图像边缘特征提取</h2><ul>
<li>图像边缘具有方向和幅度两个主要成分。沿边缘方向移动，像素的灰度值变化速率较为平缓，而沿垂直于边缘的方向移动，像素的灰度值变化率较为剧烈。这种剧烈的变化或者呈阶跃状（Step Edge），或呈屋顶状（Proof Edge），分为称为阶跃状边缘和屋顶状边缘。根据边缘的性质，一般用一阶或二阶导数对其进行描述和检测。<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture10.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>图像中的边缘可以通过对他们求导数确定，而导数可利用微分算子计算。对于数字图像处理而言，通常利用差分近似微分。</li>
<li>图像边缘检测的基本步骤如下。<strong>① 滤波</strong>边缘检测主要基于导数计算，但易受噪声影响，滤波操作的主要目的是降低噪声的干扰，但滤波在降低噪声的同时，也会损失边缘强度。<strong>② 增强</strong>增强算法将局部邻域中灰度值有显著变化的点突出显示，一般可通过计算梯度幅值完成。<strong>③ 检测</strong>有些图像中梯度幅值较大的点并不是边缘点，需要对其进行进一步筛选，最简单的检测方法是设定梯度幅值阈值。<strong>④ 定位</strong>定位即精确确定边缘的位置。</li>
<li>传统边缘检测的流程。</li>
</ul>
<p><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture11.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h3 id="4-1-梯度边缘检测"><a href="#4-1-梯度边缘检测" class="headerlink" title="4.1 梯度边缘检测"></a>4.1 梯度边缘检测</h3><ul>
<li>梯度的方向（由梯度矢量的幅角表示）是函数 f(x,y)增加最快的方向，定义为 <code>ϕ(x,y)</code>=<code>arctan(Gy/Gx)</code>，从梯度原理出发，已经发展了很多边缘检测算子。</li>
</ul>
<h3 id="4-2-一阶边缘检测算子"><a href="#4-2-一阶边缘检测算子" class="headerlink" title="4.2 一阶边缘检测算子"></a>4.2 一阶边缘检测算子</h3><h4 id="罗伯特算子"><a href="#罗伯特算子" class="headerlink" title="罗伯特算子"></a>罗伯特算子</h4><ul>
<li>罗伯特边缘检测算子，用对角线上相邻像素之差代替梯度寻找边缘。</li>
<li>罗伯特边缘检测的步骤：<br>（1）用两个模板分别对图像进行运算得到 <code>Rxf</code>和 <code>Ryf</code>，并计算 <code>|G(i,j)|</code>=<code>|Gx|</code>+<code>|Gy|</code>；<br>（2）判断该相加结果是否大于某个阈值。如果满足条件，则将其作为结果图像中对应模板(i,j)位置的像素值；如果不满足条件，则结合结果图像中对应模板 <code>(i,j)</code>位置的像素赋 0 值。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera</span><br><span class="line"><span class="keyword">from</span> skimage.filters <span class="keyword">import</span> roberts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">image = camera()</span><br><span class="line">edge_roberts = roberts(image),</span><br><span class="line">fig, ax = plt.subplots(ncols=<span class="number">2</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>, figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line">ax[<span class="number">0</span>].imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>].imshow(edge_roberts, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&#x27;Roberts 边缘检测&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> ax:</span><br><span class="line">    a.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture12.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<h4 id="索贝尔算子"><a href="#索贝尔算子" class="headerlink" title="索贝尔算子"></a>索贝尔算子</h4><ul>
<li>索贝尔边缘检测的步骤：<br>（1）用两个模板分别对图像进行计算，得出 <code>|G(i,j)|</code>=<code>Gx</code>+<code>Gy</code>；<br>（2）判别该相加结果是否大于或等于某个阈值，如果满足条件，则将其作为结果图像中对应模板 <code>(i,j)</code>位置的像素值；如果不满足条件，则给结果图像中对应模板 <code>(i,j)</code>位置的像素赋 0 值。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera</span><br><span class="line"><span class="keyword">from</span> skimage.filters <span class="keyword">import</span> sobel, sobel_v, sobel_h</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">image = camera()</span><br><span class="line">edge_sobel = sobel(image)</span><br><span class="line">edge_sobel_v = sobel_v(image)</span><br><span class="line">edge_sobel_h = sobel_h(image)</span><br><span class="line">fig, ax = plt.subplots(ncols=<span class="number">2</span>, nrows=<span class="number">2</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>, figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(image, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(edge_sobel, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;Sobel 边缘检测&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(edge_sobel_v, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;Sobel 垂直边缘检测&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(edge_sobel_h, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;Sobel 水平边缘检测&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> ax:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> a:</span><br><span class="line">        j.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture13.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<ul>
<li>索贝尔边缘检测算子在较好的获得边缘性效果的同时，对噪声具有一定的平滑作用，减少了噪声的敏感性。但索贝尔边缘检测的边缘比较粗，会检测出一些伪边缘，边缘检测精度较低。</li>
</ul>
<h4 id="Prewitt-算子"><a href="#Prewitt-算子" class="headerlink" title="Prewitt 算子"></a>Prewitt 算子</h4><ul>
<li>Prewitt 算子在方向和方向的梯度幅值上的形式，与索贝尔算子的形式完全相同，只是系数均为 1，对应的 3*3 模板为<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture14.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>Prewitt 算子的计算比索贝尔算子更简单，但在噪声抑制方面，索贝尔算子比 Prewitt 算子略胜一筹。</li>
<li>梯度算子对噪声有一定的敏感性，所以适用于图像边缘灰度值比较尖锐，且图像中噪声比较小的情况</li>
</ul>
<h3 id="4-3-二阶边缘检测算子"><a href="#4-3-二阶边缘检测算子" class="headerlink" title="4.3 二阶边缘检测算子"></a>4.3 二阶边缘检测算子</h3><ul>
<li>在利用一阶导数的边缘检测算子进行边缘检测时，有时会出现因检测到的边缘点过多，而导致边缘线过粗的情况。</li>
<li>通过去除一阶导数中的非局部最大值，就可以检测出更细的边缘，而一阶导数的局部最大值对应二阶导数的零交叉点。所以，通过找图像的二阶导数的零交叉点，就能找到精确的边缘点。</li>
</ul>
<h4 id="拉普拉斯（Laplace）算子"><a href="#拉普拉斯（Laplace）算子" class="headerlink" title="拉普拉斯（Laplace）算子"></a>拉普拉斯（Laplace）算子</h4><ul>
<li>对阶跃状边缘，其二阶导数在边缘点出现过零交叉，即边缘点两旁的二阶导数取异号，据此可通过二阶导数检测边缘点。</li>
<li>Laplace 算子的边缘检测</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera, coffee</span><br><span class="line"><span class="keyword">from</span> skimage.filters <span class="keyword">import</span> laplace</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">image_camera = camera()</span><br><span class="line">edge_laplace_camera = laplace(image_camera)</span><br><span class="line">image_coffee = coffee()</span><br><span class="line">edge_laplace_coffee = laplace(image_coffee)</span><br><span class="line">fig, ax = plt.subplots(ncols=<span class="number">2</span>, nrows=<span class="number">2</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(image_camera, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(edge_laplace_camera, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;Laplace 边缘检测&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(image_coffee, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(edge_laplace_coffee, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;Laplace 边缘检测&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> ax:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> a:</span><br><span class="line">        j.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>边缘检测算子模板的基本特征是中心位置的系数为正，其余位置的系数为负，且模板的系数之和为 0.</li>
<li>它的使用方法是用图中的两个点阵之一作为卷积核，与原图像进行卷积运算即可。</li>
<li>Lapace 检测模板的特点是各向同性，对孤立点及线端的检测效果好，Laplace 算子的缺点是会出现边缘方向信息丢失，对噪声敏感，整体检测效果不如梯度算子，且与索贝尔算子相比，对图像进行处理时，Laplace 算子能使噪声成分得到加强，对噪声更敏感。<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture15.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h4 id="LoG-边缘检测算子"><a href="#LoG-边缘检测算子" class="headerlink" title="LoG 边缘检测算子"></a>LoG 边缘检测算子</h4><ul>
<li>实际应用中，由于噪声的影响，对噪声敏感的边缘检测点检测算法（如拉普拉斯算子法）可能会把噪声当边缘检测点检测出来，而真正的边缘点会被噪声淹没而未检测出。</li>
<li>LoG 算子基于 Laplace 算子和 Gauss 算子，也称拉普拉斯-高斯边缘检测算子。</li>
<li>由于平滑会导致边缘的延展，因此在边缘检测时，仅考虑那些具有局部最大值的点为边缘点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera, coffee</span><br><span class="line"><span class="keyword">from</span> skimage.filters <span class="keyword">import</span> laplace, gaussian</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">image = camera()</span><br><span class="line">edge_laplace = laplace(image)</span><br><span class="line">gaussian_image = gaussian(image)</span><br><span class="line">edge_LoG = laplace(gaussian_image)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(ncols=<span class="number">2</span>, nrows=<span class="number">2</span>, sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(image, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(edge_laplace, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;Laplace 边缘检测&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(gaussian_image, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;高斯平滑后的图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(edge_LoG, cmap=plt.cm.gray)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;LoG 边缘检测&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> ax:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> a:</span><br><span class="line">        j.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>基于 LoG 的边缘检测效果<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture16.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h2 id="5-图像点特征提取"><a href="#5-图像点特征提取" class="headerlink" title="5 图像点特征提取"></a>5 图像点特征提取</h2><ul>
<li>如果图像中一个非常小的区域的灰度值，与其邻域值相比有明显的差异，则称这个非常小的区域为图像点（一般意义上的孤立像素点）<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture17.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>目前对图像点特征提取的技术有多种，其中研究最多、应用最广的是角点检测算法。</li>
<li>从直观可视的角度出发，两条直线相交的顶点可看作是角点；物体的几个平面的相交处也可以看作角点。从图像特征的角度出发，图像中周围灰度变化较剧烈的点可看作是角点；图像边界上曲率足够高的点也可以看作是角点。</li>
<li>常见的角点类型。<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture18.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>角点的检测方法有很多种，其检测原理也多种多样，但这些方法概括起来大体可分为 3 类：一是基于模板的角点检测算法；二是基于边缘的角点检测算法；三是基于图像灰度变化的角点检测算法。其中，基于图像灰度变化的角点检测算法应用最广泛。</li>
<li>SUSAN 角点检测算法选用圆形模板，将位于圆形窗口模板中心等待检测的像素点称为核心点。核心点的邻域被划分为两个区域：亮度值相似于核心点亮度的区域即核值相似区和亮度值不相似于核心点亮度的区域。</li>
<li>SUSAN 算法通过核值相似区的大小判别图像角点，并实现图像中角点特征的检测和提取。<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture19.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>SUSAN 算子实现代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage.data <span class="keyword">import</span> camera</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">susan_mask</span>():</span><br><span class="line">    mask = np.ones((<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">    mask[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">0</span>, <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">0</span>, <span class="number">5</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">0</span>, <span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">1</span>, <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">1</span>, <span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">5</span>, <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">5</span>, <span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">6</span>, <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">6</span>, <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">6</span>, <span class="number">5</span>] = <span class="number">0</span></span><br><span class="line">    mask[<span class="number">6</span>, <span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> mask</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">susan_corner_detection</span>(<span class="params">img</span>):</span><br><span class="line">    img = img.astype(np.float64)</span><br><span class="line">    g = <span class="number">37</span> / <span class="number">2</span></span><br><span class="line">    circularMask = susan_mask()</span><br><span class="line">    output = np.zeros(img.shape)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>, img.shape[<span class="number">0</span>] - <span class="number">3</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>, img.shape[<span class="number">1</span>] - <span class="number">3</span>):</span><br><span class="line">            ir = np.array(img[i - <span class="number">3</span>:i + <span class="number">4</span>, j - <span class="number">3</span>:j + <span class="number">4</span>])</span><br><span class="line">            ir = ir[circularMask == <span class="number">1</span>]</span><br><span class="line">            ir0 = img[i, j]</span><br><span class="line">            a = np.<span class="built_in">sum</span>(np.exp(-((ir - ir0) / <span class="number">10</span>) ** <span class="number">6</span>))</span><br><span class="line">            <span class="keyword">if</span> a &lt;= g:</span><br><span class="line">                a = g - a</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                a = <span class="number">0</span></span><br><span class="line">            output[i, j] = a</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">image = camera()</span><br><span class="line">out = susan_corner_detection(image)</span><br><span class="line">plt.imshow(out, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>基于 SUSAN 算子的角点检测响应图像<br><img src="/../img/post/DigitalImageProcessing-FeatureExtraction/picture20.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
]]></content>
      <categories>
        <category>学习记录类</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>图像压缩</title>
    <url>/2021/06/12/DigitalImageProcessing-ImageCompression/</url>
    <content><![CDATA[<h1 id="图像压缩"><a href="#图像压缩" class="headerlink" title="图像压缩"></a>图像压缩</h1><span id="more"></span>

<ul>
<li>数字化之后的图像数据占用的空间非常大，如一幅分辨率为 <code>800 * 600</code>像素的 32 位灰度图像，其像素数目位 <code>480000</code>，占用空间大小为 <code>480000</code> * <code>32bit</code> &#x3D; <code>480000</code> * <code>4B</code> &#x3D; 1.83 * 1024 * 1024 B，即 1.83MB。目前电影的帧率一般为 24 帧每秒，此分辨率下存储一秒的电影需要 <code>1.83</code> * <code>24</code> &#x3D; <code>43.92MB</code>。</li>
<li>图像数据给图像存储及图像传输造成了很大的困难。图像压缩是将图像数据存在的冗余信息去掉，以实现有效压缩。</li>
</ul>
<h2 id="1-图像压缩简介"><a href="#1-图像压缩简介" class="headerlink" title="1 图像压缩简介"></a>1 图像压缩简介</h2><ul>
<li>数据是用来表示信息的，如果不同的方法为表示给定量的信息，使用了不同的信息，那么使用较多数据量的方法中，有些信息必然代表了无用信息。冗余数据的存在为图像压缩提供了可能。</li>
</ul>
<p>（1）编码冗余<br>如果一个图像的灰度级编码使用了多于实际需要的编码符号，就称该图像包含了编码冗余。如可以使用 8 位表示图像的像素，也可以使用 1 位表示该图像的像素，就称该图像存在编码冗余。</p>
<p>（2）像素间冗余<br>像素间冗余反应了图像中像素之间的相互关系。图像像素值并非完全随机，而是与其相邻像素存在某种关联关系。对于一幅图像，很多单个像素对视觉的贡献是冗余的。它的值可以通过与它相邻的像素值进行预测。因为任何给定像素的值可以根据与这个像素相邻的像素进行预测，所以单个像素携带的信息相对较少。<br>原图像数据：234 223 231 238 235<br>压缩后数据：234 -11 8 7 -3</p>
<p>（3）心理视觉冗余眼睛对所有视觉信息感受的灵敏度不同，相比之下，有些信息在通常的视觉过程中并不重要，去除这些信息并不会明显降低图像质量。</p>
<ul>
<li>编码冗余、像素间冗余、心理视觉冗余是一般图像压缩的基础，在此基础上发展出各类编码和压缩算法。按照压缩过程中是否出现信息丢失，可以将图片压缩算法大致分为有损压缩和无损压缩两类，无损图像压缩方法有行程长度编码、熵编码法等。有损图像压缩方法包括变换编码、分形压缩等。</li>
<li>无损压缩和有损压缩都是以更少的信息对原图像进行表示，但无损压缩在图像压缩之后可以将信息的原貌进行恢复，而有损压缩进行图像压缩后，会使部分信息丢失，导致无法完全进行原始图像的重建。<br><img src="/../img/post/DigitalImageProcessing-ImageCompression/picture1.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<p>（1）熵编码或统计编码<br>熵编码或统计编码属于无损编码，给出现概率较大的符号赋予一个短码子，给出现概率较小的符号赋予一个长码字，从而使最终的平均码长很小。主要的熵编码方法包括哈夫曼编码、香农编码、算术编码。</p>
<p>（2）预测编码<br>基于图像数据的空间或时间冗余特性，用相邻的已知像素（或像素块）预测当前像素（或像素块）的取值，然后再对预测误差进行量化和编码，包括脉冲编码调制（PCM）、差分脉冲编码调制（DPCM）。</p>
<p>（3）变换编码<br>将空域上的图像变换到另一个变换域上，变换后图像的大部分能量只集中到少数几个变换系数上，采用适当的量化和熵编码就可以有效压缩图像。</p>
<p>（4）混合编码<br>混合编码是综合了熵编码、变换编码或预测编码的编码方法，如 JPEG 标准和 MPEG 标准。</p>
<h2 id="2-熵编码技术"><a href="#2-熵编码技术" class="headerlink" title="2 熵编码技术"></a>2 熵编码技术</h2><ul>
<li>熵编码技术是一类典型无损编码技术。该类编码技术基于信息论对图像进行重新编码，通常的做法是给出现概率较高的符号一个较短的编码，而给出现概率较低的符号一个较长的编码，保证平均编码长度最短，主要编码方法包括哈夫曼编码、香农编码、及算术编码。</li>
<li>信息熵是表征某个数据集合或序列所需的最优编码长度的理论值，各种熵编码算法均是从不同角度对此理论值进行近似。</li>
</ul>
<h3 id="2-1-哈夫曼编码"><a href="#2-1-哈夫曼编码" class="headerlink" title="2.1 哈夫曼编码"></a>2.1 哈夫曼编码</h3><ul>
<li>哈夫曼编码是不定长编码。哈夫曼编码的基本方法是先对图像数据扫描一遍，计算出各种像素出现的概率，按概率大小指定不同长度的唯一码字，由此得到一张该图像的哈夫曼表。编码后的图像数据记录的是每个像素的码字，而码字与实际像素值对应关系记录在码表中。</li>
<li>哈夫曼编码的基本步骤：<br>（1）将需要考虑的像素值按概率排序，并将最低概率的像素符号联结为一个单一符号。<br>（2）对每个化简后的像素进行编码，从出现概率最小的像素符号开始，一直编码到图像中的所有元素。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> queue</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义需要编码的图像</span></span><br><span class="line">image = np.array([[<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>]])</span><br><span class="line"><span class="comment"># 计算每种元素出现的概率</span></span><br><span class="line">hist = np.bincount(image.ravel(), minlength=<span class="number">5</span>)</span><br><span class="line">probabilities = hist / np.<span class="built_in">sum</span>(hist)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找出数据中的最小元素</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_smallest</span>(<span class="params">data</span>):</span><br><span class="line">    first = second = <span class="number">1</span></span><br><span class="line">    fid = sid = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> idx, element <span class="keyword">in</span> <span class="built_in">enumerate</span>(data):</span><br><span class="line">        <span class="keyword">if</span> element &lt; first:</span><br><span class="line">            second = first</span><br><span class="line">            sid = fid</span><br><span class="line">            first = element</span><br><span class="line">            fid = idx</span><br><span class="line">        <span class="keyword">elif</span> element &lt; second <span class="keyword">and</span> element != first:</span><br><span class="line">            second = element</span><br><span class="line">    <span class="keyword">return</span> fid, first, sid, second</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义哈夫曼树</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Node</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        元素值存储在叶子结点</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.prob = <span class="literal">None</span></span><br><span class="line">        self.code = <span class="literal">None</span></span><br><span class="line">        self.data = <span class="literal">None</span></span><br><span class="line">        self.left = <span class="literal">None</span></span><br><span class="line">        self.right = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__lt__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        定义优先树中排序规则</span></span><br><span class="line"><span class="string">        :param other:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.prob &lt; other.prob:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__ge__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">if</span> self.prob &gt; other.prob:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建哈夫曼树</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tree</span>(<span class="params">probabilities</span>):</span><br><span class="line">    prq = queue.PriorityQueue()</span><br><span class="line">    <span class="keyword">for</span> color, probability <span class="keyword">in</span> <span class="built_in">enumerate</span>(probabilities):</span><br><span class="line">        leaf = Node()</span><br><span class="line">        leaf.data = color</span><br><span class="line">        leaf.prob = probability</span><br><span class="line">        prq.put(leaf)</span><br><span class="line">    <span class="keyword">while</span> prq.qsize() &gt; <span class="number">1</span>:</span><br><span class="line">        new_node = Node()</span><br><span class="line">        l = prq.get()</span><br><span class="line">        r = prq.get()</span><br><span class="line">        <span class="comment"># 找出叶子结点中概率最小的两个</span></span><br><span class="line">        <span class="comment"># 移除最小的两个结点</span></span><br><span class="line">        new_node.left = l  <span class="comment"># 左侧是较小的</span></span><br><span class="line">        new_node.right = r</span><br><span class="line">        new_prob = l.prob + r.prob  <span class="comment"># 新概率是两个小概率之和</span></span><br><span class="line">        new_node.prob = new_prob</span><br><span class="line">        prq.put(new_node)  <span class="comment"># 插入新结点，替代原有的两个结点</span></span><br><span class="line">    <span class="keyword">return</span> prq.get()  <span class="comment"># 返回根结点完成树的构建</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对哈夫曼树进行遍历，得出编码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">huffman_traversal</span>(<span class="params">root_node, tmp_array, f</span>):</span><br><span class="line">    <span class="keyword">if</span> root_node.left <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        tmp_array[huffman_traversal.count] = <span class="number">1</span></span><br><span class="line">        huffman_traversal.count += <span class="number">1</span></span><br><span class="line">        huffman_traversal(root_node.left, tmp_array, f)</span><br><span class="line">        huffman_traversal.count -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> root_node.right <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        tmp_array[huffman_traversal.count] = <span class="number">0</span></span><br><span class="line">        huffman_traversal.count += <span class="number">1</span></span><br><span class="line">        huffman_traversal(root_node.right, tmp_array, f)</span><br><span class="line">        huffman_traversal.count -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        huffman_traversal.output_bits[root_node.data] = huffman_traversal.count  <span class="comment"># 得出每个元素的编码值</span></span><br><span class="line">        bit_stream = <span class="string">&#x27;&#x27;</span>.join(<span class="built_in">str</span>(cell) <span class="keyword">for</span> cell <span class="keyword">in</span> tmp_array[<span class="number">1</span>:huffman_traversal.count])</span><br><span class="line">        color = <span class="built_in">str</span>(root_node.data)</span><br><span class="line">        wr_str = color + <span class="string">&#x27;&#x27;</span> + bit_stream + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">        f.write(wr_str)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">root_node = tree(probabilities)</span><br><span class="line">tmp_array = np.ones([<span class="number">4</span>], dtype=<span class="built_in">int</span>)</span><br><span class="line">huffman_traversal.output_bits = np.empty(<span class="number">5</span>, dtype=<span class="built_in">int</span>)</span><br><span class="line">huffman_traversal.count = <span class="number">0</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;code.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">huffman_traversal(root_node, tmp_array, f)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>哈夫曼编码根据信息论进行数据编码构造，能够达到接近理论最优的效率，但也存在编码过于复杂的问题</li>
</ul>
<h3 id="2-2-算术编码"><a href="#2-2-算术编码" class="headerlink" title="2.2 算术编码"></a>2.2 算术编码</h3><ul>
<li>在算术编码中，信源符号和编码之间的一一对应关系并不存在。一个算术编码要赋给整个信源符号序列，而编码本身确定 0 和 1 之间的 1 一个实数区间。随着符号序列中的符号数量增加，用来代表它的区间减小而表达区间的信息单位数量变大。</li>
<li>算术编码的具体方法是：将编码的信源消息表示成实数轴 0~1 的一个间隔，消息越长，编码表示的间隔越小，即这一间隔所需的二进制位越多。</li>
<li>与哈夫曼编码不同，采用算术编码每个符号的平均编码长度可以为小数。</li>
<li>算术编码的思想如下。（1）对一组信源符号，按照符号的概率大小排序，将[0,1)设为当前分析区间。按信源符号的概率序列，在当前分析区间划分比例间隔。（2）检索“输入消息序列”，锁定当前消息符号（初次检索的话就是第一个消息符号），找到当前符号在当前分析区间的比例间隔，将此间隔作为新的当前分析区间，并把当前分析区间的起点（即左端点）指示的数补加到编码输出数里。当前消息符号指针后移。（3）仍然按照信源符号的概率序列在当前分析区间划分比例间隔。然后重复第二步，直到输入消息序列检索完毕为止。（4）最后的编码输出数就是编码好的数据。</li>
<li>在算术编码中需要注意 3 个问题。（1）由于实际计算机的精度不可能无限长，运算中出现溢出是一个明显的问题，但多数计算机都有 16 位、32 位、64 位的精度，因此这个问题可以使用比例缩放方法解决。（2）算术编码器是一种对错误很敏感的方法，如果有一位发生错误，就会导致整个消息翻译错误。</li>
<li>算术编码可以是静态的或者自适应的。在静态算术编码中，信源符号的概率是固定的。在自适应算术编码中，信源符号的概率根据编码时，符号出现的频率动态的修改，在编码期间估算信源符号概率的过程叫做建模。</li>
<li>需要开发动态编码的原因是事前知道精确的信源概率是很难的，而且不切实际。</li>
</ul>
<h3 id="2-3-行程编码"><a href="#2-3-行程编码" class="headerlink" title="2.3 行程编码"></a>2.3 行程编码</h3><ul>
<li>行程长度编码（Run-Length Encoding，RLE）压缩算法是 Windows 系统中使用的一种图像文件压缩方法，基本思想是：将一扫描行中颜色值相同的相邻像素用两个字段表示，第一个字段是一个计数值，用于指定像素重复的次数；第二个字段是具体像素的值，主要通过压缩除掉数据中的冗余字节或字节中的冗余位，从而达到减少文件所占空间的目的。</li>
<li>译码时按照与编码时采用的相同规则进行，还原后得到的数据与压缩前的数据完全相同。因此，RLE 是无损压缩技术。RLE 编码简单直观，编码&#x2F;解码速度快。</li>
<li>RLE 所能获得的压缩比主要取决于图像本身的特点，图像中具有相同颜色的图像块越大，图像块数目越少，压缩比就越高。</li>
<li>行程编码适合于对二值图像的编码，如果图像由很多块颜色会灰度相同的大面积区域组成，采用行程编码可以达到很大的压缩比。</li>
</ul>
<h3 id="2-4-LZW-编码"><a href="#2-4-LZW-编码" class="headerlink" title="2.4 LZW 编码"></a>2.4 LZW 编码</h3><ul>
<li>LZW 编码是一种无损压缩技术。该算法通过建立编译表，实现字符重用与编码，适用于信源中重复率很高的数据压缩，</li>
<li>LZW 压缩有 3 个重要的对象：数据流（CharStream），编码流（CodeStream），编译表（String Table）。</li>
<li>编码时，数据流是输入对象（文本文件的数据序列），编码流就是输出对象（经过压缩运算的编码数据）；解码时，编码流是输入对象，数据流是输出对象；而编译表是编码和解码时都需要借助的对象。</li>
<li>LZW 压缩算法的基本原理：提取原始文本文件数据中的不同字符，基于这些字符创建一个编译表，然后用编译表中的字符的索引，代替原始文本文件数据中相应字符，减少原始数据大小。编译表不是事前创建好的，而是根据原始文件数据动态创建的，解码时还要从已编码的数据中还原出原来的编译表。</li>
<li>LZW 的基本概念如下。</li>
<li>字符（Character）：最基础的数据元素，在文本文件中就是一个字节，在光栅数据中就是一个像素的颜色在指定颜色列表中的索引值。</li>
<li>字符串（String）：由几个连续的字符组成。</li>
<li>前缀（Prefix）：也是一个字符串，通常用在另一个字符的前面，而且它的长度可以为 0。</li>
<li>根（Root）：一个长度的字符串。</li>
<li>编码（Code）：一个数字，按照固定长度（编码长度）从编码流中取出，编译表的映射值。</li>
<li>图案：一个字符串，按不定长度从数据流中读出，映射到编译表条目。</li>
<li>针对该编码过程的仿真实验代码如下。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">string = <span class="string">&#x27;abbababac&#x27;</span></span><br><span class="line">dictionary = &#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;c&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line">last = <span class="number">4</span></span><br><span class="line">p = <span class="string">&quot;&quot;</span></span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> string:</span><br><span class="line">    pc = p + c</span><br><span class="line">    <span class="keyword">if</span> pc <span class="keyword">in</span> dictionary:</span><br><span class="line">        p = pc</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result.append(dictionary[p])</span><br><span class="line">        dictionary[pc] = last</span><br><span class="line">        last += <span class="number">1</span></span><br><span class="line">        p = c</span><br><span class="line"><span class="keyword">if</span> p != <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">    result.append(dictionary[p])</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3-预测编码"><a href="#3-预测编码" class="headerlink" title="3 预测编码"></a>3 预测编码</h2><ul>
<li>预测编码压缩技术建立在信号数据的相关性上，根据某一模型利用以前的样本值对新样本进行预测，以此减少数据在时间和空间上的相关性，从而达到压缩数据的目的。</li>
<li>预测编码的基本思想是：通过每个像素中新增信息进行提取和编码，以此消除像素之间的冗余，这里的新增信息是指像素当前实际值和预测值的差。如果已知图像一个像素离散幅度的真实值，利用其相邻像素的相关性，预测它的可能数值。</li>
<li>预测编码算法属于有损编码。<br><img src="/../img/post/DigitalImageProcessing-ImageCompression/picture2.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="3-DPCM-编码"><a href="#3-DPCM-编码" class="headerlink" title="3 DPCM 编码"></a>3 DPCM 编码</h3><ul>
<li>模拟量到数字量的转换过程是脉冲编码调制过程（Pulse Code Modulation，PCM）。对于图像而言，直接以 PCM 编码存储量很大。</li>
<li>预测编码可以利用相邻像素之间的相关性，用前面已出现的像素值估计当前像素值，对实际值与估计值的差值进行编码。</li>
<li>DPCM 编码的基本步骤：（1）读取待压缩图像。（2）计算预测器产生的误差。（3）量化误差。</li>
<li>解码器流程：<br>（1）接收数据的量化误差<br>（2）计算样本的预测值<br>（3）将误差加到预测值中。</li>
</ul>
<h2 id="4-变换编码"><a href="#4-变换编码" class="headerlink" title="4 变换编码"></a>4 变换编码</h2><ul>
<li>变换编码不是直接对空域图像进行编码，而是首先将空域图像信号映射变换到另一个正交矢量空间（变换域或频域），产生一批变换系数，然后对这些变换系数进行编码处理。</li>
<li>变换编码是一种间接编码方法，其中关键问题是在时域或空域描述时，数据之间相关性大，数据冗余度大，经过变换在变换域中描述，数据相关性大大减少，数据冗余量减少，参数独立，数据量少，这样再进行量化，编码就能得到较大的压缩比。</li>
<li>基于变换编码的图像压缩和解压过程<br><img src="/../img/post/DigitalImageProcessing-ImageCompression/picture3.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="4-1-K-L-编码"><a href="#4-1-K-L-编码" class="headerlink" title="4.1 K-L 编码"></a>4.1 K-L 编码</h3><ul>
<li>K-L 变换又称 Hotelling 变换，特征向量变换或主分量方法。K-L 变换可使原来多波段图像经变换后提供出一组不相关的图像变量，最前面的主分量具有较大的方差，包含了原始影像的主要信息，所以要集中表达信息，突出图像某些细节特征，可采用主分量变换完成。</li>
<li>K-L 变换的主要思想<br>（1）目的是寻找任意统计分布的数据集合主要分量的子集。<br>（2）基向量满足相互正交性，且由它定义的空间最优地考虑了数据的相关性。<br>（3）将原始数据集合变换到主分量空间，使单一样本的互相关性降到最低点。</li>
</ul>
<h3 id="4-2-离散余弦变换"><a href="#4-2-离散余弦变换" class="headerlink" title="4.2 离散余弦变换"></a>4.2 离散余弦变换</h3><ul>
<li>离散余弦变换（DCT），经常被信号处理和图像处理使用，用于对信号和图像（包括静止图像和运动图像）进行有损数据压缩。这是由于离散余弦变换具有很强的“能量集中”特性：大多数的自然信号（包括声音和图像）的能量都集中在离散余弦变换后的低频部分，而且当信号具有接近马尔可夫过程的统计特性时，离散余弦变换的去相关性接近于 K-L 变换的性能。<br>（1）分块：在对输入图像进行 DCT 前，需要将图像分成子块。<br>（2）变换：对每个块的每行进行 DCT，然后对每列进行变换，得到的是一个变换系数矩阵。<br>（3）(0,0)位置的元素就是直流分量，矩阵中的其他元素根据其位置，表示不同频率的交流分量。</li>
</ul>
<h2 id="5-JPEG-编码"><a href="#5-JPEG-编码" class="headerlink" title="5 JPEG 编码"></a>5 JPEG 编码</h2><ul>
<li>JPEG（Joint Picture Expert Group）是由 ISO（国际标准化组织）和 CCITT（国际电话电报咨询委员会）联合成立的专家组负责制定静态图像（彩色与灰度图像）的压缩算法。</li>
<li>该编码方案定义了 3 种编码系统：<br>（1）基于 DCT 的有损编码基本系统，可用于绝大多数压缩应用场合。<br>（2）用于高压缩比、高精确度或渐近重建应用的扩展编码系统。<br>（3）用于无失真应用场合的无损系统。</li>
</ul>
<p><img src="/../img/post/DigitalImageProcessing-ImageCompression/picture4.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
]]></content>
      <categories>
        <category>学习记录类</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>小波变换</title>
    <url>/2021/06/12/DigitalImageProcessing-WaveletTransform/</url>
    <content><![CDATA[<h1 id="图像小波变换与多分辨率"><a href="#图像小波变换与多分辨率" class="headerlink" title="图像小波变换与多分辨率"></a>图像小波变换与多分辨率</h1><ul>
<li>小波变换是近年来图像处理中十分受重视的新技术，面向图像压缩、特征检测、纹理分析等提出了很多新方法，如多分辨率分析、时频域分析、金字塔算法等，都属于小波变换的范畴。</li>
<li>信号分析是为了时间和频率之间的相互关系。傅里叶变换提供了有关频域的信息，但有关时间的局部化信息却基本丢失。与傅里叶变换不同，小波变换是通过缩放母小波（Mother Wavelet）的宽度获得信号的频域特征，通过平移母小波获得信号的时间信息。对母小波的缩放和平移是为了计算小波系数，这些小波系数反映了小波和局部信号之间的相关程度。</li>
<li>像傅里叶分析一样，小波分析就是把一个信号分解为将母小波经过缩放和平移之后的一系列小波，因此小波是小波变换的基函数。小波变换可以理解为用经过缩放和平移的一系列小波函数，代替傅里叶变换的正弦波和余弦波进行傅里叶变换的结果。</li>
<li>小波变换中的 <code>小</code>是指在时域具有紧支集或近似紧支集，<code>波</code>是指具有正负交替的波动性，直流分量为 0。小波本质上是定义在有限间隔而且其平均值为 0 的一种函数。</li>
<li>与傅里叶变换相比，小波变换是空间（时间）和频率的局部变换，通过伸缩平移运算，对信号逐步进行多尺度细化，最终达到高频处时间细分，低频处频率细分，能自动适应时频信号分析的要求，从而可聚焦到信号的任意细节。</li>
<li>小波变换是基于具有变化的频率和有限持续时间的小型波进行的。</li>
</ul>
<h2 id="1-从傅里叶变换到小波变换"><a href="#1-从傅里叶变换到小波变换" class="headerlink" title="1 从傅里叶变换到小波变换"></a>1 从傅里叶变换到小波变换</h2><h3 id="1-1-小波"><a href="#1-1-小波" class="headerlink" title="1.1 小波"></a>1.1 小波</h3><h4 id="小波的概念"><a href="#小波的概念" class="headerlink" title="小波的概念"></a>小波的概念</h4><ul>
<li>小波是在有限时间范围内变化且其平均值为 0 的数学函数。具有两个特点。（1）具有有限的持续时间和突变的频率和振幅。（2）在有限的时间范围内，它的平均值为 0</li>
<li>小波变换的结果为各种小波系数，这些系数由尺度和位移函数组成。</li>
</ul>
<h4 id="小波变换"><a href="#小波变换" class="headerlink" title="小波变换"></a>小波变换</h4><ul>
<li>通过小波对一个信号在空间和时间上进行局部化的一种数学变换，通过平移母小波，捕获到信号信息。通过缩放母小波的宽度捕获到信号的频域特性。对母小波的平移和缩放操作是为计算小波分量的系数，这些系数代表局部信号和小波之间的相互关系，这些参数反映了信号的时间属性和频率属性。</li>
</ul>
<h3 id="1-2-感性认识小波变换"><a href="#1-2-感性认识小波变换" class="headerlink" title="1.2 感性认识小波变换"></a>1.2 感性认识小波变换</h3><ul>
<li>傅里叶变换一直是信号处理领域应用最广泛、效果最好的一种分析手段，是时域到频域互相转化的工具。从物理意义上，傅里叶变换的实质是把对原函数的研究转化为对其傅里叶变换的研究。但是，傅里叶变换只能提供信号在整个时域上的频率，不能提供信号在某个局部时间段上的频率信息。</li>
<li>傅里叶变换：在时域的常量函数，在频域将表现为冲击函数，表明具有很好的频域局部化性质。<br><img src="/../img/post/DigitalImageProcessing-WaveletTransform/picture1.png" alt="在这里插入图片描述" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.fftpack <span class="keyword">import</span> fft</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">t = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">400</span>, endpoint=<span class="literal">False</span>)</span><br><span class="line">cond = [t &lt; <span class="number">0.25</span>, (t &gt;= <span class="number">0.25</span>) &amp; (t &lt; <span class="number">0.5</span>), t &gt;= <span class="number">0.5</span>]</span><br><span class="line">f1 = <span class="keyword">lambda</span> t: np.cos(<span class="number">2</span> * np.pi * <span class="number">10</span> * t)</span><br><span class="line">f2 = <span class="keyword">lambda</span> t: np.cos(<span class="number">2</span> * np.pi * <span class="number">50</span> * t)</span><br><span class="line">f3 = <span class="keyword">lambda</span> t: np.cos(<span class="number">2</span> * np.pi * <span class="number">100</span> * t)</span><br><span class="line">y1 = np.piecewise(t, cond, [f1, f2, f3])</span><br><span class="line">y2 = np.piecewise(t, cond, [f2, f1, f3])</span><br><span class="line">Y1 = <span class="built_in">abs</span>(fft(y1))</span><br><span class="line">Y2 = <span class="built_in">abs</span>(fft(y2))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">9</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(t, y1)</span><br><span class="line">plt.title(<span class="string">&#x27;信号1 时间域&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;时间/s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">400</span>), Y1)</span><br><span class="line">plt.title(<span class="string">&#x27;信号1 频率域&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;频率/Hz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(t, y2)</span><br><span class="line">plt.title(<span class="string">&#x27;信号2 时间域&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;时间/s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">400</span>), Y2)</span><br><span class="line">plt.title(<span class="string">&#x27;信号2 频率域&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;频率/Hz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>从时域上看，相差很大的两个信号，在频域上却非常相近。一个很自然的方法是加窗（短时距傅里叶变换），将长时间信号分成数个较短的等长信号，然后再分别对每个窗进行傅里叶变换，从而得到频率随时间的变化，这就是短时距傅里叶变换<br><img src="/../img/post/DigitalImageProcessing-WaveletTransform/picture2.png" alt="在这里插入图片描述" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>小波变换可以解决这个问题。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pywt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">t = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">400</span>, endpoint=<span class="literal">False</span>)</span><br><span class="line">cond = [t &lt; <span class="number">0.25</span>, (t &gt;= <span class="number">0.25</span>) &amp; (t &lt; <span class="number">0.5</span>), t &gt;= <span class="number">0.5</span>]</span><br><span class="line"></span><br><span class="line">f1 = <span class="keyword">lambda</span> t: np.cos(<span class="number">2</span> * np.pi * <span class="number">10</span> * t)</span><br><span class="line">f2 = <span class="keyword">lambda</span> t: np.cos(<span class="number">2</span> * np.pi * <span class="number">50</span> * t)</span><br><span class="line">f3 = <span class="keyword">lambda</span> t: np.cos(<span class="number">2</span> * np.pi * <span class="number">100</span> * t)</span><br><span class="line"></span><br><span class="line">y1 = np.piecewise(t, cond, [f1, f2, f3])</span><br><span class="line">y2 = np.piecewise(t, cond, [f2, f1, f3])</span><br><span class="line"></span><br><span class="line">cwtmatr1, freqs1 = pywt.cwt(y1, np.arange(<span class="number">1</span>, <span class="number">200</span>), <span class="string">&#x27;cgau8&#x27;</span>, <span class="number">1</span> / <span class="number">400</span>)</span><br><span class="line">cwtmatr2, freqs2 = pywt.cwt(y2, np.arange(<span class="number">1</span>, <span class="number">200</span>), <span class="string">&#x27;cgau8&#x27;</span>, <span class="number">1</span> / <span class="number">400</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">9</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(t, y1)</span><br><span class="line">plt.title(<span class="string">&#x27;信号1 时间域&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;时间/s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.contourf(t, freqs1, <span class="built_in">abs</span>(cwtmatr1))</span><br><span class="line">plt.title(<span class="string">&#x27;信号1 时间频率关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;时间/s&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;频率/Hz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(t, y2)</span><br><span class="line">plt.title(<span class="string">&#x27;信号2 时间域&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;时间/s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.contourf(t, freqs2, <span class="built_in">abs</span>(cwtmatr2))</span><br><span class="line">plt.title(<span class="string">&#x27;信号2 时间频率关系&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;时间/s&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;频率/Hz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>图中不仅可以看到信号中有哪些频率，还可以看到不同的频率成分在什么时间出现。傅里叶变换类似棱镜，可以将不同的信号分解。小波变换类似于显微镜，不仅知道信号中有哪些成分，还可以知道各种成分在什么位置出现。<br><img src="/../img/post/DigitalImageProcessing-WaveletTransform/picture3.png" alt="在这里插入图片描述" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
<li>经典的傅里叶变换把信号按正弦、余弦展开，将任意函数表示为具有不同频率的谐波函数的线性叠加，能较好的刻画信号的频率特性。但在时空域上无任何分辨，不能做局部分析。</li>
<li>小波分析优于傅里叶分析之处在于：小波分析在时域和频域同时具有良好的局部化性质，因为小波函数是紧支集，而正弦、余弦的区间是无穷区间，所以小波变换可以对高频成分采用逐渐精细的时域或空域取代步长。，从而可以聚焦到对象的任意细节。</li>
</ul>
<h2 id="2-简单小波示例"><a href="#2-简单小波示例" class="headerlink" title="2 简单小波示例"></a>2 简单小波示例</h2><h3 id="2-1-哈尔小波构建"><a href="#2-1-哈尔小波构建" class="headerlink" title="2.1 哈尔小波构建"></a>2.1 哈尔小波构建</h3><ul>
<li>哈尔基函数可以捕捉到信号的尺度信息，而哈尔小波函数信号的细节信息。哈尔小波变换要做的就是将信号分解到不同的基函数及小波函数上，并求每个函数对应分量的值。</li>
<li>哈尔小波具有如下特点：<br>（1）哈尔小波在时域是紧支撑的，即其非零区间为[0,1)<br>（2）哈尔小波属于正交小波。<br>（3）哈尔小波是对称的。系统的单位冲击响应若具有对称性，则该系统具有线性相位，这对于去除相位失真是非常有利的，哈尔小波是目前唯一一个具有对称性，又是有限支撑的正交小波。<br>（4）哈尔小波仅取+1 和-1，计算简单。<br>（5）哈尔小波是不连续小波，在实际的信号分析与处理中受到了限制。</li>
</ul>
<h2 id="3-图像多分辨率"><a href="#3-图像多分辨率" class="headerlink" title="3 图像多分辨率"></a>3 图像多分辨率</h2><h3 id="3-1-小波多分辨率"><a href="#3-1-小波多分辨率" class="headerlink" title="3.1 小波多分辨率"></a>3.1 小波多分辨率</h3><ul>
<li>多分辨分析是小波分析中最重要的概念之一，将一个函数表示为一个低频成分与不同分辨率下的高频成分，并且多分辨分析能提供一种构造小波的统一框架，提供函数分解与重构的快速算法。</li>
<li>单调性。</li>
<li>伸缩性。</li>
<li>平移不变性。</li>
<li>Riesz 基。</li>
</ul>
<h3 id="3-2-图像金字塔"><a href="#3-2-图像金字塔" class="headerlink" title="3.2 图像金字塔"></a>3.2 图像金字塔</h3><ul>
<li>当观察图象时，通常看到是相连接的纹理与灰度级相似的区域，它们相互结合形成物体。如果物体的尺寸较小或者对比度不高，通常采用较高的分辨率观察；如果物体的尺寸很大或者对比度很强，只需要较低的分辨率。</li>
<li>如果物体的尺寸有大有小，或者对比度有强有弱的情况同时发生，那么，以若干个分辨率对他们进行研究将具有优势。</li>
<li>以多分辨率解释图像的一种有效但概念简单的结构是图像金字塔，图像金字塔最初用于机器视觉或者图像压缩，将图像表示为一系列分辨率逐渐降低的集合。</li>
<li>多分辨率分析：将信号或图像用多种分辨率层次表示。在某个分辨率层次上难以检测到的特征，可能很容易在其他分辨率特征上检测出来，每层中包含一个近似图像和一个残差图像，多种分辨率层次联合起来可以称为图像金字塔。<br><img src="/../img/post/DigitalImageProcessing-WaveletTransform/picture4.png" alt="在这里插入图片描述" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="3-3-图像子带编码"><a href="#3-3-图像子带编码" class="headerlink" title="3.3 图像子带编码"></a>3.3 图像子带编码</h3><ul>
<li>在子带编码中，一幅图像被分解成一系列频带受限的分量，称为子带。子带可以重组在一起，无失真的重建原始图像。每个子带通过对输入图像进行带通滤波而得到。</li>
</ul>
<h2 id="4-图像小波变换"><a href="#4-图像小波变换" class="headerlink" title="4 图像小波变换"></a>4 图像小波变换</h2><h3 id="4-1-二维小波变换基础"><a href="#4-1-二维小波变换基础" class="headerlink" title="4.1 二维小波变换基础"></a>4.1 二维小波变换基础</h3><ul>
<li>通过小波变换得到 N 个小波系数，而二维离散小波变换输入的是二维矩阵，每个步骤输出的是近似图像，水平细节，垂直细节和对角细节</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pywt.data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">original = pywt.data.camera()</span><br><span class="line"><span class="comment"># Wavelet transform of image, and plot approximation and details</span></span><br><span class="line">titles = [<span class="string">&#x27;近似图像&#x27;</span>, <span class="string">&#x27;水平细节&#x27;</span>, <span class="string">&#x27;垂直细节&#x27;</span>, <span class="string">&#x27;对角线细节&#x27;</span>]</span><br><span class="line">coeffs2 = pywt.dwt2(original, <span class="string">&#x27;haar&#x27;</span>)</span><br><span class="line">LL, (LH, HL, HH) = coeffs2</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> i, a <span class="keyword">in</span> <span class="built_in">enumerate</span>([LL, LH, HL, HH]):</span><br><span class="line">    ax = fig.add_subplot(<span class="number">1</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">    ax.imshow(a, interpolation=<span class="string">&quot;nearest&quot;</span>, cmap=plt.cm.gray)</span><br><span class="line">    ax.set_title(titles[i], fontsize=<span class="number">10</span>)</span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([])</span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>基于哈尔小波对图像进行二维小波变换结果<br><img src="/../img/post/DigitalImageProcessing-WaveletTransform/picture5.png" alt="在这里插入图片描述" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<h3 id="4-2-小波变换在图像处理中的应用"><a href="#4-2-小波变换在图像处理中的应用" class="headerlink" title="4.2 小波变换在图像处理中的应用"></a>4.2 小波变换在图像处理中的应用</h3><ul>
<li>小波变换在图像处理中的应用与傅里叶变换类似，基本方法是：（1）计算一幅图像的二维小波变换，并得到小波系数（2）对小波系数进行修改，保留有效成分，过滤不必要成分（3）使用修改后的小波系数进行图像重建</li>
<li>基于小波变换的图像去噪步骤<br>（1）图像小波变换。选择一个小波，计算噪声图像的小波系数。<br>（2）对细节系数通过阈值进行过滤。选择一个细节系数阈值，并对所有细节系数进行阈值化操作。<br>（3）基于阈值化过滤后的细节系数及原始近似系数，使用小波变换对图像进行重建。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pywt</span><br><span class="line"><span class="keyword">from</span> skimage.restoration <span class="keyword">import</span> denoise_wavelet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">x = pywt.data.ecg().astype(<span class="built_in">float</span>) / <span class="number">256</span></span><br><span class="line"></span><br><span class="line">sigma = <span class="number">.05</span></span><br><span class="line">x_noisy = x + sigma * np.random.randn(x.size)</span><br><span class="line">x_denoise = denoise_wavelet(x_noisy, sigma=sigma, wavelet=<span class="string">&#x27;sym4&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">311</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始信号&#x27;</span>)</span><br><span class="line">plt.plot(x)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">312</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;加噪图像&#x27;</span>)</span><br><span class="line">plt.plot(x_noisy)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">313</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;去噪图像&#x27;</span>)</span><br><span class="line">plt.plot(x_denoise)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>小波对一维信号去噪<br><img src="/../img/post/DigitalImageProcessing-WaveletTransform/picture6.png" alt="在这里插入图片描述" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage.restoration <span class="keyword">import</span> (denoise_wavelet, estimate_sigma)</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, img_as_float</span><br><span class="line"><span class="keyword">from</span> skimage.util <span class="keyword">import</span> random_noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示工具函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_ch</span>():</span><br><span class="line">    <span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>]</span><br><span class="line">    mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set_ch()</span><br><span class="line">original = img_as_float(data.coffee())</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始图像&#x27;</span>)</span><br><span class="line">plt.imshow(original)</span><br><span class="line"></span><br><span class="line">sigma = <span class="number">0.2</span></span><br><span class="line">noisy = random_noise(original, var=sigma ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;加噪图像&#x27;</span>)</span><br><span class="line">plt.imshow(noisy)</span><br><span class="line"></span><br><span class="line">im_haar = denoise_wavelet(noisy, wavelet=<span class="string">&#x27;db2&#x27;</span>,</span><br><span class="line">                          channel_axis=-<span class="number">1</span>, convert2ycbcr=<span class="literal">True</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;使用haar去噪后&#x27;</span>)</span><br><span class="line">plt.imshow(im_haar)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同颜色通道的噪声平均标准差</span></span><br><span class="line">sigma_est = estimate_sigma(noisy, channel_axis=-<span class="number">1</span>, average_sigmas=<span class="literal">True</span>)</span><br><span class="line">im_haar_sigma = denoise_wavelet(</span><br><span class="line">    noisy, wavelet=<span class="string">&#x27;db2&#x27;</span>, channel_axis=-<span class="number">1</span>, convert2ycbcr=<span class="literal">True</span>, sigma=sigma_est)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;使用haar with sigma去噪后&#x27;</span>)</span><br><span class="line">plt.imshow(im_haar_sigma)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>二维小波图像去噪<br><img src="/../img/post/DigitalImageProcessing-WaveletTransform/picture7.png" alt="在这里插入图片描述" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></li>
</ul>
]]></content>
      <categories>
        <category>学习记录类</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>十二大常见的损失函数</title>
    <url>/2021/06/12/CommonLossFunction/</url>
    <content><![CDATA[<h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><span id="more"></span>

<p>在机器学习中，“损失函数”（Loss Function）是一个核心概念，用于量化模型的预测值与真实值之间的差异。损失函数的目的是通过最小化这个差异来训练模型，使其能够做出更准确的预测。<br>具体来说，损失函数通常定义为模型预测值与真实值之间差异的累积或平均值。在回归问题中，常用的损失函数是 <code>&lt;strong&gt;</code>均方误差（Mean Squared Error, MSE）<code>&lt;/strong&gt;</code>，它计算的是每个样本的预测值与真实值之间差异的平方的平均值。在分类问题中，常用的损失函数是 <code>&lt;strong&gt;</code>交叉熵损失（Cross-Entropy Loss）<code>&lt;/strong&gt;</code>，它衡量的是模型预测的概率分布与真实分布之间的差异。通过最小化损失函数，我们可以找到使模型在所有样本上表现最佳的参数配置。</p>
<h2 id="1-均方误差（MSE）"><a href="#1-均方误差（MSE）" class="headerlink" title="1. 均方误差（MSE）"></a>1. 均方误差（MSE）</h2><p>以下是关于均方误差损失函数（Mean Squared Error, MSE）的详细介绍，包括介绍、数学公式、工作原理、Python 代码实现以及优缺点。</p>
<h3 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h3><p>均方误差损失函数是回归问题中最常用的损失函数之一。它的目的是通过最小化预测值与真实值之间的平方差来训练模型，从而使模型能够更准确地预测结果。MSE 衡量的是模型预测性能的一种标准方法，常用于评估回归模型的准确性。</p>
<h3 id="1-2-数学公式"><a href="#1-2-数学公式" class="headerlink" title="1.2 数学公式"></a>1.2 数学公式</h3><p>均方误差损失函数的数学公式如下：</p>
<p>$$<br>MSE &#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} (y_i - \hat{y}_i)^2<br>$$</p>
<p>其中：</p>
<ul>
<li>$ n $ 是样本的数量。</li>
<li>$ y_i $ 是第 $ i $ 个样本的真实值。</li>
<li>$ \hat{y}_i $ 是第 $ i $ 个样本的预测值。</li>
<li>$ \sum $ 是求和符号，表示对所有的样本进行求和。</li>
<li>$ (y_i - \hat{y}_i)^2 $ 表示第 $ i $ 个样本的真实值和预测值之间差的平方。</li>
</ul>
<h3 id="1-3-工作原理"><a href="#1-3-工作原理" class="headerlink" title="1.3 工作原理"></a>1.3 工作原理</h3><p>MSE 损失函数的工作原理是通过计算预测值与真实值之间的平方差，并将这些平方差求和后平均，来评估模型的性能。模型的训练目标是最小化这个平均平方误差值，从而使模型的预测值更接近真实值。通过最小化 MSE，模型能够更好地拟合训练数据，提高预测准确性。</p>
<h3 id="1-4-纯-Python-代码实现"><a href="#1-4-纯-Python-代码实现" class="headerlink" title="1.4 纯 Python 代码实现"></a>1.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现 MSE 损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 真实值</span></span><br><span class="line">y_true = np.array([<span class="number">3</span>, -<span class="number">0.5</span>, <span class="number">2</span>, <span class="number">7</span>])</span><br><span class="line"><span class="comment"># 预测值</span></span><br><span class="line">y_pred = np.array([<span class="number">2.5</span>, <span class="number">0.0</span>, <span class="number">2</span>, <span class="number">8</span>])</span><br><span class="line"><span class="comment"># 计算MSE</span></span><br><span class="line">mse = np.mean((y_true - y_pred) ** <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MSE:&quot;</span>, mse)</span><br></pre></td></tr></table></figure>

<h3 id="1-5-优缺点"><a href="#1-5-优缺点" class="headerlink" title="1.5 优缺点"></a>1.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>数学性质良好</strong>：MSE 是一个连续可导的凸函数，确保了使用梯度下降等优化算法时能够找到全局最小值。</li>
<li><strong>对大误差的惩罚大</strong>：由于平方项的存在，较大的误差会对损失函数产生更大的影响，这有助于模型关注那些预测特别不准确的数据点。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>对异常值敏感</strong>：由于是误差的平方，异常值会对损失函数产生不成比例的影响，可能导致模型对异常值过于敏感。</li>
</ul>
<h2 id="2-平均绝对误差（MAE）"><a href="#2-平均绝对误差（MAE）" class="headerlink" title="2. 平均绝对误差（MAE）"></a>2. 平均绝对误差（MAE）</h2><h3 id="2-1-介绍"><a href="#2-1-介绍" class="headerlink" title="2.1 介绍"></a>2.1 介绍</h3><p>平均绝对误差（MAE）是回归问题中另一种常用的损失函数。它通过计算预测值与真实值之间差的绝对值的平均数来评估模型的性能。与均方误差（MSE）相比，MAE 对异常值不那么敏感，因此在数据中存在异常值时，MAE 可能是一个更好的选择。</p>
<h3 id="2-2-数学公式"><a href="#2-2-数学公式" class="headerlink" title="2.2 数学公式"></a>2.2 数学公式</h3><p>平均绝对误差的数学公式如下：</p>
<p>$$<br>MAE &#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} |y_i - \hat{y}_i|<br>$$</p>
<p>其中：</p>
<ul>
<li>$ n $ 是样本的数量。</li>
<li>$ y_i $ 是第 $ i $ 个样本的真实值。</li>
<li>$ \hat{y}_i $ 是第 $ i $ 个样本的预测值。</li>
<li>$ | \cdot | $ 是绝对值符号。</li>
<li>$ \sum $ 是求和符号，表示对所有的样本进行求和。</li>
</ul>
<h3 id="2-3-工作原理"><a href="#2-3-工作原理" class="headerlink" title="2.3 工作原理"></a>2.3 工作原理</h3><p>MAE 损失函数的工作原理是通过计算预测值与真实值之间的绝对差值，并将这些绝对差值求和后平均，来评估模型的性能。模型的训练目标是最小化这个平均绝对误差值，从而使模型的预测值更接近真实值。通过最小化 MAE，模型能够更好地拟合训练数据，提高预测准确性。</p>
<h3 id="2-4-纯-Python-代码实现"><a href="#2-4-纯-Python-代码实现" class="headerlink" title="2.4 纯 Python 代码实现"></a>2.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现 MAE 损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 真实值</span></span><br><span class="line">y_true = np.array([<span class="number">3</span>, -<span class="number">0.5</span>, <span class="number">2</span>, <span class="number">7</span>])</span><br><span class="line"><span class="comment"># 预测值</span></span><br><span class="line">y_pred = np.array([<span class="number">2.5</span>, <span class="number">0.0</span>, <span class="number">2</span>, <span class="number">8</span>])</span><br><span class="line"><span class="comment"># 计算MAE</span></span><br><span class="line">mae = np.mean(np.<span class="built_in">abs</span>(y_true - y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MAE:&quot;</span>, mae)</span><br></pre></td></tr></table></figure>

<h3 id="2-5-优缺点"><a href="#2-5-优缺点" class="headerlink" title="2.5 优缺点"></a>2.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>对异常值不敏感</strong>：由于使用了绝对值，MAE 对异常值的敏感度较低，因此在数据中存在异常值时，MAE 可能是一个更好的选择。</li>
<li><strong>计算简单</strong>：MAE 的计算相对简单，只需要进行基本的算术运算。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>无法体现误差的大小</strong>：MAE 不考虑误差的绝对大小，因此在预测值与真实值相差很大时，MAE 可能无法准确反映模型的性能。</li>
</ul>
<h2 id="3-hinge-损失函数（Hinge-Loss）"><a href="#3-hinge-损失函数（Hinge-Loss）" class="headerlink" title="3. hinge 损失函数（Hinge Loss）"></a>3. hinge 损失函数（Hinge Loss）</h2><h3 id="3-1-介绍"><a href="#3-1-介绍" class="headerlink" title="3.1 介绍"></a>3.1 介绍</h3><p>铰链损失函数是一种用于分类问题的损失函数，特别是在支持向量机（Support Vector Machines, SVM）中。它的目的是通过最小化分类错误的样本的损失来训练模型，同时保持其他样本的损失为零。铰链损失函数鼓励模型正确分类支持向量（即那些位于决策边界附近的样本），同时对错误分类的样本施加较大的损失。</p>
<h3 id="3-2-数学公式"><a href="#3-2-数学公式" class="headerlink" title="3.2 数学公式"></a>3.2 数学公式</h3><p>铰链损失函数的数学公式如下：<br>对于二分类问题，公式为：</p>
<p>$$<br>L(y, f(x)) &#x3D; \max(0, 1 - y f(x))<br>$$</p>
<p>其中：</p>
<ul>
<li>$ y $ 是第 $ i $ 个样本的真实标签（-1 或 1）。</li>
<li>$ f(x) $ 是第 $ i $ 个样本的预测分数。</li>
<li>$ \max(0, \cdot) $ 表示取括号内表达式的最大值，即只考虑非负部分。</li>
</ul>
<h3 id="3-3-工作原理"><a href="#3-3-工作原理" class="headerlink" title="3.3 工作原理"></a>3.3 工作原理</h3><p>铰链损失函数的工作原理是通过对错误分类的样本施加较大的损失来惩罚模型，而对正确分类的样本的损失为零。在二分类问题中，如果预测分数大于 1，则该样本被视为正类；如果预测分数小于-1，则被视为负类。如果预测分数在-1 和 1 之间，则样本被视为错误分类。铰链损失函数通过这种方式鼓励模型正确分类那些位于决策边界附近的样本，即支持向量。</p>
<h3 id="3-4-纯-Python-代码实现"><a href="#3-4-纯-Python-代码实现" class="headerlink" title="3.4 纯 Python 代码实现"></a>3.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现铰链损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hinge_loss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算铰链损失函数的值。</span></span><br><span class="line"><span class="string">    :param y_true: 真实标签，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param y_pred: 预测分数，一维数组或向量。</span></span><br><span class="line"><span class="string">    :return: 铰链损失函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算预测分数与真实标签的乘积</span></span><br><span class="line">    margin = y_true * y_pred</span><br><span class="line">    <span class="comment"># 只考虑非负部分</span></span><br><span class="line">    loss = np.maximum(<span class="number">0</span>, <span class="number">1</span> - margin)</span><br><span class="line">    <span class="comment"># 计算平均损失</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(loss)</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = np.array([<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">y_pred = np.array([<span class="number">0.5</span>, -<span class="number">0.5</span>, <span class="number">1.5</span>, -<span class="number">0.5</span>])</span><br><span class="line"><span class="comment"># 计算铰链损失</span></span><br><span class="line">hinge_loss_value = hinge_loss(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hinge Loss:&quot;</span>, hinge_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="3-5-优缺点"><a href="#3-5-优缺点" class="headerlink" title="3.5 优缺点"></a>3.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>适用于 SVM</strong>：铰链损失函数是支持向量机中的标准损失函数，适合于线性可分和近似线性可分的问题。</li>
<li><strong>对异常值不敏感</strong>：与均方误差相比，铰链损失对异常值不那么敏感。</li>
<li><strong>能够处理非线性问题</strong>：通过使用核技巧，可以扩展到非线性问题。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>对错误分类的惩罚大</strong>：铰链损失对错误分类的样本施加较大的损失，这可能导致模型在训练过程中变得过于保守。</li>
<li><strong>难以处理多分类问题</strong>：铰链损失函数主要用于二分类问题，处理多分类问题时需要使用一对多（One-vs-All）或多对多（One-vs-One）策略。</li>
<li><strong>参数敏感</strong>：铰链损失函数中的正则化参数 C 对模型的性能有很大影响，需要仔细调整。</li>
</ul>
<h2 id="4-指数损失函数（Exponential-Loss）"><a href="#4-指数损失函数（Exponential-Loss）" class="headerlink" title="4. 指数损失函数（Exponential Loss）"></a>4. 指数损失函数（Exponential Loss）</h2><h3 id="4-1-介绍"><a href="#4-1-介绍" class="headerlink" title="4.1 介绍"></a>4.1 介绍</h3><p>指数损失函数，也称为对数损失函数（Log Loss）的一种形式，是一种常用于二分类问题的损失函数。它度量的是模型预测的概率与真实标签之间的差异。指数损失函数鼓励模型对正类样本的预测概率接近 1，对负类样本的预测概率接近 0。</p>
<h3 id="4-2-数学公式"><a href="#4-2-数学公式" class="headerlink" title="4.2 数学公式"></a>4.2 数学公式</h3><p>指数损失函数的数学公式如下：<br>对于二分类问题，公式为：</p>
<p>$$<br>L(y, p) &#x3D; -y \log(p) - (1 - y) \log(1 - p)<br>$$</p>
<p>其中：</p>
<ul>
<li>$ y $ 是第 $ i $ 个样本的真实标签（0 或 1）。</li>
<li>$ p $ 是模型对正类的预测概率。</li>
<li>$ \log $ 是自然对数。</li>
</ul>
<h3 id="4-3-工作原理"><a href="#4-3-工作原理" class="headerlink" title="4.3 工作原理"></a>4.3 工作原理</h3><p>指数损失函数的工作原理是通过对正类样本的预测概率进行惩罚，如果预测概率小于真实标签，而对负类样本的预测概率进行奖励，如果预测概率大于真实标签。这种惩罚和奖励机制使得模型在训练过程中逐渐调整参数，以便对正类样本的预测概率接近 1，对负类样本的预测概率接近 0。</p>
<h3 id="4-4-纯-Python-代码实现"><a href="#4-4-纯-Python-代码实现" class="headerlink" title="4.4 纯 Python 代码实现"></a>4.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现指数损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exponential_loss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算指数损失函数的值。</span></span><br><span class="line"><span class="string">    :param y_true: 真实标签，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param y_pred: 预测概率，一维数组或向量。</span></span><br><span class="line"><span class="string">    :return: 指数损失函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算指数损失</span></span><br><span class="line">    loss = -y_true * np.log(y_pred) - (<span class="number">1</span> - y_true) * np.log(<span class="number">1</span> - y_pred)</span><br><span class="line">    <span class="comment"># 计算平均损失</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(loss)</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">y_pred = np.array([<span class="number">0.9</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.8</span>])</span><br><span class="line"><span class="comment"># 计算指数损失</span></span><br><span class="line">exponential_loss_value = exponential_loss(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Exponential Loss:&quot;</span>, exponential_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="4-5-优缺点"><a href="#4-5-优缺点" class="headerlink" title="4.5 优缺点"></a>4.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>适用于二分类问题</strong>：指数损失函数适合于二分类问题，可以有效地度量模型对正类和负类样本的预测概率。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>对预测概率的敏感度</strong>：指数损失函数对预测概率的微小变化非常敏感，可能导致模型在训练过程中对预测概率的调整不够平滑。</li>
<li><strong>可能需要正则化</strong>：在实际应用中，指数损失函数可能需要通过添加正则化项来防止过拟合。<br>通过以上介绍，您可以对指数损失函数有一个更详细的了解。</li>
</ul>
<h2 id="5-huber-损失函数（Huber-Loss）"><a href="#5-huber-损失函数（Huber-Loss）" class="headerlink" title="5. huber 损失函数（Huber Loss）"></a>5. huber 损失函数（Huber Loss）</h2><h3 id="5-1-介绍"><a href="#5-1-介绍" class="headerlink" title="5.1 介绍"></a>5.1 介绍</h3><p>Huber 损失函数是一种在回归问题中常用的损失函数，它结合了均方误差（MSE）和绝对损失（MAE）的特点。当误差较小时，Huber 损失函数接近于 MSE，这样可以保证损失函数的连续可导性；当误差较大时，Huber 损失函数变为绝对损失，这样可以减少大误差对损失函数的影响。Huber 损失函数适用于包含异常值的数据集。</p>
<h3 id="5-2-数学公式"><a href="#5-2-数学公式" class="headerlink" title="5.2 数学公式"></a>5.2 数学公式</h3><p>Huber 损失函数的数学公式如下：</p>
<p>$$<br>L(a) &#x3D; \begin{cases}<br>    \frac{1}{2}a^2 &amp; \text{for } |a| \leq \delta \<br>    \delta(|a| - \frac{1}{2}\delta) &amp; \text{for } |a| &gt; \delta<br>\end{cases}<br>$$</p>
<p>其中：</p>
<ul>
<li>$ a $ 是预测值与真实值之间的差值。</li>
<li>$ \delta $ 是 Huber 损失函数的参数，称为“delta”。</li>
</ul>
<h3 id="5-3-工作原理"><a href="#5-3-工作原理" class="headerlink" title="5.3 工作原理"></a>5.3 工作原理</h3><p>Huber 损失函数的工作原理是通过对预测值与真实值之间的差值进行平方，当差值的绝对值小于或等于 delta 时；当差值的绝对值大于 delta 时，使用 delta 乘以差值的绝对值减去 delta 的一半。这种方法使得 Huber 损失函数在预测值与真实值之间的差值较小时，接近于均方误差，而在差值较大时，接近于绝对损失。</p>
<h3 id="5-4-纯-Python-代码实现"><a href="#5-4-纯-Python-代码实现" class="headerlink" title="5.4 纯 Python 代码实现"></a>5.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现 Huber 损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">huber_loss</span>(<span class="params">y_true, y_pred, delta</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算Huber损失函数的值。</span></span><br><span class="line"><span class="string">    :param y_true: 真实值，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param y_pred: 预测值，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param delta: Huber损失函数的参数，即delta。</span></span><br><span class="line"><span class="string">    :return: Huber损失函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算预测值与真实值之间的差值</span></span><br><span class="line">    diff = y_true - y_pred</span><br><span class="line">    <span class="comment"># 计算差值的绝对值</span></span><br><span class="line">    diff_abs = np.<span class="built_in">abs</span>(diff)</span><br><span class="line">    <span class="comment"># 判断差值的绝对值是否大于delta</span></span><br><span class="line">    condition = diff_abs &lt;= delta</span><br><span class="line">    <span class="comment"># 当差值的绝对值小于等于delta时，使用均方误差</span></span><br><span class="line">    mse = <span class="number">0.5</span> * np.square(diff)</span><br><span class="line">    <span class="comment"># 当差值的绝对值大于delta时，使用绝对损失</span></span><br><span class="line">    mae = delta * (diff_abs - <span class="number">0.5</span> * delta)</span><br><span class="line">    <span class="comment"># 合并两种情况</span></span><br><span class="line">    loss = np.where(condition, mse, mae)</span><br><span class="line">    <span class="comment"># 计算平均损失</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(loss)</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = np.array([<span class="number">3</span>, -<span class="number">0.5</span>, <span class="number">2</span>, <span class="number">7</span>])</span><br><span class="line">y_pred = np.array([<span class="number">2.5</span>, <span class="number">0.0</span>, <span class="number">2</span>, <span class="number">8</span>])</span><br><span class="line">delta = <span class="number">1.0</span></span><br><span class="line"><span class="comment"># 计算Huber损失</span></span><br><span class="line">huber_loss_value = huber_loss(y_true, y_pred, delta)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Huber Loss:&quot;</span>, huber_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="5-5-优缺点"><a href="#5-5-优缺点" class="headerlink" title="5.5 优缺点"></a>5.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>对异常值不敏感</strong>：Huber 损失函数对异常值不敏感，适用于包含异常值的数据集。</li>
<li><strong>平滑过渡</strong>：Huber 损失函数在均方误差和绝对损失之间平滑过渡，可以减少模型对异常值的敏感度。</li>
<li><strong>易于实现</strong>：Huber 损失函数的实现相对简单，可以通过调整 delta 参数来适应不同的数据集。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>参数敏感</strong>：Huber 损失函数的性能依赖于 delta 参数的选择，选择不当可能会影响模型的性能。</li>
<li><strong>计算复杂度</strong>：与均方误差相比，Huber 损失函数的计算复杂度略高，因为需要对每个样本的差值进行判断和计算。</li>
</ul>
<h2 id="6-KL-散度函数（相对熵）"><a href="#6-KL-散度函数（相对熵）" class="headerlink" title="6. KL 散度函数（相对熵）"></a>6. KL 散度函数（相对熵）</h2><h3 id="6-1-介绍"><a href="#6-1-介绍" class="headerlink" title="6.1 介绍"></a>6.1 介绍</h3><p>KL 散度函数，也称为相对熵，是一种衡量两个概率分布之间差异的度量。在机器学习中，KL 散度常用于比较模型的预测分布与真实分布或另一个模型的分布。KL 散度是非对称的，表示从分布 $ P $ 到分布 $ Q $ 的差异，而 $ Q $ 到 $ P $ 的差异可能不同。</p>
<h3 id="6-2-数学公式"><a href="#6-2-数学公式" class="headerlink" title="6.2 数学公式"></a>6.2 数学公式</h3><p>KL 散度函数的数学公式如下：</p>
<p>$$<br>D_{KL}(P || Q) &#x3D; \sum_{i} P(i) \log_2 \left( \frac{P(i)}{Q(i)} \right)<br>$$</p>
<p>其中：</p>
<ul>
<li>$ P $ 和 $ Q $ 是两个概率分布。</li>
<li>$ P(i) $ 是分布 $ P $ 中第 $ i $ 个事件的概率。</li>
<li>$ Q(i) $ 是分布 $ Q $ 中第 $ i $ 个事件的概率。</li>
<li>$ \log_2 $ 是以 2 为底的对数。</li>
</ul>
<h3 id="6-3-工作原理"><a href="#6-3-工作原理" class="headerlink" title="6.3 工作原理"></a>6.3 工作原理</h3><p>KL 散度的工作原理是通过比较两个概率分布的每个事件的对数比值，来度量它们之间的差异。如果两个分布完全相同，那么 KL 散度为 0。如果一个分布的概率大于另一个分布的概率，那么这个分布的概率的对数比值会大于 1，从而增加 KL 散度的值。KL 散度越大，表示两个分布的差异越大。</p>
<h3 id="6-4-纯-Python-代码实现"><a href="#6-4-纯-Python-代码实现" class="headerlink" title="6.4 纯 Python 代码实现"></a>6.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现 KL 散度函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kl_divergence</span>(<span class="params">P, Q</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算KL散度函数的值。</span></span><br><span class="line"><span class="string">    :param P: 第一个概率分布，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param Q: 第二个概率分布，一维数组或向量。</span></span><br><span class="line"><span class="string">    :return: KL散度函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算KL散度</span></span><br><span class="line">    kl = np.<span class="built_in">sum</span>(P * np.log2(P / Q))</span><br><span class="line">    <span class="keyword">return</span> kl</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">P = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>])</span><br><span class="line">Q = np.array([<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.3</span>])</span><br><span class="line"><span class="comment"># 计算KL散度</span></span><br><span class="line">kl_divergence_value = kl_divergence(P, Q)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;KL Divergence:&quot;</span>, kl_divergence_value)</span><br></pre></td></tr></table></figure>

<h3 id="6-5-优缺点"><a href="#6-5-优缺点" class="headerlink" title="6.5 优缺点"></a>6.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>信息论背景</strong>：KL 散度是基于信息论的概念，具有坚实的理论基础。</li>
<li><strong>非对称性</strong>：KL 散度反映了从分布 $ P $ 到分布 $ Q $ 的转换信息，这有助于理解数据或模型在转换过程中的变化。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>不满足对称性</strong>：KL 散度不满足对称性，即 $ D*{KL}(P || Q) \neq D*{KL}(Q || P) $，这使得它在对称情况下可能不是衡量两个分布差异的最佳选择。</li>
<li><strong>对极值敏感</strong>：KL 散度对概率分布的极值非常敏感，这可能导致在处理具有不同峰值和形状的分布时产生较大的差异。</li>
<li><strong>不适用于非概率分布</strong>：KL 散度是专门为概率分布设计的，不适用于非概率分布的比较。</li>
</ul>
<h2 id="7-交叉熵损失（Cross-Entropy-Loss）"><a href="#7-交叉熵损失（Cross-Entropy-Loss）" class="headerlink" title="7. 交叉熵损失（Cross-Entropy Loss）"></a>7. 交叉熵损失（Cross-Entropy Loss）</h2><h3 id="7-1-介绍"><a href="#7-1-介绍" class="headerlink" title="7.1 介绍"></a>7.1 介绍</h3><p>交叉熵损失是一种常用于分类问题的损失函数，特别是在神经网络中。它的目的是度量实际输出与期望输出之间的差异。交叉熵损失鼓励模型输出概率分布与真实标签的分布尽可能接近。</p>
<h3 id="7-2-数学公式"><a href="#7-2-数学公式" class="headerlink" title="7.2 数学公式"></a>7.2 数学公式</h3><p>对于二分类问题，交叉熵损失的数学公式如下：</p>
<p>$$<br>L(y, p) &#x3D; -y \log(p)<br>$$</p>
<p>其中：</p>
<ul>
<li>$ y $ 是第 $ i $ 个样本的真实标签（0 或 1）。</li>
<li>$ p $ 是模型对正类的预测概率。</li>
<li>$ \log $ 是自然对数。<br>对于多分类问题，交叉熵损失的数学公式通常采用 softmax 函数将输出转换为概率分布，然后计算对数似然损失：<br>$$<br>L(y, p) &#x3D; -\sum_{i} y_i \log(p_i)<br>$$<br>其中：</li>
<li>$ y $ 是真实标签的 one-hot 编码。</li>
<li>$ p $ 是模型的预测概率分布。</li>
<li>$ \log $ 是自然对数。</li>
</ul>
<h3 id="7-3-工作原理"><a href="#7-3-工作原理" class="headerlink" title="7.3 工作原理"></a>7.3 工作原理</h3><p>交叉熵损失的工作原理是通过计算模型预测的概率分布与真实标签的分布之间的对数似然比，来度量它们之间的差异。对于二分类问题，如果模型正确预测了正类，那么对数似然比为正，交叉熵损失为负；如果模型错误预测了正类，那么对数似然比为负，交叉熵损失为正。对于多分类问题，交叉熵损失通过计算每个类别的对数似然比，然后求和来评估整个概率分布的差异。</p>
<h3 id="7-4-纯-Python-代码实现"><a href="#7-4-纯-Python-代码实现" class="headerlink" title="7.4 纯 Python 代码实现"></a>7.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现交叉熵损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy_loss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算交叉熵损失函数的值。</span></span><br><span class="line"><span class="string">    :param y_true: 真实标签，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param y_pred: 预测概率，二维数组或矩阵。</span></span><br><span class="line"><span class="string">    :return: 交叉熵损失函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算交叉熵损失</span></span><br><span class="line">    loss = -np.<span class="built_in">sum</span>(y_true * np.log(y_pred))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">y_pred = np.array([[<span class="number">0.9</span>, <span class="number">0.1</span>],</span><br><span class="line">                   [<span class="number">0.1</span>, <span class="number">0.9</span>],</span><br><span class="line">                   [<span class="number">0.8</span>, <span class="number">0.2</span>],</span><br><span class="line">                   [<span class="number">0.2</span>, <span class="number">0.8</span>]])</span><br><span class="line"><span class="comment"># 计算交叉熵损失</span></span><br><span class="line">cross_entropy_loss_value = cross_entropy_loss(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Cross-Entropy Loss:&quot;</span>, cross_entropy_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="7-5-优缺点"><a href="#7-5-优缺点" class="headerlink" title="7.5 优缺点"></a>7.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>适用于分类问题</strong>：交叉熵损失适合于分类问题，可以有效地度量模型对不同类别的预测概率。</li>
<li><strong>连续可导</strong>：交叉熵损失是连续可导的，这使得可以使用梯度下降等优化算法来寻找最小化损失函数的参数。</li>
<li><strong>对异常值不敏感</strong>：交叉熵损失对异常值不敏感，适用于各种类型的数据集。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>对预测概率的敏感度</strong>：交叉熵损失对预测概率的微小变化非常敏感，可能导致模型在训练过程中对预测概率的调整不够平滑。</li>
<li><strong>计算复杂度</strong>：交叉熵损失的计算复杂度较高，特别是在多分类问题中，需要对每个类别进行计算。</li>
</ul>
<h2 id="8-逻辑回归损失函数（Logistic-Loss）"><a href="#8-逻辑回归损失函数（Logistic-Loss）" class="headerlink" title="8. 逻辑回归损失函数（Logistic Loss）"></a>8. 逻辑回归损失函数（Logistic Loss）</h2><h3 id="8-1-介绍"><a href="#8-1-介绍" class="headerlink" title="8.1 介绍"></a>8.1 介绍</h3><p>逻辑回归损失函数是一种用于二分类问题的损失函数。它度量的是模型预测的概率与真实标签之间的差异。逻辑回归损失函数鼓励模型对正类样本的预测概率接近 1，对负类样本的预测概率接近 0。</p>
<h3 id="8-2-数学公式"><a href="#8-2-数学公式" class="headerlink" title="8.2 数学公式"></a>8.2 数学公式</h3><p>逻辑回归损失函数的数学公式如下：</p>
<p>$$<br>L(y, p) &#x3D; -y \log(p) - (1 - y) \log(1 - p)<br>$$</p>
<p>其中：</p>
<ul>
<li>$ y $ 是第 $ i $ 个样本的真实标签（0 或 1）。</li>
<li>$ p $ 是模型对正类的预测概率。</li>
<li>$ \log $ 是自然对数。</li>
</ul>
<h3 id="8-3-工作原理"><a href="#8-3-工作原理" class="headerlink" title="8.3 工作原理"></a>8.3 工作原理</h3><p>逻辑回归损失函数的工作原理是通过对正类样本的预测概率进行惩罚，如果预测概率小于真实标签，而对负类样本的预测概率进行奖励，如果预测概率大于真实标签。这种惩罚和奖励机制使得模型在训练过程中逐渐调整参数，以便对正类样本的预测概率接近 1，对负类样本的预测概率接近 0。</p>
<h3 id="8-4-纯-Python-代码实现"><a href="#8-4-纯-Python-代码实现" class="headerlink" title="8.4 纯 Python 代码实现"></a>8.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现逻辑回归损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logistic_loss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算逻辑回归损失函数的值。</span></span><br><span class="line"><span class="string">    :param y_true: 真实标签，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param y_pred: 预测概率，一维数组或向量。</span></span><br><span class="line"><span class="string">    :return: 逻辑回归损失函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算逻辑回归损失</span></span><br><span class="line">    loss = -y_true * np.log(y_pred) - (<span class="number">1</span> - y_true) * np.log(<span class="number">1</span> - y_pred)</span><br><span class="line">    <span class="comment"># 计算平均损失</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(loss)</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">y_pred = np.array([<span class="number">0.9</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.8</span>])</span><br><span class="line"><span class="comment"># 计算逻辑回归损失</span></span><br><span class="line">logistic_loss_value = logistic_loss(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Logistic Loss:&quot;</span>, logistic_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="8-5-优缺点"><a href="#8-5-优缺点" class="headerlink" title="8.5 优缺点"></a>8.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>适用于二分类问题</strong>：逻辑回归损失函数适合于二分类问题，可以有效地度量模型对正类和负类样本的预测概率。</li>
<li><strong>易于理解和实现</strong>：逻辑回归损失函数的公式简单易懂，易于在编程语言中实现。</li>
<li><strong>对异常值不敏感</strong>：逻辑回归损失函数对异常值不敏感，适用于各种类型的数据集。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>对预测概率的敏感度</strong>：逻辑回归损失函数对预测概率的微小变化非常敏感，可能导致模型在训练过程中对预测概率的调整不够平滑。</li>
<li><strong>可能需要正则化</strong>：在实际应用中，逻辑回归损失函数可能需要通过添加正则化项来防止过拟合。</li>
</ul>
<h2 id="9-对数双曲余弦损失（Log-Cosh-Loss）"><a href="#9-对数双曲余弦损失（Log-Cosh-Loss）" class="headerlink" title="9. 对数双曲余弦损失（Log-Cosh Loss）"></a>9. 对数双曲余弦损失（Log-Cosh Loss）</h2><h3 id="9-1-介绍"><a href="#9-1-介绍" class="headerlink" title="9.1 介绍"></a>9.1 介绍</h3><p>对数双曲余弦损失是一种用于回归问题的损失函数，它是对均方误差（MSE）的一种平滑化。它在预测值与真实值之间差值较大时，惩罚相对较轻，而在差值较小时，惩罚相对较重。这种性质使得 Log-Cosh Loss 在处理包含异常值的数据时更加鲁棒。</p>
<h3 id="9-2-数学公式"><a href="#9-2-数学公式" class="headerlink" title="9.2 数学公式"></a>9.2 数学公式</h3><p>对数双曲余弦损失的数学公式如下：</p>
<p>$$<br>L(y, \hat{y}) &#x3D; \log\left(cosh(y - \hat{y})\right)<br>$$</p>
<p>其中：</p>
<ul>
<li>$ y $ 是第 $ i $ 个样本的真实值。</li>
<li>$ \hat{y} $ 是第 $ i $ 个样本的预测值。</li>
<li>$ cosh $ 是双曲余弦函数。</li>
<li>$ \log $ 是自然对数。</li>
</ul>
<h3 id="9-3-工作原理"><a href="#9-3-工作原理" class="headerlink" title="9.3 工作原理"></a>9.3 工作原理</h3><p>对数双曲余弦损失的工作原理是通过计算预测值与真实值之间的双曲余弦值，然后取其对数。当预测值与真实值之间的差值较大时，双曲余弦值接近于 1，对数值接近于 0，因此损失较小；当预测值与真实值之间的差值较小时，双曲余弦值接近于 0，对数值较大，因此损失较大。这种性质使得 Log-Cosh Loss 在处理包含异常值的数据时更加鲁棒。</p>
<h3 id="9-4-纯-Python-代码实现"><a href="#9-4-纯-Python-代码实现" class="headerlink" title="9.4 纯 Python 代码实现"></a>9.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现对数双曲余弦损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log_cosh_loss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算对数双曲余弦损失函数的值。</span></span><br><span class="line"><span class="string">    :param y_true: 真实值，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param y_pred: 预测值，一维数组或向量。</span></span><br><span class="line"><span class="string">    :return: 对数双曲余弦损失函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算预测值与真实值之间的差值</span></span><br><span class="line">    diff = y_true - y_pred</span><br><span class="line">    <span class="comment"># 计算双曲余弦值</span></span><br><span class="line">    cosh_diff = np.cosh(diff)</span><br><span class="line">    <span class="comment"># 计算对数双曲余弦损失</span></span><br><span class="line">    loss = np.log(cosh_diff)</span><br><span class="line">    <span class="comment"># 计算平均损失</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(loss)</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = np.array([<span class="number">3</span>, -<span class="number">0.5</span>, <span class="number">2</span>, <span class="number">7</span>])</span><br><span class="line">y_pred = np.array([<span class="number">2.5</span>, <span class="number">0.0</span>, <span class="number">2</span>, <span class="number">8</span>])</span><br><span class="line"><span class="comment"># 计算对数双曲余弦损失</span></span><br><span class="line">log_cosh_loss_value = log_cosh_loss(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Log-Cosh Loss:&quot;</span>, log_cosh_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="9-5-优缺点"><a href="#9-5-优缺点" class="headerlink" title="9.5 优缺点"></a>9.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>对异常值不敏感</strong>：对数双曲余弦损失对异常值不敏感，适用于包含异常值的数据集。</li>
<li><strong>平滑过渡</strong>：对数双曲余弦损失在均方误差和绝对损失之间平滑过渡，可以减少模型对异常值的敏感度。</li>
<li><strong>易于实现</strong>：对数双曲余弦损失的实现相对简单，可以通过调整双曲余弦函数的参数来适应不同的数据集。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>计算复杂度</strong>：与均方误差相比，对数双曲余弦损失的计算复杂度略高，因为需要对每个样本的差值进行双曲余弦计算和对数计算。</li>
</ul>
<h2 id="10-对数双曲正切损失（Log-Hyperbolic-Tangent-Loss）"><a href="#10-对数双曲正切损失（Log-Hyperbolic-Tangent-Loss）" class="headerlink" title="10. 对数双曲正切损失（Log-Hyperbolic Tangent Loss）"></a>10. 对数双曲正切损失（Log-Hyperbolic Tangent Loss）</h2><h3 id="10-1-介绍"><a href="#10-1-介绍" class="headerlink" title="10.1 介绍"></a>10.1 介绍</h3><p>对数双曲正切损失函数是一种结合了对数损失和双曲正切函数的损失函数。它鼓励模型输出概率分布与真实标签的分布尽可能接近，并且在模型预测概率接近 1 或-1 时更加稳定。</p>
<h3 id="10-2-数学公式"><a href="#10-2-数学公式" class="headerlink" title="10.2 数学公式"></a>10.2 数学公式</h3><p>对数双曲正切损失的数学公式如下：</p>
<p>$$<br>L(y, f(x)) &#x3D; -y \log(1 + \exp(f(x))) - (1 - y) \log(1 + \exp(-f(x)))<br>$$</p>
<p>其中：</p>
<ul>
<li>$ y $ 是第 $ i $ 个样本的真实标签（0 或 1）。</li>
<li>$ f(x) $ 是模型对正类的预测分数。</li>
<li>$ \log $ 是自然对数。</li>
<li>$ \exp $ 是指数函数。</li>
</ul>
<h3 id="10-3-工作原理"><a href="#10-3-工作原理" class="headerlink" title="10.3 工作原理"></a>10.3 工作原理</h3><p>对数双曲正切损失的工作原理是通过对数函数和双曲正切函数的组合。当模型预测概率接近 1 时，对数函数接近其上限，此时损失主要受对数函数的影响；当模型预测概率接近-1 时，对数函数接近其下限，此时损失主要受双曲正切函数的影响。这种设计使得对数双曲正切损失在模型预测概率接近 1 或-1 时更加稳定。</p>
<h3 id="10-4-纯-Python-代码实现"><a href="#10-4-纯-Python-代码实现" class="headerlink" title="10.4 纯 Python 代码实现"></a>10.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现对数双曲正切损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log_hyperbolic_tangent_loss</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算对数双曲正切损失函数的值。</span></span><br><span class="line"><span class="string">    :param y_true: 真实标签，一维数组或向量。</span></span><br><span class="line"><span class="string">    :param y_pred: 预测概率，一维数组或向量。</span></span><br><span class="line"><span class="string">    :return: 对数双曲正切损失函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算对数双曲正切损失</span></span><br><span class="line">    loss = -y_true * np.log(<span class="number">1</span> + np.exp(y_pred)) - (<span class="number">1</span> - y_true) * np.log(<span class="number">1</span> + np.exp(-y_pred))</span><br><span class="line">    <span class="comment"># 计算平均损失</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(loss)</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">y_true = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">y_pred = np.array([<span class="number">0.9</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.8</span>])</span><br><span class="line"><span class="comment"># 计算对数双曲正切损失</span></span><br><span class="line">log_hyperbolic_tangent_loss_value = log_hyperbolic_tangent_loss(y_true, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Log-Hyperbolic Tangent Loss:&quot;</span>, log_hyperbolic_tangent_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="10-5-优缺点"><a href="#10-5-优缺点" class="headerlink" title="10.5 优缺点"></a>10.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>稳定性</strong>：对数双曲正切损失在预测概率接近 1 或-1 时更加稳定，适用于输出概率非常接近 1 或-1 的情况。</li>
<li><strong>易于实现</strong>：对数双曲正切损失的实现相对简单，可以通过调整双曲正切函数的参数来适应不同的数据集。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>计算复杂度</strong>：与均方误差或交叉熵损失相比，对数双曲正切损失的计算复杂度较高，因为需要对每个样本的预测概率进行双曲正切计算和对数计算。</li>
</ul>
<h2 id="11-余弦相似度损失（Cosine-Similarity-Loss）"><a href="#11-余弦相似度损失（Cosine-Similarity-Loss）" class="headerlink" title="11. 余弦相似度损失（Cosine Similarity Loss）"></a>11. 余弦相似度损失（Cosine Similarity Loss）</h2><h3 id="11-1-介绍"><a href="#11-1-介绍" class="headerlink" title="11.1 介绍"></a>11.1 介绍</h3><p>余弦相似度损失是一种用于衡量两个向量之间相似度的损失函数。在机器学习中，特别是在表示学习或嵌入空间中，余弦相似度损失常用于度量两个向量表示的相似度。它鼓励模型学习到能够保持数据点之间相似度的特征表示。</p>
<h3 id="11-2-数学公式"><a href="#11-2-数学公式" class="headerlink" title="11.2 数学公式"></a>11.2 数学公式</h3><p>余弦相似度损失的数学公式如下：</p>
<p>$$<br>L(x, \hat{x}) &#x3D; 1 - \cos(\theta)<br>$$</p>
<p>其中：</p>
<ul>
<li>$ x $ 是第 $ i $ 个样本的真实向量。</li>
<li>$ \hat{x} $ 是第 $ i $ 个样本的预测向量。</li>
<li>$ \theta $ 是向量 $ x $ 和 $ \hat{x} $ 之间的夹角。</li>
<li>$ \cos(\theta) $ 是向量 $ x $ 和 $ \hat{x} $ 之间的余弦相似度。</li>
</ul>
<h3 id="11-3-工作原理"><a href="#11-3-工作原理" class="headerlink" title="11.3 工作原理"></a>11.3 工作原理</h3><p>余弦相似度损失的工作原理是通过计算两个向量之间的余弦相似度，然后取其相反数。当两个向量表示相同或相似的实体时，它们的夹角接近 0 度，余弦相似度接近 1，此时损失接近 0；当两个向量表示不同的实体时，它们的夹角接近 90 度，余弦相似度接近 0，此时损失接近 1。这种性质使得余弦相似度损失能够有效地度量两个向量之间的相似度。</p>
<h3 id="11-4-纯-Python-代码实现"><a href="#11-4-纯-Python-代码实现" class="headerlink" title="11.4 纯 Python 代码实现"></a>11.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 NumPy 库来实现余弦相似度损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cosine_similarity_loss</span>(<span class="params">x, x_hat</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算余弦相似度损失函数的值。</span></span><br><span class="line"><span class="string">    :param x: 真实向量，二维数组或矩阵。</span></span><br><span class="line"><span class="string">    :param x_hat: 预测向量，二维数组或矩阵。</span></span><br><span class="line"><span class="string">    :return: 余弦相似度损失函数的值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算余弦相似度</span></span><br><span class="line">    cos_sim = np.dot(x, x_hat) / (np.linalg.norm(x) * np.linalg.norm(x_hat))</span><br><span class="line">    <span class="comment"># 计算余弦相似度损失</span></span><br><span class="line">    loss = <span class="number">1</span> - cos_sim</span><br><span class="line">    <span class="comment"># 计算平均损失</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(loss)</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>],</span><br><span class="line">              [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line">x_hat = np.array([[<span class="number">0.5</span>, -<span class="number">0.5</span>, <span class="number">0.5</span>],</span><br><span class="line">                  [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]])</span><br><span class="line"><span class="comment"># 计算余弦相似度损失</span></span><br><span class="line">cosine_similarity_loss_value = cosine_similarity_loss(x, x_hat)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Cosine Similarity Loss:&quot;</span>, cosine_similarity_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="11-5-优缺点"><a href="#11-5-优缺点" class="headerlink" title="11.5 优缺点"></a>11.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>度量相似度</strong>：余弦相似度损失能够直接度量两个向量之间的相似度，无需额外的参数。</li>
<li><strong>易于理解</strong>：余弦相似度损失的公式简单易懂，易于在编程语言中实现。</li>
<li><strong>适用于嵌入空间</strong>：在表示学习或嵌入空间中，余弦相似度损失能够有效地度量数据点之间的相似度。<br><strong>缺点：</strong></li>
<li><strong>对方向不敏感</strong>：余弦相似度损失仅考虑向量的方向，不考虑向量的幅度，这可能导致在某些情况下对结果不够敏感。</li>
<li><strong>不适用于非线性关系</strong>：余弦相似度损失基于余弦函数，仅适用于度量向量之间的线性关系，对于非线性关系可能不够适用。</li>
</ul>
<h2 id="12-感知损失（Perceptual-Loss）"><a href="#12-感知损失（Perceptual-Loss）" class="headerlink" title="12. 感知损失（Perceptual Loss）"></a>12. 感知损失（Perceptual Loss）</h2><p>感知损失（Perceptual Loss）是一种在图像处理和计算机视觉中使用的损失函数，它利用预训练的卷积神经网络（CNN）来评估两个图像之间的感知差异。这种损失函数的目的是使生成模型产生的图像在人类视觉上与真实图像难以区分。感知损失通常用于图像到图像的翻译任务，如风格迁移、超分辨率、去噪等。</p>
<h3 id="12-1-介绍"><a href="#12-1-介绍" class="headerlink" title="12.1 介绍"></a>12.1 介绍</h3><p>感知损失是基于人类视觉感知的特点，它不是简单地计算图像像素级的差异，而是考虑图像的整体结构和内容。感知损失通常使用预训练的 CNN 模型，如 VGG19，来提取图像的高级特征，然后基于这些高级特征计算损失。</p>
<h3 id="12-2-数学公式"><a href="#12-2-数学公式" class="headerlink" title="12.2 数学公式"></a>12.2 数学公式</h3><p>感知损失的数学公式通常如下：</p>
<p>$$<br>L_{perceptual}(\text{G}(x), x) &#x3D; \frac{1}{H \times W} \sum_{i, j} \left| \text{VGG19}(G(x))<em>{i, j} - \text{VGG19}(x)</em>{i, j} \right|<br>$$</p>
<p>其中：</p>
<ul>
<li>$ G(x) $ 是生成模型生成的图像。</li>
<li>$ x $ 是真实图像。</li>
<li>$ H \times W $ 是图像的高度和宽度。</li>
<li>$ \text{VGG19} $ 是预训练的 VGG19 CNN 模型。</li>
<li>$ \left| \cdot \right| $ 是绝对值。</li>
</ul>
<h3 id="12-3-工作原理"><a href="#12-3-工作原理" class="headerlink" title="12.3 工作原理"></a>12.3 工作原理</h3><p>感知损失的工作原理是使用预训练的 CNN 模型提取图像的高级特征，然后比较生成图像和真实图像在这些高级特征上的差异。这种方法考虑了图像的结构和内容，而不仅仅是像素级的差异。通过最小化感知损失，生成模型学习到的特征更加接近真实图像的特征，从而在人类视觉上难以区分。</p>
<h3 id="12-4-纯-Python-代码实现"><a href="#12-4-纯-Python-代码实现" class="headerlink" title="12.4 纯 Python 代码实现"></a>12.4 纯 Python 代码实现</h3><p>在 Python 中，可以使用 PyTorch 库来实现感知损失函数。以下是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># 加载预训练的VGG19模型</span></span><br><span class="line">vgg19 = models.vgg19(pretrained=<span class="literal">True</span>).<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># 定义感知损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">perceptual_loss</span>(<span class="params">G, x</span>):</span><br><span class="line">    <span class="comment"># 提取VGG19模型的特征层</span></span><br><span class="line">    G_features = vgg19(F.interpolate(G, size=(<span class="number">224</span>, <span class="number">224</span>), mode=<span class="string">&#x27;bilinear&#x27;</span>))</span><br><span class="line">    x_features = vgg19(F.interpolate(x, size=(<span class="number">224</span>, <span class="number">224</span>), mode=<span class="string">&#x27;bilinear&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss = F.mse_loss(G_features, x_features)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">G = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">256</span>)  <span class="comment"># 生成图像</span></span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">256</span>)  <span class="comment"># 真实图像</span></span><br><span class="line"><span class="comment"># 计算感知损失</span></span><br><span class="line">perceptual_loss_value = perceptual_loss(G, x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Perceptual Loss:&quot;</span>, perceptual_loss_value)</span><br></pre></td></tr></table></figure>

<h3 id="12-5-优缺点"><a href="#12-5-优缺点" class="headerlink" title="12.5 优缺点"></a>12.5 优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li><strong>考虑图像结构</strong>：感知损失考虑了图像的高级特征，能够捕捉图像的结构和内容。</li>
<li><strong>适用于图像翻译任务</strong>：在图像到图像的翻译任务中，感知损失能够有效地评估生成图像的质量。</li>
<li><strong>易于实现</strong>：感知损失可以通过使用预训练的 CNN 模型来实现，无需复杂的计算。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>依赖预训练模型</strong>：感知损失依赖于预训练的 CNN 模型，这可能需要大量的计算资源。</li>
<li><strong>难以解释</strong>：由于感知损失基于复杂的高级特征，其计算过程难以解释和理解。</li>
<li><strong>对模型敏感</strong>：感知损失的性能可能受到所选 CNN 模型的影响，不同的模型可能产生不同的结果。</li>
</ul>
]]></content>
      <categories>
        <category>学习记录类</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
