<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Adream blog</title>
  
  
  <link href="https://www.adream.icu/atom.xml" rel="self"/>
  
  <link href="https://www.adream.icu/"/>
  <updated>2024-03-09T06:30:01.000Z</updated>
  <id>https://www.adream.icu/</id>
  
  <author>
    <name>Adream</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Code Snippet</title>
    <link href="https://www.adream.icu/2023/01/05/code_snippet/"/>
    <id>https://www.adream.icu/2023/01/05/code_snippet/</id>
    <published>2023-01-05T07:08:29.000Z</published>
    <updated>2024-03-09T06:30:01.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight bash"><figcaption><span>代码块的标题</span><a href="/aas/asd">/asd/asd</a></figcaption><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###### CONFIG</span></span><br><span class="line">ACCEPTED_HOSTS=<span class="string">&quot;/root/.hag_accepted.conf&quot;</span></span><br><span class="line">BE_VERBOSE=<span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$UID</span>&quot;</span> -ne 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"> <span class="built_in">echo</span> <span class="string">&quot;Superuser rights required&quot;</span></span><br><span class="line"> <span class="built_in">exit</span> 2</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">genApacheConf</span></span>()&#123;</span><br><span class="line"> <span class="built_in">echo</span> -e <span class="string">&quot;# Host <span class="variable">$&#123;HOME_DIR&#125;</span><span class="variable">$1</span>/<span class="variable">$2</span> :&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;&quot;quoted&quot;&#x27;</span> | <span class="built_in">tr</span> -d \&quot; &gt; text.txt</span><br></pre></td></tr></table></figure><figure class="highlight typescript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="attr">myValue</span>: <span class="built_in">string</span>;</span><br><span class="line">  <span class="title function_">constructor</span>(<span class="params">init: <span class="built_in">string</span></span>) &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">myValue</span> = init;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">import</span> fs = <span class="built_in">require</span>(<span class="string">&quot;fs&quot;</span>);</span><br><span class="line"><span class="variable language_">module</span> <span class="title class_">MyModule</span> &#123;</span><br><span class="line">  <span class="keyword">export</span> <span class="keyword">interface</span> <span class="title class_">MyInterface</span> <span class="keyword">extends</span> <span class="title class_">Other</span> &#123;</span><br><span class="line">    <span class="attr">myProperty</span>: <span class="built_in">any</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">declare</span> magicNumber <span class="built_in">number</span>;</span><br><span class="line">myArray.<span class="title function_">forEach</span>(<span class="function">() =&gt;</span> &#123; &#125;); <span class="comment">// fat arrow syntax</span></span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">$initHighlight</span>(<span class="params">block, cls</span>) &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (cls.<span class="title function_">search</span>(<span class="regexp">/\bno\-highlight\b/</span>) != -<span class="number">1</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="title function_">process</span>(block, <span class="literal">true</span>, <span class="number">0x0F</span>) +</span><br><span class="line">             <span class="string">` class=&quot;<span class="subst">$&#123;cls&#125;</span>&quot;`</span>;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">    <span class="comment">/* handle exception */</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span> / <span class="number">2</span>; i &lt; classes.<span class="property">length</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="title function_">checkCondition</span>(classes[i]) === <span class="literal">undefined</span>)</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;undefined&#x27;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">web-component</span>&gt;</span>&#123;block&#125;<span class="tag">&lt;/<span class="name">web-component</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span>  $initHighlight;</span><br></pre></td></tr></table></figure><figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> System.IO.Compression;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> <span class="keyword">warning</span> disable 414, 3021</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="title">MyApplication</span></span><br><span class="line">&#123;</span><br><span class="line">    [<span class="meta">Obsolete(<span class="string">&quot;...&quot;</span>)</span>]</span><br><span class="line">    <span class="keyword">class</span> <span class="title">Program</span> : <span class="title">IInterface</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;<span class="built_in">int</span>&gt; <span class="title">JustDoIt</span>(<span class="params"><span class="built_in">int</span> count</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            Span&lt;<span class="built_in">int</span>&gt; numbers = <span class="keyword">stackalloc</span> <span class="built_in">int</span>[length];</span><br><span class="line">            Console.WriteLine(<span class="string">$&quot;Hello <span class="subst">&#123;Name&#125;</span>!&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> List&lt;<span class="built_in">int</span>&gt;(<span class="keyword">new</span> <span class="built_in">int</span>[] &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span> &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">  <span class="attribute">font-family</span>: Chunkfive; <span class="attribute">src</span>: <span class="built_in">url</span>(<span class="string">&#x27;Chunkfive.otf&#x27;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">body</span>, <span class="selector-class">.usertext</span> &#123;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#F0F0F0</span>; <span class="attribute">background</span>: <span class="number">#600</span>;</span><br><span class="line">  <span class="attribute">font-family</span>: Chunkfive, sans;</span><br><span class="line">  <span class="attr">--heading-1</span>: <span class="number">30px</span>/<span class="number">32px</span> Helvetica, sans-serif;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">@import</span> url(print.css);</span><br><span class="line"><span class="keyword">@media</span> print &#123;</span><br><span class="line">  <span class="selector-tag">a</span><span class="selector-attr">[href^=http]</span><span class="selector-pseudo">::after</span> &#123;</span><br><span class="line">    <span class="attribute">content</span>: <span class="built_in">attr</span>(href)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>Title<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"><span class="selector-tag">body</span> &#123;<span class="attribute">width</span>: <span class="number">500px</span>;&#125;</span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;application/javascript&quot;</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">  <span class="keyword">function</span> <span class="title function_">$init</span>(<span class="params"></span>) &#123;<span class="keyword">return</span> <span class="literal">true</span>;&#125;</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span> <span class="attr">checked</span> <span class="attr">class</span>=<span class="string">&quot;title&quot;</span> <span class="attr">id</span>=<span class="string">&#x27;title&#x27;</span>&gt;</span>Title<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- here goes the rest of the page --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># hello world</span></span><br><span class="line"></span><br><span class="line">you can write text [<span class="string">with links</span>](<span class="link">http://example.com</span>) inline or [<span class="string">link references</span>][<span class="symbol">1</span>].</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> one <span class="emphasis">_thing_</span> has <span class="emphasis">*em*</span>phasis</span><br><span class="line"><span class="bullet">*</span> two <span class="strong">__things__</span> are <span class="strong">**bold**</span></span><br><span class="line"></span><br><span class="line">[<span class="symbol">1</span>]: <span class="link">http://example.com</span></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="section">hello world</span></span><br><span class="line"><span class="section">===========</span></span><br><span class="line"></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">this_is</span> <span class="attr">inline</span>=<span class="string">&quot;xml&quot;</span>&gt;</span></span><span class="language-xml"><span class="tag">&lt;/<span class="name">this_is</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="quote">&gt; markdown is so cool</span></span><br><span class="line"></span><br><span class="line"><span class="code">    so are code segments</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">1.</span> one thing (yeah!)</span><br><span class="line"><span class="bullet">2.</span> two thing <span class="code">`i can write code`</span>, and <span class="code">`more`</span> wipee!</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> &quot;topic&quot; (</span><br><span class="line">    &quot;id&quot; <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    &quot;forum_id&quot; <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    &quot;subject&quot; <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> &quot;topic&quot;</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> forum_id <span class="keyword">FOREIGN</span> KEY (&quot;forum_id&quot;)</span><br><span class="line"><span class="keyword">REFERENCES</span> &quot;forum&quot; (&quot;id&quot;);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Initials</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> &quot;topic&quot; (&quot;forum_id&quot;, &quot;subject&quot;)</span><br><span class="line"><span class="keyword">values</span> (<span class="number">2</span>, <span class="string">&#x27;D&#x27;&#x27;artagnian&#x27;</span>);</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">

&lt;figure class=&quot;highlight bash&quot;&gt;&lt;figcaption&gt;&lt;span&gt;代码块的标题&lt;/span&gt;&lt;a href=&quot;/aas/asd&quot;&gt;/asd/asd&lt;/a&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Tag Plugins</title>
    <link href="https://www.adream.icu/2022/12/30/tag_plugins/"/>
    <id>https://www.adream.icu/2022/12/30/tag_plugins/</id>
    <published>2022-12-30T07:08:29.000Z</published>
    <updated>2024-03-09T06:30:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>主题内置的一些标签插件说明和示例。</p><span id="more"></span><h2 id="Imgs-照片"><a href="#Imgs-照片" class="headerlink" title="Imgs 照片"></a>Imgs 照片</h2><p>用于适配黑白两种主题时显示图片，切换主题样式查看效果。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">%</span> <span class="string">imgs</span> [<span class="string">class</span> <span class="string">names</span>] [<span class="string">src1</span>] [<span class="string">src2</span>] [<span class="string">width</span>] [<span class="string">height</span>] [<span class="string">alt</span> <span class="string">text&#x27;title</span> <span class="string">text</span>] <span class="string">%</span>&#125;</span><br><span class="line"></span><br><span class="line">[<span class="string">src1</span>]          <span class="string">:</span> <span class="string">亮色主题时显示图片路径</span></span><br><span class="line">[<span class="string">src2</span>]          <span class="string">:</span> <span class="string">暗色主题时显示图片路径</span></span><br><span class="line">[<span class="string">width</span>]         <span class="string">:</span> <span class="string">宽</span></span><br><span class="line">[<span class="string">height</span>]        <span class="string">:</span> <span class="string">高</span></span><br><span class="line">[<span class="string">alt</span> <span class="string">text</span>]      <span class="string">:</span> <span class="string">alt</span> <span class="string">属性</span></span><br><span class="line">[<span class="string">title</span> <span class="string">text</span>]    <span class="string">:</span> <span class="string">title</span> <span class="string">属性</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用方式</p><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% imgs trm-cover /img/1.jpg /img/2.jpg  alt text %&#125;</span><br><span class="line"></span><br><span class="line">等效于</span><br><span class="line"></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">&quot;trm-cover trm-light-icon&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/img/1.jpg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;alt text&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">&quot;trm-cover trm-dark-icon&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/img/2.jpg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;alt text&quot;</span>&gt;</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure><img class="trm-cover trm-light-icon" src="/img/1.jpg" title="text" alt loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'> <img class="trm-cover trm-dark-icon" src="/img/2.jpg" title="text" alt loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><h2 id="Tabs-标签选项卡"><a href="#Tabs-标签选项卡" class="headerlink" title="Tabs 标签选项卡"></a>Tabs 标签选项卡</h2><p>从next主题移植</p><p>使用方法</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">%</span> <span class="string">tabs</span> <span class="string">Unique</span> <span class="string">name</span>, [<span class="string">index</span>] <span class="string">%</span>&#125;</span><br><span class="line"><span class="string">&lt;!--</span> <span class="string">tab</span> [<span class="string">Tab</span> <span class="string">caption</span>]<span class="string">--&gt;</span></span><br><span class="line"><span class="string">任何内容(也支持内联标签)。</span></span><br><span class="line"><span class="string">&lt;!--</span> <span class="string">endtab</span> <span class="string">--&gt;</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endtabs</span> <span class="string">%</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">Unique name   :</span> <span class="string">标签块标签的唯一名称，不带逗号。</span></span><br><span class="line">                <span class="string">如果名称中有空格，对于生成</span> <span class="string">id，所有空格将被破折号取代</span></span><br><span class="line">[<span class="string">index</span>]       <span class="string">:</span> <span class="string">tabs</span> <span class="string">默认选项卡的下标。</span></span><br><span class="line">                <span class="string">如果未指定，将选择第一个选项卡。</span></span><br><span class="line">                <span class="string">如果索引为</span> <span class="number">-1</span><span class="string">，则不会选择任何选项卡。</span></span><br><span class="line">                <span class="string">(可选参数)</span></span><br><span class="line"></span><br><span class="line">[<span class="string">Tab</span> <span class="string">caption</span>] <span class="string">:</span> <span class="string">当前标签的标题。</span></span><br><span class="line">                <span class="string">如果没有指定标题，带有标签索引后缀的唯一名称将被用作标签标题。</span></span><br><span class="line">                <span class="string">(可选参数)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="默认使用方式"><a href="#默认使用方式" class="headerlink" title="默认使用方式"></a>默认使用方式</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% tabs test1 %&#125;</span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 1.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 2.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 3.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line">&#123;% endtabs %&#125;</span><br></pre></td></tr></table></figure><div class="trm-tabs" id="test1"><ul class="trm-nav-tabs"><li class="trm-tab active"><button type="button" data-href="#test1-1">标签1</button></li><li class="trm-tab"><button type="button" data-href="#test1-2">标签2</button></li><li class="trm-tab"><button type="button" data-href="#test1-3">test1 3</button></li></ul><div class="trm-tab-contents"><div class="trm-tab-item-content active" id="test1-1"><p><strong>This is Tab 1.</strong></p></div><div class="trm-tab-item-content" id="test1-2"><p><strong>This is Tab 2.</strong></p></div><div class="trm-tab-item-content" id="test1-3"><p><strong>This is Tab 3.</strong></p></div></div></div><h3 id="预设选择tabs"><a href="#预设选择tabs" class="headerlink" title="预设选择tabs"></a>预设选择tabs</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% tabs test2, 3 %&#125;</span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 1.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 2.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 3.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line">&#123;% endtabs %&#125;</span><br></pre></td></tr></table></figure><div class="trm-tabs" id="test2"><ul class="trm-nav-tabs"><li class="trm-tab"><button type="button" data-href="#test2-1">test2 1</button></li><li class="trm-tab"><button type="button" data-href="#test2-2">test2 2</button></li><li class="trm-tab active"><button type="button" data-href="#test2-3">test2 3</button></li></ul><div class="trm-tab-contents"><div class="trm-tab-item-content" id="test2-1"><p><strong>This is Tab 1.</strong></p></div><div class="trm-tab-item-content" id="test2-2"><p><strong>This is Tab 2.</strong></p></div><div class="trm-tab-item-content active" id="test2-3"><p><strong>This is Tab 3.</strong></p></div></div></div><h3 id="沒有预设tabs"><a href="#沒有预设tabs" class="headerlink" title="沒有预设tabs"></a>沒有预设tabs</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% tabs test3, -1 %&#125;</span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 1.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 2.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- tab --&gt;</span><br><span class="line"><span class="strong">**This is Tab 3.**</span></span><br><span class="line">&lt;!-- endtab --&gt;</span><br><span class="line">&#123;% endtabs %&#125;</span><br></pre></td></tr></table></figure><div class="trm-tabs" id="test3"><ul class="trm-nav-tabs"><li class="trm-tab"><button type="button" data-href="#test3-1">test3 1</button></li><li class="trm-tab"><button type="button" data-href="#test3-2">test3 2</button></li><li class="trm-tab"><button type="button" data-href="#test3-3">test3 3</button></li></ul><div class="trm-tab-contents"><div class="trm-tab-item-content" id="test3-1"><p><strong>This is Tab 1.</strong></p></div><div class="trm-tab-item-content" id="test3-2"><p><strong>This is Tab 2.</strong></p></div><div class="trm-tab-item-content" id="test3-3"><p><strong>This is Tab 3.</strong></p></div></div></div><h2 id="Gallery-相册"><a href="#Gallery-相册" class="headerlink" title="Gallery 相册"></a>Gallery 相册</h2><p>一个相册集合。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&lt;div</span> <span class="string">class=&quot;row&quot;&gt;</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">galleryGroup</span> <span class="string">name</span> <span class="string">description</span> <span class="string">link</span> <span class="string">img-url</span> [<span class="string">col</span>] <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">galleryGroup</span> <span class="string">name</span> <span class="string">description</span> <span class="string">link</span> <span class="string">img-url</span> [<span class="string">col</span>] <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">galleryGroup</span> <span class="string">name</span> <span class="string">description</span> <span class="string">link</span> <span class="string">img-url</span> [<span class="string">col</span>] <span class="string">%</span>&#125;</span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">name            :</span> <span class="string">相册名字</span></span><br><span class="line"><span class="attr">description     :</span> <span class="string">相册描述</span></span><br><span class="line"><span class="attr">link            :</span> <span class="string">连接到对应相册的地址</span></span><br><span class="line"><span class="attr">img-url         :</span> <span class="string">图库封面的地址</span></span><br><span class="line">[<span class="string">col</span>]           <span class="string">:</span> <span class="string">相册列宽</span> <span class="number">1</span><span class="number">-12</span> <span class="string">，默认为</span> <span class="number">6</span></span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;row&quot;</span>&gt;</span></span></span><br><span class="line">&#123;% gallery &#x27;壁纸&#x27; &#x27;收藏的一些壁纸&#x27; &#x27;/gallery/wallpaper&#x27; https://th.wallhaven.cc/lg/z8/z8dg9y.jpg %&#125;</span><br><span class="line">&#123;% gallery &#x27;图库&#x27; &#x27;收藏的一些壁纸&#x27; &#x27;/gallery/wallpaper&#x27; https://th.wallhaven.cc/lg/rd/rddgwm.jpg %&#125;</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br></pre></td></tr></table></figure><div class="row"><div class="col-lg-6">    <a href="/gallery/wallpaper" class="trm-portfolio-item trm-scroll-animation">        <div class="trm-cover-frame" style="padding-bottom:60%">            <img class="trm-cover no-fancybox" src="https://th.wallhaven.cc/lg/z8/z8dg9y.jpg" alt="Group Image Gallery" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>        </div>        <div class="trm-item-description">            <div>                <h6>壁纸</h6>                <p style="margin: 5px 0 0;font-size: .9rem;opacity: .8;">收藏的一些壁纸</p>            </div>        </div>    </a></div><div class="col-lg-6">    <a href="/gallery/wallpaper" class="trm-portfolio-item trm-scroll-animation">        <div class="trm-cover-frame" style="padding-bottom:60%">            <img class="trm-cover no-fancybox" src="https://th.wallhaven.cc/lg/rd/rddgwm.jpg" alt="Group Image Gallery" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>        </div>        <div class="trm-item-description">            <div>                <h6>图库</h6>                <p style="margin: 5px 0 0;font-size: .9rem;opacity: .8;">收藏的一些壁纸</p>            </div>        </div>    </a></div></div><h3 id="相册详情"><a href="#相册详情" class="headerlink" title="相册详情"></a>相册详情</h3><p>相册详情，会根据图片自动排版。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">%</span> <span class="string">galleryGroup</span> <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">galleryItem</span> <span class="string">url1</span> [<span class="string">url2</span>] <span class="string">%</span>&#125;</span><br><span class="line"><span class="string">markdown</span> <span class="string">图片格式</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endgalleryGroup</span> <span class="string">%</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">有两种编写方式可以直接写</span> <span class="string">markdown</span> <span class="string">格式图片，也可以使用</span> <span class="string">galleryItem</span> <span class="string">标签插件。</span></span><br><span class="line"></span><br><span class="line"><span class="string">galleryItem</span></span><br><span class="line"><span class="attr">url1        :</span> <span class="string">图片略缩图地址</span></span><br><span class="line">[<span class="string">url2</span>]      <span class="string">:</span> <span class="string">图片原图地址，可选</span></span><br></pre></td></tr></table></figure>示例：<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% galleryGroup %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/85/85oy2j.jpg https://w.wallhaven.cc/full/85/wallhaven-85oy2j.png %&#125;</span><br><span class="line">![](<span class="link">https://w.wallhaven.cc/full/jx/wallhaven-jx3z65.jpg</span>)</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/85/85oylj.jpg https://w.wallhaven.cc/full/85/wallhaven-85oylj.png %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/vq/vq9688.jpg https://w.wallhaven.cc/full/vq/wallhaven-vq9688.jpg %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/2y/2y8q7m.jpg https://w.wallhaven.cc/full/2y/wallhaven-2y8q7m.png %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/85/85oyzj.jpg https://w.wallhaven.cc/full/85/wallhaven-85oyzj.png %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/7p/7p2589.jpg https://w.wallhaven.cc/full/7p/wallhaven-7p2589.png %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/m3/m39kj1.jpg https://w.wallhaven.cc/full/m3/wallhaven-m39kj1.jpg %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/6d/6dorxl.jpg https://w.wallhaven.cc/full/6d/wallhaven-6dorxl.jpg %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/o5/o53ro5.jpg https://w.wallhaven.cc/full/o5/wallhaven-o53ro5.jpg %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/l8/l831lq.jpg https://w.wallhaven.cc/full/l8/wallhaven-l831lq.jpg %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/zy/zy8ewv.jpg https://w.wallhaven.cc/full/zy/wallhaven-zy8ewv.jpg %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/3l/3lz1pd.jpg https://w.wallhaven.cc/full/3l/wallhaven-3lz1pd.png %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/1p/1pkz5w.jpg https://w.wallhaven.cc/full/1p/wallhaven-1pkz5w.png %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/p9/p9kdej.jpg https://w.wallhaven.cc/full/p9/wallhaven-p9kdej.jpg %&#125;</span><br><span class="line">&#123;% galleryItem https://th.wallhaven.cc/orig/x6/x68mrd.jpg https://w.wallhaven.cc/full/x6/wallhaven-x68mrd.jpg %&#125;</span><br><span class="line">&#123;% endgalleryGroup %&#125;</span><br></pre></td></tr></table></figure><div class="fj-gallery no-fancybox">    <img src="https://th.wallhaven.cc/orig/85/85oy2j.jpg" data-src="https://w.wallhaven.cc/full/85/wallhaven-85oy2j.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><p><img src="https://w.wallhaven.cc/full/jx/wallhaven-jx3z65.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><img src="https://th.wallhaven.cc/orig/85/85oylj.jpg" data-src="https://w.wallhaven.cc/full/85/wallhaven-85oylj.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/vq/vq9688.jpg" data-src="https://w.wallhaven.cc/full/vq/wallhaven-vq9688.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/2y/2y8q7m.jpg" data-src="https://w.wallhaven.cc/full/2y/wallhaven-2y8q7m.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/85/85oyzj.jpg" data-src="https://w.wallhaven.cc/full/85/wallhaven-85oyzj.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/7p/7p2589.jpg" data-src="https://w.wallhaven.cc/full/7p/wallhaven-7p2589.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/m3/m39kj1.jpg" data-src="https://w.wallhaven.cc/full/m3/wallhaven-m39kj1.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/6d/6dorxl.jpg" data-src="https://w.wallhaven.cc/full/6d/wallhaven-6dorxl.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/o5/o53ro5.jpg" data-src="https://w.wallhaven.cc/full/o5/wallhaven-o53ro5.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/l8/l831lq.jpg" data-src="https://w.wallhaven.cc/full/l8/wallhaven-l831lq.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/zy/zy8ewv.jpg" data-src="https://w.wallhaven.cc/full/zy/wallhaven-zy8ewv.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/3l/3lz1pd.jpg" data-src="https://w.wallhaven.cc/full/3l/wallhaven-3lz1pd.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/1p/1pkz5w.jpg" data-src="https://w.wallhaven.cc/full/1p/wallhaven-1pkz5w.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/p9/p9kdej.jpg" data-src="https://w.wallhaven.cc/full/p9/wallhaven-p9kdej.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://th.wallhaven.cc/orig/x6/x68mrd.jpg" data-src="https://w.wallhaven.cc/full/x6/wallhaven-x68mrd.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></div><h2 id="Caniuse-查看兼容性"><a href="#Caniuse-查看兼容性" class="headerlink" title="Caniuse 查看兼容性"></a>Caniuse 查看兼容性</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">%</span> <span class="string">caniuse</span> <span class="string">feature</span> <span class="string">@</span> [<span class="string">periods</span>] <span class="string">%</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">feature     :</span> <span class="string">在https://caniuse.com上搜索您想要的特性，然后单击搜索结果标题左侧的#，您将得到该特性的唯一名称。</span></span><br><span class="line">[<span class="string">periods</span>]   <span class="string">:</span> <span class="string">可选参数。选择要显示的浏览器版本。支持值:，，，，，，，，。如果该值为空，将使用默认值</span> <span class="string">past_1past_2past_3past_4past_5currentfuture_3future_2future_1current</span></span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% caniuse fetch %&#125;</span><br></pre></td></tr></table></figure><iframe data-feature="fetch" src="https://caniuse.bitsofco.de/embed/index.html?feat=fetch&periods=current&accessible-colours=false" frameborder="0" width="100%" height="400px"></iframe><h2 id="Flink-链接列表"><a href="#Flink-链接列表" class="headerlink" title="Flink 链接列表"></a>Flink 链接列表</h2><p>可在任何界面插入类似友情链接列表效果</p><p>内容格式与友情链接界面一样，支持 yml 格式</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">%</span> <span class="string">flink</span> [<span class="string">key</span>] [<span class="string">col</span>] <span class="string">%</span>&#125;</span><br><span class="line">[<span class="string">content</span>]</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endflink</span> <span class="string">%</span>&#125;</span><br><span class="line"></span><br><span class="line">[<span class="string">content</span>]   <span class="string">:</span> <span class="string">可选参数。链接数据，格式为</span> <span class="string">yaml。</span></span><br><span class="line">[<span class="string">key</span>]       <span class="string">:</span> <span class="string">可选参数。Hexo</span> <span class="string">数据文件的</span> <span class="string">key，如果</span> <span class="string">content</span> <span class="string">为空，则会加载指定</span> <span class="string">key</span> <span class="string">数据。[content]</span> <span class="string">和</span> [<span class="string">key</span>] <span class="string">需要二选一。</span></span><br><span class="line">[<span class="string">col</span>]       <span class="string">:</span> <span class="string">可选参数。链接列宽</span> <span class="number">1</span><span class="number">-12</span> <span class="string">，默认为</span> <span class="number">6</span></span><br></pre></td></tr></table></figure><p>示例</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% flink 12 %&#125;</span><br><span class="line">- name: Hexo</span><br><span class="line">  url: //hexo.io/</span><br><span class="line">  image: //d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg</span><br><span class="line">  desc: 快速、简洁且高效的博客框架</span><br><span class="line">- name: 白云苍狗</span><br><span class="line">  url: //www.imalun.com/</span><br><span class="line">  image: //www.imalun.com/images/avatar.jpg</span><br><span class="line">  desc: 醒，亦在人间；梦，亦在人间</span><br><span class="line">&#123;% endflink %&#125;</span><br></pre></td></tr></table></figure><div class="trm-flink row"><div class="col-lg-12">    <a href='//hexo.io/' target='_blank' rel="nofollow">        <div class="trm-service-icon-box trm-scroll-animation trm-p-20">            <div class="trm-service-content">                <div class="trm-icon">                    <img class="no-fancybox" draggable="false" onerror='this.onerror=null;this.src="/img/friend_404.gif"' alt="Hexo" src="//d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>                </div>                <div class="trm-service-text">                    <h6 class="trm-mb-10">Hexo</h6>                    <div>快速、简洁且高效的博客框架</div>                </div>            </div>        </div>    </a></div><div class="col-lg-12">    <a href='//www.imalun.com/' target='_blank' rel="nofollow">        <div class="trm-service-icon-box trm-scroll-animation trm-p-20">            <div class="trm-service-content">                <div class="trm-icon">                    <img class="no-fancybox" draggable="false" onerror='this.onerror=null;this.src="/img/friend_404.gif"' alt="白云苍狗" src="//www.imalun.com/images/avatar12312.jpg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>                </div>                <div class="trm-service-text">                    <h6 class="trm-mb-10">白云苍狗</h6>                    <div>醒，亦在人间；梦，亦在人间</div>                </div>            </div>        </div>    </a></div></div><p>或者使用 Hexo 数据文件</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% flink links 12 %&#125;</span><br><span class="line">&#123;% endflink %&#125;</span><br></pre></td></tr></table></figure><div class="trm-flink row"><div class="col-lg-12">    <a href='//hexo.io/' target='_blank' rel="nofollow">        <div class="trm-service-icon-box trm-scroll-animation trm-p-20">            <div class="trm-service-content">                <div class="trm-icon">                    <img class="no-fancybox" draggable="false" onerror='this.onerror=null;this.src="/img/friend_404.gif"' alt="Hexo" src="//d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>                </div>                <div class="trm-service-text">                    <h6 class="trm-mb-10">Hexo</h6>                    <div>快速、简洁且高效的博客框架</div>                </div>            </div>        </div>    </a></div></div><h2 id="Note-便签"><a href="#Note-便签" class="headerlink" title="Note 便签"></a>Note 便签</h2><p>快速插入便签。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">%</span> <span class="string">note</span> [<span class="string">type</span>] [<span class="string">title</span>] <span class="string">%</span>&#125;</span><br><span class="line"><span class="string">文字或者</span> <span class="string">`markdown`</span> <span class="string">均可</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endnote</span> <span class="string">%</span>&#125; </span><br><span class="line"></span><br><span class="line">[<span class="string">type</span>]<span class="string">:</span> <span class="string">可选参数。便签类型</span> <span class="string">info,</span> <span class="string">tip,</span> <span class="string">warning,</span> <span class="string">danger,</span> <span class="string">details</span></span><br><span class="line">[<span class="string">title</span>]<span class="string">:</span> <span class="string">可选参数。标题。</span></span><br></pre></td></tr></table></figure><p>示例</p><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% note info %&#125;</span><br><span class="line">This is an info box.</span><br><span class="line">&#123;% endnote %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% note tip %&#125;</span><br><span class="line">This is a tip.</span><br><span class="line">&#123;% endnote %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% note warning %&#125;</span><br><span class="line">This is a warning.</span><br><span class="line">&#123;% endnote %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% note danger %&#125;</span><br><span class="line">This is a dangerous warning.</span><br><span class="line">&#123;% endnote %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% note details %&#125;</span><br><span class="line">This is a details block.</span><br><span class="line">&#123;% endnote %&#125;</span><br></pre></td></tr></table></figure><div class="trm-note info"><div class="trm-note-title">INFO</div><p>This is an info box.</p></div><div class="trm-note tip"><div class="trm-note-title">TIP</div><p>This is a tip.</p></div><div class="trm-note warning"><div class="trm-note-title">WARNING</div><p>This is a warning.</p></div><div class="trm-note danger"><div class="trm-note-title">DANGER</div><p>This is a dangerous warning.</p></div><details><summary>DETAILS</summary><p>This is a details block.</p></details>]]></content>
    
    
    <summary type="html">&lt;p&gt;主题内置的一些标签插件说明和示例。&lt;/p&gt;</summary>
    
    
    
    <category term="Plugins" scheme="https://www.adream.icu/categories/Plugins/"/>
    
    
  </entry>
  
  <entry>
    <title>KaTeX</title>
    <link href="https://www.adream.icu/2022/09/22/katex/"/>
    <id>https://www.adream.icu/2022/09/22/katex/</id>
    <published>2022-09-22T07:45:29.000Z</published>
    <updated>2024-03-09T06:30:01.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="KaTeX"><a href="#KaTeX" class="headerlink" title="KaTeX"></a>KaTeX</h2><ul><li><a href="https://katex.org/docs/autorender.html">https://katex.org/docs/autorender.html</a></li></ul><h3 id="行内公式"><a href="#行内公式" class="headerlink" title="行内公式"></a>行内公式</h3><figure class="highlight md"><table><tr><td class="code"><pre><span class="line"><span class="quote">&gt; <span class="language-xml"><span class="tag">&lt;<span class="name">span</span>&gt;</span></span>$\&#123;x | Ax = b\&#125;$<span class="language-xml"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span></span><br></pre></td></tr></table></figure><p><span>$\mathcal{X}_{c^*}&lt;1, \mathcal{X}_{q^*}&lt;1$</span></p><p>$E &#x3D; mc^2$</p><p>$\frac{\partial}{\partial t}$</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="built_in">$</span>E = mc<span class="built_in">^</span>2<span class="built_in">$</span></span><br><span class="line"><span class="built_in">$</span><span class="keyword">\frac</span>&#123;<span class="keyword">\partial</span>&#125;&#123;<span class="keyword">\partial</span> t&#125;<span class="built_in">$</span></span><br></pre></td></tr></table></figure><h3 id="行间公式"><a href="#行间公式" class="headerlink" title="行间公式"></a>行间公式</h3><p>$$ E &#x3D; mc^2 $$</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="built_in">$</span><span class="built_in">$</span> E = mc<span class="built_in">^</span>2 <span class="built_in">$</span><span class="built_in">$</span></span><br></pre></td></tr></table></figure><p>注意，在 Markdown 文件中直接书写时，你需要多一个 <code>\</code> 来转译 <code>\</code>。或直接使用 <code>$$ E = mc^2 $$</code> 的形式。</p><p>使用 <code>\\[ E = mc^2 \\]</code> 而不是 <code>\[ E = mc^2 \]</code>。</p><blockquote><p>如果你有过多需要转译的字符，你可以直接使用 HTML 标签包裹它（内部的字符将不会被作为 Markdown 解析），而无需使用多个 <code>\</code> 来转译。</p></blockquote><p>譬如：</p><div>\[ E = mc^2 \]</div><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span>\[ E = mc^2 \]<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><hr><p>\[ E &#x3D; mc^2 \]</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\[</span> E = mc<span class="built_in">^</span>2 <span class="keyword">\]</span></span><br></pre></td></tr></table></figure><hr><p>\( E &#x3D; mc^2 \)</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\(</span> E = mc<span class="built_in">^</span>2 <span class="keyword">\)</span></span><br></pre></td></tr></table></figure><hr><p>$$ \vec a&#x3D;\frac{d\vec v}{dt}&#x3D;\frac{d(\frac{dr}{dt}\vec e*{i}+r\frac{d\theta}{dt}\vec e*{j})}{dt}&#x3D;\frac{d^2r}{dt^2}\vec e*{i}+\frac{dr}{dt}\frac{d\vec e*{i}}{dt}+\frac{dr}{dt}\frac{d\theta}{dt}\vec e*{j}+r\frac{d^2\theta}{dt^2}\vec e*{j}+r\frac{d\theta}{dt}\frac{d\vec e_{j}}{dt} $$</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\[</span> <span class="keyword">\vec</span> a=<span class="keyword">\frac</span>&#123;d<span class="keyword">\vec</span> v&#125;&#123;dt&#125;=<span class="keyword">\frac</span>&#123;d(<span class="keyword">\frac</span>&#123;dr&#125;&#123;dt&#125;<span class="keyword">\vec</span> e<span class="built_in">_</span>&#123;i&#125;+r<span class="keyword">\frac</span>&#123;d<span class="keyword">\theta</span>&#125;&#123;dt&#125;<span class="keyword">\vec</span> e<span class="built_in">_</span>&#123;j&#125;)&#125;&#123;dt&#125;=<span class="keyword">\frac</span>&#123;d<span class="built_in">^</span>2r&#125;&#123;dt<span class="built_in">^</span>2&#125;<span class="keyword">\vec</span> e<span class="built_in">_</span>&#123;i&#125;+<span class="keyword">\frac</span>&#123;dr&#125;&#123;dt&#125;<span class="keyword">\frac</span>&#123;d<span class="keyword">\vec</span> e<span class="built_in">_</span>&#123;i&#125;&#125;&#123;dt&#125;+<span class="keyword">\frac</span>&#123;dr&#125;&#123;dt&#125;<span class="keyword">\frac</span>&#123;d<span class="keyword">\theta</span>&#125;&#123;dt&#125;<span class="keyword">\vec</span> e<span class="built_in">_</span>&#123;j&#125;+r<span class="keyword">\frac</span>&#123;d<span class="built_in">^</span>2<span class="keyword">\theta</span>&#125;&#123;dt<span class="built_in">^</span>2&#125;<span class="keyword">\vec</span> e<span class="built_in">_</span>&#123;j&#125;+r<span class="keyword">\frac</span>&#123;d<span class="keyword">\theta</span>&#125;&#123;dt&#125;<span class="keyword">\frac</span>&#123;d<span class="keyword">\vec</span> e<span class="built_in">_</span>&#123;j&#125;&#125;&#123;dt&#125; <span class="keyword">\]</span></span><br></pre></td></tr></table></figure><p>$$ m_t&#x3D;g_t $$</p><p>$$ V_t&#x3D;1 $$</p><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="built_in">$</span><span class="built_in">$</span> m<span class="built_in">_</span>t=g<span class="built_in">_</span>t <span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line"><span class="built_in">$</span><span class="built_in">$</span> V<span class="built_in">_</span>t=1 <span class="built_in">$</span><span class="built_in">$</span></span><br></pre></td></tr></table></figure><div><p>$$ \eta_t&#x3D;lr*{\frac {m_t}{\sqrt V_t}}&#x3D;lr*g_t $$</p><p>$$ w_{t+1}&#x3D;w_t-\eta_t&#x3D;w_t-lr*{\frac {m_t}{\sqrt V_t}}&#x3D;w_t-lr*g_t $$</p><font size=5 color=red><p>$$ {\Rightarrow \boxed{w_{t+1}&#x3D;w_t-lr*{\frac {\partial loss}{\partial w_t}}}} $$</p></font></div><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="built_in">$</span><span class="built_in">$</span> <span class="keyword">\eta</span><span class="built_in">_</span>t=lr*&#123;<span class="keyword">\frac</span> &#123;m<span class="built_in">_</span>t&#125;&#123;<span class="keyword">\sqrt</span> V<span class="built_in">_</span>t&#125;&#125;=lr*g<span class="built_in">_</span>t <span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line"><span class="built_in">$</span><span class="built_in">$</span> w<span class="built_in">_</span>&#123;t+1&#125;=w<span class="built_in">_</span>t-<span class="keyword">\eta</span><span class="built_in">_</span>t=w<span class="built_in">_</span>t-lr*&#123;<span class="keyword">\frac</span> &#123;m<span class="built_in">_</span>t&#125;&#123;<span class="keyword">\sqrt</span> V<span class="built_in">_</span>t&#125;&#125;=w<span class="built_in">_</span>t-lr*g<span class="built_in">_</span>t <span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line"></span><br><span class="line">&lt;font size=5 color=red&gt;</span><br><span class="line"></span><br><span class="line"><span class="built_in">$</span><span class="built_in">$</span> &#123;<span class="keyword">\Rightarrow</span> <span class="keyword">\boxed</span>&#123;w<span class="built_in">_</span>&#123;t+1&#125;=w<span class="built_in">_</span>t-lr*&#123;<span class="keyword">\frac</span> &#123;<span class="keyword">\partial</span> loss&#125;&#123;<span class="keyword">\partial</span> w<span class="built_in">_</span>t&#125;&#125;&#125;&#125; <span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line"></span><br><span class="line">&lt;/font&gt;</span><br></pre></td></tr></table></figure><div>$$ \begin{bmatrix} a & b \\ c & d \end{bmatrix} $$</div><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line"><span class="built_in">$</span><span class="built_in">$</span> <span class="keyword">\begin</span>&#123;bmatrix&#125; a <span class="built_in">&amp;</span> b <span class="keyword">\\</span> c <span class="built_in">&amp;</span> d <span class="keyword">\end</span>&#123;bmatrix&#125; <span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure><div>$$\begin{equation}  \left\{    \begin{aligned}      x=a\cos\theta\\      y=b\sin\theta\\    \end{aligned}  \right.\end{equation}$$</div><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line"><span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">  <span class="keyword">\left</span><span class="keyword">\&#123;</span></span><br><span class="line">    <span class="keyword">\begin</span>&#123;aligned&#125;</span><br><span class="line">      x=a<span class="keyword">\cos</span><span class="keyword">\theta</span><span class="keyword">\\</span></span><br><span class="line">      y=b<span class="keyword">\sin</span><span class="keyword">\theta</span><span class="keyword">\\</span></span><br><span class="line">    end&#123;aligned&#125;</span><br><span class="line">  <span class="keyword">\right</span>.</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br><span class="line"><span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;KaTeX&quot;&gt;&lt;a href=&quot;#KaTeX&quot; class=&quot;headerlink&quot; title=&quot;KaTeX&quot;&gt;&lt;/a&gt;KaTeX&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://katex.org/docs/autorender.html&quot;&gt;htt</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Markdown</title>
    <link href="https://www.adream.icu/2022/09/21/markdown/"/>
    <id>https://www.adream.icu/2022/09/21/markdown/</id>
    <published>2022-09-21T07:25:29.000Z</published>
    <updated>2024-03-09T06:30:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>主题 Hexo-theme-async 文章页面适配预览。</p><span id="more"></span><h2 id="Markdown-基础语法"><a href="#Markdown-基础语法" class="headerlink" title="Markdown 基础语法"></a>Markdown 基础语法</h2><h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="六级标题"></a>六级标题</h6><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><p>粗体、斜体、粗体和斜体，删除线，需要在文字前后加不同的标记符号。如下：</p><p><strong>这个是粗体</strong></p><p><em>这个是斜体</em></p><p><em><strong>这个是粗体加斜体</strong></em></p><p><del>这里想用删除线</del></p><p>注：如果想给字体换颜色、字体或者居中显示，需要使用内嵌HTML来实现。</p><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><p>无序列表的使用，在符号<code>-</code>后加空格使用。如下：</p><ul><li>无序列表 1</li><li>无序列表 2</li><li>无序列表 3</li></ul><p>多层嵌套效果。如下：</p><ul><li>无序列表 1</li><li>无序列表 2<ul><li>无序列表 2.1</li><li>无序列表 2.2<ul><li>无序列表 2.2.1</li><li>无序列表 2.2.2</li></ul></li></ul></li></ul><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><p>有序列表的使用，在数字及符号<code>.</code>后加空格后输入内容，如下：</p><ol><li>有序列表 1</li><li>有序列表 2</li><li>有序列表 3</li></ol><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>引用的格式是在符号<code>&gt;</code>后面书写文字。如下：</p><blockquote><p>读一本好书，就是在和高尚的人谈话。 ——歌德</p></blockquote><blockquote><p>雇用制度对工人不利，但工人根本无力摆脱这个制度。 ——阮一峰</p></blockquote><h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><p>关于 <code>Hexo-theme-async</code> 的使用文档可以<a href="https://hexo-theme-async.imalun.com/">点击这里</a>查看</p><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>插入图片，格式如下：</p><p><img src="https://hexo-theme-async.imalun.com/github_star.png" alt="这里写图片描述" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p><img src="https://markdown.com.cn/images/i-am-svg.svg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><img src="https://hexo-theme-async.imalun.com/github_star.png" align="left" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><img src="https://hexo-theme-async.imalun.com/github_star.png" align="right" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><div class="row">  <div class="col-lg-4">    <img src="https://hexo-theme-async.imalun.com/github_star.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>  </div>  <div class="col-lg-4">    <img src="https://hexo-theme-async.imalun.com/github_star.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>  </div>  <div class="col-lg-4">    <img src="https://hexo-theme-async.imalun.com/github_star.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'>  </div></div><h3 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h3><p>可以在一行中用三个以上的减号来建立一个分隔线，同时需要在分隔线的上面空一行。如下：</p><hr><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p>可以使用冒号来定义表格的对齐方式，如下：</p><table><thead><tr><th align="left">姓名</th><th align="center">年龄</th><th align="right">工作</th></tr></thead><tbody><tr><td align="left">小可爱</td><td align="center">18</td><td align="right">吃可爱多</td></tr><tr><td align="left">小小勇敢</td><td align="center">20</td><td align="right">爬棵勇敢树</td></tr><tr><td align="left">小小小机智</td><td align="center">22</td><td align="right">看一本机智书</td></tr></tbody></table><h2 id="特殊语法"><a href="#特殊语法" class="headerlink" title="特殊语法"></a>特殊语法</h2><h3 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h3><p>Here’s a sentence with a footnote. [^1]<br>[^1]: This is the footnote.</p><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><p>如果在一个行内需要引用代码，只要用反引号引起来就好，如下：</p><p>Use the <code>printf()</code> function.</p><p>在需要高亮的代码块的前一行及后一行使用三个反引号，同时<strong>第一行反引号后面表示代码块所使用的语言</strong>，如下：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// FileName: HelloWorld.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloWorld</span> &#123;</span><br><span class="line">  <span class="comment">// Java 入口程序，程序从此入口</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Hello,World!&quot;</span>); <span class="comment">// 向控制台打印一条语句</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>diff 不能同时和其他语言的高亮同时显示，使用效果如下:</p><figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="addition">+ 新增项</span></span><br><span class="line"><span class="deletion">- 删除项</span></span><br></pre></td></tr></table></figure><h3 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h3><p>行内公式使用方法：\(ce{Hg^2+ -&gt;[I-] HgI2 -&gt;[I-] [Hg^{II}I4]^2-}\)</p><p>块公式使用方法如下：</p><p>$$H(D_2) &#x3D; -\left(\frac{2}{4}\log_2 \frac{2}{4} + \frac{2}{4}\log_2 \frac{2}{4}\right) &#x3D; 1$$</p><h3 id="定义列表"><a href="#定义列表" class="headerlink" title="定义列表"></a>定义列表</h3><dl><dt>First Term</dt><dd>This is the definition of the first term.</dd></dl><dl><dt>Second Term<br>: This is one definition of the second term.</dt><dd>This is another definition of the second term.</dd></dl><h3 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h3><ul><li><input checked="" disabled="" type="checkbox"> Write the press release</li><li><input disabled="" type="checkbox"> Update the website</li><li><input disabled="" type="checkbox"> Contact the media</li></ul><h2 id="HTML"><a href="#HTML" class="headerlink" title="HTML"></a>HTML</h2><h3 id="注音标签"><a href="#注音标签" class="headerlink" title="注音标签"></a>注音标签</h3><p><ruby>喜大普奔<rt>hē hē hē hē</rt></ruby></p><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ruby</span>&gt;</span>喜大普奔<span class="tag">&lt;<span class="name">rt</span>&gt;</span>hē hē hē hē<span class="tag">&lt;/<span class="name">rt</span>&gt;</span><span class="tag">&lt;/<span class="name">ruby</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="details"><a href="#details" class="headerlink" title="details"></a>details</h3><details>  <summary>Async 安装方法</summary><p>进入您的 Hexo 博客根目录，执行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm i hexo-theme-async@latest</span><br></pre></td></tr></table></figure></details>]]></content>
    
    
    <summary type="html">&lt;p&gt;主题 Hexo-theme-async 文章页面适配预览。&lt;/p&gt;</summary>
    
    
    
    <category term="测试分类" scheme="https://www.adream.icu/categories/%E6%B5%8B%E8%AF%95%E5%88%86%E7%B1%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>Hello Theme Async</title>
    <link href="https://www.adream.icu/2022/09/21/hello-world/"/>
    <id>https://www.adream.icu/2022/09/21/hello-world/</id>
    <published>2022-09-21T07:08:29.000Z</published>
    <updated>2024-03-09T06:30:01.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://hexo-theme-async.imalun.com/imgs/demo2.png" alt="1663833969157.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'><em>示例图</em></p><p>Welcome to <a href="https://hexo-theme-async.imalun.com/">hexo-theme-async</a>.</p><span id="more"></span><h2 id="Hexo-Theme-Async"><a href="#Hexo-Theme-Async" class="headerlink" title="Hexo Theme Async"></a>Hexo Theme Async</h2><ul><li>docs: <a href="https://hexo-theme-async.imalun.com/">https://hexo-theme-async.imalun.com/</a></li></ul><h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://hexo-theme-async.imalun.com/imgs/demo2.png&quot; alt=&quot;1663833969157.png&quot;&gt;&lt;em&gt;示例图&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo-theme-async.imalun.com/&quot;&gt;hexo-theme-async&lt;/a&gt;.&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>决策树分类算法原理</title>
    <link href="https://www.adream.icu/2021/06/12/DecisionTree-Classification/"/>
    <id>https://www.adream.icu/2021/06/12/DecisionTree-Classification/</id>
    <published>2021-06-12T15:20:59.000Z</published>
    <updated>2024-03-12T11:56:16.856Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><span id="more"></span><h2 id="1、决策树概述"><a href="#1、决策树概述" class="headerlink" title="1、决策树概述"></a>1、决策树概述</h2><p>决策树是属于有监督机器学习的一种，起源非常早，符合直觉并且非常直观，模仿人类做决策的过程，早期人工智能模型中有很多应用，现在更多的是使用基于决策树的一些集成学习的算法。这一章我们把决策树算法理解透彻了，非常有利于后面去学习集成学习。</p><h3 id="1-1、示例一"><a href="#1-1、示例一" class="headerlink" title="1.1、示例一"></a>1.1、示例一</h3><p>我们有如下数据：</p><table><thead><tr><th>ID</th><th>拥有房产（是&#x2F;否）</th><th>婚姻[单身，已婚，离婚]</th><th>年收入（单位：千元）</th><th>无法偿还债务（是&#x2F;否）</th></tr></thead><tbody><tr><td>1</td><td>是</td><td>单身</td><td>125</td><td>否</td></tr><tr><td>2</td><td>否</td><td>已婚</td><td>100</td><td>否</td></tr><tr><td>3</td><td>否</td><td>单身</td><td>70</td><td>否</td></tr><tr><td>4</td><td>是</td><td>已婚</td><td>120</td><td>否</td></tr><tr><td>5</td><td>否</td><td>离婚</td><td>95</td><td>是</td></tr><tr><td>6</td><td>否</td><td>已婚</td><td>60</td><td>否</td></tr><tr><td>7</td><td>是</td><td>离婚</td><td>220</td><td>否</td></tr><tr><td>8</td><td>否</td><td>单身</td><td>85</td><td>是</td></tr><tr><td>9</td><td>否</td><td>已婚</td><td>75</td><td>否</td></tr><tr><td>10</td><td>否</td><td>单身</td><td>90</td><td>是</td></tr></tbody></table><p>上表根据历史数据，记录已有的用户是否可以偿还债务，以及相关的信息。通过该数据，构建的决策树如下：</p><p><img src="/../img/post/DecisionTree-Classification/1-%E5%86%B3%E7%AD%96%E6%A0%91.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>比如新来一个用户：无房产，单身，年收入 55K，那么根据上面的决策树，可以预测他无法偿还债务（蓝色虚线路径）。从上面的决策树，还可以知道是否拥有房产可以很大的决定用户是否可以偿还债务，对借贷业务具有指导意义。</p><h3 id="1-2、示例二"><a href="#1-2、示例二" class="headerlink" title="1.2、示例二"></a>1.2、示例二</h3><p>女孩母亲要给她介绍对象，年龄是多少，母亲说 24。长得帅吗？挺帅的。收入高吗？中等收入。是公务员吗？母亲说，是的。女孩：好，我去见见。</p><p>根据<strong>实力</strong>构建决策树：</p><p><img src="/../img/post/DecisionTree-Classification/2-%E7%9B%B8%E4%BA%B2.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>问题：图片是二叉树吗？</p><p>决策树是标准的二叉树，每个节点只有两个分支~</p><ul><li>上面那棵树中，属性：绿色的节点（年龄、长相、收入、是否是公务员）<ul><li>属性叫做，data，数据，一般使用 X 表示</li><li>跟属性对应，目标值（橘色节点），一般使用 y 表示</li></ul></li><li>构建这棵树时，先后顺序，每个人，标准不同，树结构不同</li><li>计算机，构建树，标准一致的，构建出来的树，一致</li></ul><h3 id="1-3、决策树算法特点"><a href="#1-3、决策树算法特点" class="headerlink" title="1.3、决策树算法特点"></a>1.3、决策树算法特点</h3><ul><li>可以处理非线性的问题</li><li>可解释性强，没有方程系数 $\theta$</li><li>模型简单，模型预测效率高 if else</li></ul><h2 id="2、DecisionTreeClassifier-使用"><a href="#2、DecisionTreeClassifier-使用" class="headerlink" title="2、DecisionTreeClassifier 使用"></a>2、DecisionTreeClassifier 使用</h2><h3 id="2-1、算例介绍"><a href="#2-1、算例介绍" class="headerlink" title="2.1、算例介绍"></a>2.1、算例介绍</h3><p><img src="/img/post/DecisionTree-Classification/3-%E8%B4%A6%E5%8F%B7%E7%9C%9F%E4%BC%AA.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>其中 s、m 和 l 分别表示小、中和大。</p><p>账号是否真实跟属性：<strong>日志密度、好友密度、是否使用真实头像</strong>有关系~</p><h3 id="2-2、构建决策树并可视化"><a href="#2-2、构建决策树并可视化" class="headerlink" title="2.2、构建决策树并可视化"></a>2.2、构建决策树并可视化</h3><p>数据创建</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">y = np.array(<span class="built_in">list</span>(<span class="string">&#x27;NYYYYYNYYN&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line">X = pd.DataFrame(&#123;<span class="string">&#x27;日志密度&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;sslmlmmlms&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;好友密度&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;slmmmlsmss&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;真实头像&#x27;</span>:<span class="built_in">list</span>(<span class="string">&#x27;NYYYYNYYYY&#x27;</span>),</span><br><span class="line">                  <span class="string">&#x27;真实用户&#x27;</span>:y&#125;)</span><br><span class="line">X</span><br></pre></td></tr></table></figure><p>模型训练（报错，原因：数据类型是字符串）</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"></span><br><span class="line">model = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line">model.fit(X,y)</span><br></pre></td></tr></table></figure><p>数据修改（map 函数，进行数据转换）</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X[<span class="string">&#x27;日志密度&#x27;</span>] = X[<span class="string">&#x27;日志密度&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;s&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;m&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;l&#x27;</span>:<span class="number">2</span>&#125;)</span><br><span class="line">X[<span class="string">&#x27;好友密度&#x27;</span>] = X[<span class="string">&#x27;好友密度&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;s&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;m&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;l&#x27;</span>:<span class="number">2</span>&#125;)</span><br><span class="line">X[<span class="string">&#x27;真实头像&#x27;</span>] = X[<span class="string">&#x27;真实头像&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;N&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;Y&#x27;</span>:<span class="number">1</span>&#125;)</span><br><span class="line">X</span><br></pre></td></tr></table></figure><p>模型训练可视化</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 使用信息熵，作为分裂标准</span></span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;STKaiti&#x27;</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">16</span>))</span><br><span class="line">fn = X.columns</span><br><span class="line">_ = tree.plot_tree(model,filled = <span class="literal">True</span>,feature_names=fn)</span><br><span class="line">plt.savefig(<span class="string">&#x27;./iris.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure><img src="/img/post/DecisionTree-Classification/4-account.jpg" style="zoom:50%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/><p>数据可视化另一种方式，<a href="https://blog.csdn.net/Soft_Po/article/details/118899477">安装教程</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line">dot_data = tree.export_graphviz(model, out_file=<span class="literal">None</span>,</span><br><span class="line">                            feature_names= X.columns,<span class="comment"># 特征名</span></span><br><span class="line">                            class_names=np.unique(y),<span class="comment"># 类别名</span></span><br><span class="line">                            filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                            rounded=<span class="literal">True</span>) <span class="comment"># 圆角</span></span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;Account&#x27;</span>,<span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br></pre></td></tr></table></figure><p>修改中文乱码</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 打开 dot_data.dot，修改 fontname=&quot;支持的中文字体&quot;</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;Account&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./Account2&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(re.sub(<span class="string">r&#x27;fontname=helvetica&#x27;</span>, <span class="string">&#x27;fontname=Fangsong&#x27;</span>, f.read()))</span><br><span class="line">f.close()</span><br><span class="line"><span class="comment"># 从文件中加载，展示</span></span><br><span class="line">graph = graphviz.Source.from_file(<span class="string">&#x27;./Account2&#x27;</span>)</span><br><span class="line">graph.render(<span class="string">&#x27;Account&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/img/post/DecisionTree-Classification/5-Account.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><h3 id="2-3、信息熵"><a href="#2-3、信息熵" class="headerlink" title="2.3、信息熵"></a>2.3、信息熵</h3><ul><li><p>构建好一颗树，数据变的有顺序了（构建前，一堆数据，杂乱无章；构建一颗，整整齐齐，顺序），用什么度量衡表示，数据是否有顺序：信息熵</p></li><li><p>物理学，热力学第二定律（熵），描述的是封闭系统的混乱程度</p><p><img src="/img/post/DecisionTree-Classification/6-entropy.gif" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p></li><li><p>信息熵，和物理学中熵类似的</p><img src="/img/post/DecisionTree-Classification/7-entropy.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/><p><font size = 5>$H(x) &#x3D; -\sum\limits_{i &#x3D; 1}^n p(x)log_2p(x)$</font></p></li><li><p><font size = 5>$H(x) &#x3D; \sum\limits_{i &#x3D; 1}^n p(x)log_2\frac{1}{p(x)}$</font></p></li></ul><h3 id="2-4、信息增益"><a href="#2-4、信息增益" class="headerlink" title="2.4、信息增益"></a>2.4、信息增益</h3><p>信息增益是知道了某个条件后，事件的不确定性下降的程度。写作 g(X,Y)。它的计算方式为熵减去条件熵，如下</p><p>$g(X,y) \rm &#x3D; H(Y) - H(Y|X)$</p><p>表示的是，知道了某个条件后，原来事件不确定性降低的幅度。</p><h3 id="2-5、手动计算实现决策树分类"><a href="#2-5、手动计算实现决策树分类" class="headerlink" title="2.5、手动计算实现决策树分类"></a>2.5、手动计算实现决策树分类</h3><p>数据整合</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X[<span class="string">&#x27;真实用户&#x27;</span>] = y</span><br><span class="line">X</span><br></pre></td></tr></table></figure><p>计算未划分信息熵</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = X[<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">p = s.value_counts()/s.size</span><br><span class="line">(p * np.log2(<span class="number">1</span>/p)).<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><p>按照日志密度进行划分</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = X[<span class="string">&#x27;日志密度&#x27;</span>].unique()</span><br><span class="line">x.sort()</span><br><span class="line"><span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">    split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">    cond = X[<span class="string">&#x27;日志密度&#x27;</span>] &lt;= split</span><br><span class="line">    <span class="comment"># 概率分布</span></span><br><span class="line">    p = cond.value_counts()/cond.size</span><br><span class="line">    <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">    indexs =p.index</span><br><span class="line">    entropy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">        user = X[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">        p_user = user.value_counts()/user.size</span><br><span class="line">        entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">    <span class="built_in">print</span>(split,entropy)</span><br></pre></td></tr></table></figure><p>筛选最佳划分条件</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">columns = [<span class="string">&#x27;日志密度&#x27;</span>,<span class="string">&#x27;好友密度&#x27;</span>,<span class="string">&#x27;真实头像&#x27;</span>]</span><br><span class="line">lower_entropy = <span class="number">1</span></span><br><span class="line">condition = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">    x = X[col].unique()</span><br><span class="line">    x.sort()</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line">    <span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">        split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">        cond = X[col] &lt;= split</span><br><span class="line">        <span class="comment"># 概率分布</span></span><br><span class="line">        p = cond.value_counts()/cond.size</span><br><span class="line">        <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">        indexs =p.index</span><br><span class="line">        entropy = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">            user = X[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">            p_user = user.value_counts()/user.size</span><br><span class="line">            entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">        <span class="built_in">print</span>(col,split,entropy)</span><br><span class="line">        <span class="keyword">if</span> entropy &lt; lower_entropy:</span><br><span class="line">            condition.clear()</span><br><span class="line">            lower_entropy = entropy</span><br><span class="line">            condition[col] = split</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最佳列分条件是：&#x27;</span>,condition)</span><br></pre></td></tr></table></figure><img src="/img/post/DecisionTree-Classification/8-Account.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/><p>进一步列分</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cond = X[<span class="string">&#x27;好友密度&#x27;</span>] &lt; <span class="number">0.5</span></span><br><span class="line">X_ = X[cond]</span><br><span class="line">columns = [<span class="string">&#x27;日志密度&#x27;</span>,<span class="string">&#x27;真实头像&#x27;</span>]</span><br><span class="line">lower_entropy = <span class="number">1</span></span><br><span class="line">condition = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">    x = X_[col].unique()</span><br><span class="line">    x.sort()</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line">    <span class="comment"># 如何划分呢，分成两部分</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x) - <span class="number">1</span>):</span><br><span class="line">        split = x[i:i+<span class="number">2</span>].mean()</span><br><span class="line">        cond = X_[col] &lt;= split</span><br><span class="line">        <span class="comment"># 概率分布</span></span><br><span class="line">        p = cond.value_counts()/cond.size</span><br><span class="line">        <span class="comment"># 按照条件划分，两边的概率分布情况</span></span><br><span class="line">        indexs =p.index</span><br><span class="line">        entropy = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">            user = X_[cond == index][<span class="string">&#x27;真实用户&#x27;</span>]</span><br><span class="line">            p_user = user.value_counts()/user.size</span><br><span class="line">            entropy += (p_user * np.log2(<span class="number">1</span>/p_user)).<span class="built_in">sum</span>() * p[index]</span><br><span class="line">        <span class="built_in">print</span>(col,split,entropy)</span><br><span class="line">        <span class="keyword">if</span> entropy &lt; lower_entropy:</span><br><span class="line">            condition.clear()</span><br><span class="line">            lower_entropy = entropy</span><br><span class="line">            condition[col] = split</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;最佳列分条件是：&#x27;</span>,condition)</span><br></pre></td></tr></table></figure><img src="/img/post/DecisionTree-Classification/9-Account.png" style="zoom:67%;"  loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'/><h2 id="3、决策树分裂指标"><a href="#3、决策树分裂指标" class="headerlink" title="3、决策树分裂指标"></a>3、决策树分裂指标</h2><p>常用的分裂条件时：</p><ul><li>信息增益</li><li>Gini 系数</li><li>信息增益率</li><li>MSE（回归问题）</li></ul><h3 id="3-1、信息熵（ID3）"><a href="#3-1、信息熵（ID3）" class="headerlink" title="3.1、信息熵（ID3）"></a>3.1、信息熵（ID3）</h3><p>在信息论里熵叫作信息量，即熵是对不确定性的度量。从控制论的角度来看，应叫不确定性。信息论的创始人香农在其著作《通信的数学理论》中提出了建立在概率统计模型上的信息度量。他把信息定义为“用来消除不确定性的东西”。在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。还是举例说明，假设 Dammi 在买衣服的时候有颜色，尺寸，款式以及设计年份四种要求，而 Sara 只有颜色和尺寸的要求，那么在购买衣服这个层面上 Dammi 由于选择更多因而不确定性因素更大，最终 Dammi 所获取的信息更多，也就是熵更大。所以信息量&#x3D;熵&#x3D;不确定性，通俗易懂。在叙述决策树时我们用熵表示不纯度（Impurity）。</p><p>对应公式如下：</p><p><font size = 5>$H(x) &#x3D; -\sum\limits_{i &#x3D; 1}^n p(x)log_2p(x)$</font></p><p>熵的变化越大，说明划分越纯，信息增益越大~</p><h3 id="3-2、Gini-系数（CART）"><a href="#3-2、Gini-系数（CART）" class="headerlink" title="3.2、Gini 系数（CART）"></a>3.2、Gini 系数（CART）</h3><p>基尼系数是指国际上通用的、用以衡量一个国家或地区居民收入差距的常用指标。</p><p>基尼系数最大为“1”，最小等于“0”。基尼系数越接近 0 表明收入分配越是趋向平等。国际惯例把 0.2 以下视为收入绝对平均，0.2-0.3 视为收入比较平均；0.3-0.4 视为收入相对合理；0.4-0.5 视为收入差距较大，当基尼系数达到 0.5 以上时，则表示收入悬殊。</p><p>基尼系数的实际数值只能介于 0 ～ 1 之间，基尼系数越小收入分配越平均，基尼系数越大收入分配越不平均。国际上通常把 0.4 作为贫富差距的警戒线，大于这一数值容易出现社会动荡。</p><p>Gini 系数越小，代表集合中的数据越纯，所有我们可以计算分裂前的值在按照某个维度对数据集进行划分，然后可以去计算多个节点的 Gini 系数。</p><p>对应公式如下：</p><p><font size = 5>$\rm gini &#x3D; \sum\limits_{i &#x3D; 1}^np_i(1 - p_i)$</font></p><p>在对数据进行分类是 gini 系数的变化越大，说明划分越纯，效果越好~</p><h3 id="3-3、信息增益率"><a href="#3-3、信息增益率" class="headerlink" title="3.3、信息增益率"></a>3.3、信息增益率</h3><p>大学期末的数学考试只有单选题。对于一个完全没有学习过的学生。该如何过关呢？</p><p>4 个选项是正确选项的概率都是 1&#x2F;4。那么单项选择题的答案的熵就是：</p><p>$H(Y) \rm &#x3D; -0.25log_2(0.25) \times 4 &#x3D; 2bit$</p><p>在学霸圈做单项选择题有一个秘籍：三长一短选最短，三短一长选最长。姑且假设学霸的秘籍一般都是正确的。</p><p>如果在某场考试中，有 10%的单项选题是三长一短，10%的选题是三短一长。计算该考试单项选题的关于长短题的条件熵：</p><table><thead><tr><th align="center">题目类型</th><th align="center">答案概率</th><th align="center">题目概率</th></tr></thead><tbody><tr><td align="center">三长一短</td><td align="center">(1,0,0,0)熵是 0，结果确定！</td><td align="center">10%</td></tr><tr><td align="center">三短一长</td><td align="center">(1,0,0,0)熵是 0</td><td align="center">10%</td></tr><tr><td align="center">一样长</td><td align="center">(0.25,0.25,0.25,0.25)熵是 2</td><td align="center">80%</td></tr></tbody></table><p>计算条件熵（条件就是：题目不同类型）</p><p>$H(Y|X) \rm &#x3D; 0.1\times 0 + 0.1 \times 0 + 0.8 \times 2 &#x3D; 1.6bit$</p><p>那么信息增益是：</p><p>$g(X,Y) \rm &#x3D; H(Y) - H(Y|X) &#x3D; 2 - 1.6 &#x3D; 0.4bit$</p><p><strong>信息增益率</strong>在信息增益的基础上增加了惩罚项，惩罚项是特征的固有值。</p><p>写作 gr(X,Y)。定义为信息增益除以特征的固有值，如下：</p><p><font size = 5>$gr(X,Y) &#x3D; \frac{g(X,Y)}{Info(X)}$</font></p><p><font size = 5>$Info(X) &#x3D; -\sum\limits_{v \in values(X)}\frac{num(v)}{num(X)}log_2{\frac{num(v)}{num(X)}}$</font></p><p>计算上面单选题题目长短案例的信息增益率：</p><p><font size = 5>$Info(X) &#x3D; -(0.1 \times log_20.1 \times 2 + 0.8 \times log_20.8) &#x3D; 0.92$</font></p><p><font size = 5>$gr(X,Y) &#x3D; \frac{g(X,Y)}{Info(X)} &#x3D; \frac{0.4}{0.92} &#x3D; 0.43$</font></p><p>对于取值多的属性，尤其一些连续型数值，这个单独的属性就可以划分所有的样本，使得所有分支下的样本集合都是“纯的”（最极端的情况是每个叶子节点只有一个样本）。<br>一个属性的信息增益越大，表明属性对样本的熵减少的能力更强，这个属性使得数据由不确定性变成确定性的能力越强。<br>所以如果是取值更多的属性，更容易使得数据更“纯”（尤其是连续型数值），其信息增益更大，决策树会首先挑选这个属性作为树的顶点。结果训练出来的形状是一棵庞大且深度很浅的树，这样的划分是极为不合理的。</p><p><img src="/img/post/DecisionTree-Classification/10-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>C4.5 使用了信息增益率，在信息增益的基础上除了一项 split information,来惩罚值更多的属性。从而使划分更加合理！</p><h3 id="3-4、MSE"><a href="#3-4、MSE" class="headerlink" title="3.4、MSE"></a>3.4、MSE</h3><p>用于回归树，后面章节具体介绍</p><p><img src="/img/post/DecisionTree-Classification/11-%E5%9B%9E%E5%BD%92%E6%A0%91.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><h2 id="4、鸢尾花分类代码实战"><a href="#4、鸢尾花分类代码实战" class="headerlink" title="4、鸢尾花分类代码实战"></a>4、鸢尾花分类代码实战</h2><h3 id="4-1、决策树分类鸢尾花数据集"><a href="#4-1、决策树分类鸢尾花数据集" class="headerlink" title="4.1、决策树分类鸢尾花数据集"></a>4.1、决策树分类鸢尾花数据集</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X,y = datasets.load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth调整树深度：剪枝操作</span></span><br><span class="line"><span class="comment"># max_depth默认，深度最大，延伸到将数据完全划分开为止。</span></span><br><span class="line">model = DecisionTreeClassifier(max_depth=<span class="literal">None</span>,criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">model.fit(X_train,y_train)</span><br><span class="line">y_ = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;算法预测是：&#x27;</span>,y_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率是：&#x27;</span>,model.score(X_test,y_test))</span><br><span class="line"><span class="comment"># 决策树提供了predict_proba这个方法，发现这个方法，返回值要么是0，要么是1</span></span><br><span class="line">model.predict_proba(X_test)</span><br></pre></td></tr></table></figure><h3 id="4-2、决策树可视化"><a href="#4-2、决策树可视化" class="headerlink" title="4.2、决策树可视化"></a>4.2、决策树可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="comment"># 导出数据</span></span><br><span class="line">dot_data = tree.export_graphviz(model,feature_names=fn,</span><br><span class="line">                     class_names=iris[<span class="string">&#x27;target_names&#x27;</span>],<span class="comment"># 类别名</span></span><br><span class="line">                     filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                     rounded=<span class="literal">True</span>,)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;iris&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/img/post/DecisionTree-Classification/12-iris.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><h3 id="4-3、决策树剪枝"><a href="#4-3、决策树剪枝" class="headerlink" title="4.3、决策树剪枝"></a>4.3、决策树剪枝</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置图片的尺寸</span></span><br><span class="line"><span class="comment"># 鸢尾花4个属性</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">fn = iris[<span class="string">&#x27;feature_names&#x27;</span>]</span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># max_depth调整树深度：剪枝操作</span></span><br><span class="line"><span class="comment"># max_depth默认，深度最大，延伸到将数据完全划分开为止。</span></span><br><span class="line"><span class="comment"># min_impurity_decrease（节点划分最小不纯度）如果某节点的不纯度(基尼系数，信息增益，均方差)小于这个阈值，则该节点不再生成子节点</span></span><br><span class="line"><span class="comment"># max_depth（决策树最大深度）；min_samples_split（内部节点再划分所需最小样本数）</span></span><br><span class="line"><span class="comment"># min_samples_leaf（叶子节点最少样本数）；max_leaf_nodes（最大叶子节点数）</span></span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>,min_impurity_decrease=<span class="number">0.2</span>)</span><br><span class="line">model.fit(X_train,y_train)</span><br><span class="line">y_ = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;真实类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;算法预测是：&#x27;</span>,y_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率是：&#x27;</span>,model.score(X_test,y_test))</span><br><span class="line"><span class="comment"># 导出数据</span></span><br><span class="line">dot_data = tree.export_graphviz(model,feature_names=fn,</span><br><span class="line">                     class_names=iris[<span class="string">&#x27;target_names&#x27;</span>],<span class="comment"># 类别名</span></span><br><span class="line">                     filled=<span class="literal">True</span>, <span class="comment"># 填充颜色</span></span><br><span class="line">                     rounded=<span class="literal">True</span>,)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph.render(<span class="string">&#x27;./13-iris-裁剪&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/img/post/DecisionTree-Classification/13-iris-%E5%89%AA%E6%9E%9D.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><h3 id="4-4、选择合适的超参数并可视化"><a href="#4-4、选择合适的超参数并可视化" class="headerlink" title="4.4、选择合适的超参数并可视化"></a>4.4、选择合适的超参数并可视化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">X,y = datasets.load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = <span class="number">256</span>)</span><br><span class="line">depth = np.arange(<span class="number">1</span>,<span class="number">16</span>)</span><br><span class="line">err = []</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> depth:</span><br><span class="line">    model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>,max_depth=d)</span><br><span class="line">    model.fit(X_train,y_train)</span><br><span class="line">    score = model.score(X_test,y_test)</span><br><span class="line">    err.append(<span class="number">1</span> - score)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;错误率为%0.3f%%&#x27;</span> % (<span class="number">100</span> * (<span class="number">1</span> - score)))</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;STKaiti&#x27;</span></span><br><span class="line">plt.plot(depth,err,<span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;决策树深度&#x27;</span>,fontsize = <span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;错误率&#x27;</span>,fontsize = <span class="number">18</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;筛选合适决策树深度&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.savefig(<span class="string">&#x27;./14-筛选超参数.png&#x27;</span>,dpi = <span class="number">200</span>)</span><br></pre></td></tr></table></figure><p><img src="/img/post/DecisionTree-Classification/14-%E7%AD%9B%E9%80%89%E8%B6%85%E5%8F%82%E6%95%B0.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><h3 id="4-5、决策树副产物"><a href="#4-5、决策树副产物" class="headerlink" title="4.5、决策树副产物"></a>4.5、决策树副产物</h3><ul><li><p>特征重要性</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;</summary>
    
    
    
    <category term="学习记录类" scheme="https://www.adream.icu/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%E7%B1%BB/"/>
    
    
    <category term="算法" scheme="https://www.adream.icu/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="机器学习" scheme="https://www.adream.icu/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归二分类</title>
    <link href="https://www.adream.icu/2021/06/11/LogisticRegression/"/>
    <id>https://www.adream.icu/2021/06/11/LogisticRegression/</id>
    <published>2021-06-11T04:20:59.000Z</published>
    <updated>2024-03-12T12:09:34.692Z</updated>
    
    <content type="html"><![CDATA[<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h2 id="1、广义线性回归到逻辑回归"><a href="#1、广义线性回归到逻辑回归" class="headerlink" title="1、广义线性回归到逻辑回归"></a>1、广义线性回归到逻辑回归</h2><h3 id="1-1、什么是逻辑回归"><a href="#1-1、什么是逻辑回归" class="headerlink" title="1.1、什么是逻辑回归"></a>1.1、什么是逻辑回归</h3><p>&emsp;&emsp;逻辑回归<strong>不是</strong>一个回归的算法，逻辑回归是一个<strong>分类</strong>的算法，好比卡巴斯基不是司机，红烧狮子头没有狮子头一样。 那为什么逻辑回归不叫逻辑分类？因为逻辑回归算法是基于多元线性回归的算法。而正因为此，逻辑回归这个分类算法是线性的分类器。未来我们要学的基于决策树的一系列算法，基于神经网络的算法等那些是非线性的算法。SVM 支持向量机的本质是线性的，但是也可以通过内部的核函数升维来变成非线性的算法。</p><p>&emsp;&emsp;逻辑回归中对应一条非常重要的曲线 S 型曲线，对应的函数是 Sigmoid 函数：</p><p><font size = 6>$f(x) &#x3D; \frac{1}{1 + e^{-x}}$</font></p><p>它有一个非常棒的特性，其导数可以用其自身表示：</p><p><font size = 6>$f’(x) &#x3D; \frac{e^{-x}}{(1 + e^{-x})^2} &#x3D;f(x) * \frac{1 + e^{-x} - 1}{1 + e^{-x}} &#x3D; f(x) * (1 - f(x))$</font></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-x))</span><br><span class="line">x = np.linspace(-<span class="number">5</span>,<span class="number">5</span>,<span class="number">100</span>)</span><br><span class="line">y = sigmoid(x)</span><br><span class="line">plt.plot(x,y,color = <span class="string">&#x27;green&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="/../img/post/LogisticRegression/1-S%E5%9E%8B%E6%9B%B2%E7%BA%BF.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><h3 id="1-2、Sigmoid-函数介绍"><a href="#1-2、Sigmoid-函数介绍" class="headerlink" title="1.2、Sigmoid 函数介绍"></a>1.2、Sigmoid 函数介绍</h3><p>&emsp;&emsp;逻辑回归就是在多元线性回归基础上把结果缩放到 0 ~ 1 之间。 $h_{\theta}(x)$ 越接近 1 越是正例，$h_{\theta}(x)$ 越接近 0 越是负例，根据中间 0.5 将数据分为二类。其中$h_{\theta}(x)$ 就是概率函数~</p><p><font size = 8>$h_{\theta}(x) &#x3D; g(\theta^Tx) &#x3D; \frac{1}{1 + e^{-\theta^Tx}}$</font></p><p>&emsp;&emsp;我们知道分类器的本质就是要找到分界，所以当我们把 0.5 作为分类边界时，我们要找的就是$\hat{y} &#x3D; h_{\theta}(x) &#x3D; \frac{1}{1 + e^{-\theta^Tx}} &#x3D; 0.5$ ，即 $z &#x3D; \theta^Tx &#x3D; 0$ 时，$\theta$ 的解~</p><p><img src="/../img/post/LogisticRegression/2-sigmoid.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>求解过程如下：</p><p><img src="/../img/post/LogisticRegression/3-Sigmoid.jpeg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>&emsp;&emsp;什么事情，都要做到知其然，知其所以然，我们知道二分类有个特点就是正例的概率 + 负例的概率 &#x3D; 1。一个非常简单的试验是只有两种可能结果的试验，比如正面或反面，成功或失败，有缺陷或没有缺陷，病人康复或未康复等等。为方便起见，记这两个可能的结果为 0 和 1，下面的定义就是建立在这类试验基础之上的。 如果随机变量 x 只取 0 和 1 两个值，并且相应的概率为：</p><ul><li>$Pr(x &#x3D; 1) &#x3D; p; Pr(x &#x3D; 0) &#x3D; 1-p; 0 &lt; p &lt; 1$</li></ul><p>&emsp;&emsp;则称随机变量 x 服从参数为 p 的<strong>Bernoulli</strong>伯努利分布( 0-1 分布)，则 x 的概率函数可写：</p><ul><li>$f(x | p) &#x3D; \begin{cases}p^x(1 - p)^{1-x}, &amp;x &#x3D;  1、0\0,&amp; x \neq 1、0\end{cases}$</li></ul><p>&emsp;&emsp;逻辑回归二分类任务会把正例的 label 设置为 1，负例的 label 设置为 0，对于上面公式就是 x &#x3D; 0、1。</p><h2 id="2、逻辑回归公式推导"><a href="#2、逻辑回归公式推导" class="headerlink" title="2、逻辑回归公式推导"></a>2、逻辑回归公式推导</h2><h3 id="2-1、损失函数推导"><a href="#2-1、损失函数推导" class="headerlink" title="2.1、损失函数推导"></a>2.1、损失函数推导</h3><p>&emsp;&emsp;这里我们依然会用到最大似然估计思想，根据若干已知的 X,y(训练集) 找到一组 $\theta$ 使得 X 作为已知条件下 y 发生的概率最大。</p><p><font size = 6>$P(y|x;\theta) &#x3D; \begin{cases}h_{\theta}(x), &amp;y &#x3D;  1\1-h_{\theta}(x),&amp; y &#x3D;  0\end{cases}$ </font></p><p><strong>整合到一起（二分类就两种情况：1、0）得到<font color = 'green'>逻辑回归表达式</font>：</strong></p><p><font size = 6 color = 'green'>$P(y|x;\theta) &#x3D; (h_{\theta}(x))^{y}(1 - h_{\theta}(x))^{1-y}$</font></p><p>我们假设训练样本相互独立，那么似然函数表达式为:</p><p><font size = 6>$L(\theta) &#x3D; \prod\limits_{i &#x3D; 1}^nP(y^{(i)}|x^{(i)};\theta)$</font></p><p><font size = 6>$L(\theta) &#x3D; \prod\limits_{i&#x3D;1}^n(h_{\theta}(x^{(i)}))^{y^{(i)}}(1 - h_{\theta}(x^{(i)}))^{1-y^{(i)}}$</font></p><p><font color = red size = 6>对数转换，自然底数为底</font></p><p><font size = 5>$l(\theta) &#x3D; \ln{L(\theta)} &#x3D;\ln( \prod\limits_{i&#x3D;1}^n({h_{\theta}(x^{(i)}))^{y^{(i)}}}{(1 - h_{\theta}(x^{(i)}))^{1-y^{(i)}}})$​​</font></p><p>化简，累乘变累加：</p><p><font size = 5>$l(\theta) &#x3D; \ln{L(\theta)} &#x3D; \sum\limits_{i &#x3D; 1}^n(y^{(i)}\ln(h_{\theta}(x^{(i)})) + (1-y^{(i)})\ln(1-h_{\theta}(x^{(i)})))$</font></p><p>&emsp;&emsp;<strong>总结</strong>，得到了逻辑回归的表达式，下一步跟线性回归类似，构建似然函数，然后最大似然估计，最终推导出 $\theta$ 的迭代更新表达式。只不过这里用的不是梯度下降，而是梯度上升，因为这里是最大化似然函数。通常我们一提到损失函数，往往是求最小，这样我们就可以用<strong>梯度下降</strong>来求解。最终损失函数就是上面公式加负号的形式:</p><p><font size = 5 color = 'green'>$J(\theta) &#x3D; -l(\theta) &#x3D; -\sum\limits_{i &#x3D; 1}^n[y^{(i)}\ln(h_{\theta}(x^{(i)})) + (1-y^{(i)})\ln(1-h_{\theta}(x^{(i)}))]$</font></p><h3 id="2-2、立体化呈现"><a href="#2-2、立体化呈现" class="headerlink" title="2.2、立体化呈现"></a>2.2、立体化呈现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> scale <span class="comment"># 数据标准化Z-score</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、加载乳腺癌数据</span></span><br><span class="line">data = datasets.load_breast_cancer()</span><br><span class="line">X, y = scale(data[<span class="string">&#x27;data&#x27;</span>][:, :<span class="number">2</span>]), data[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、求出两个维度对应的数据在逻辑回归算法下的最优解</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、分别把两个维度所对应的参数W1和W2取出来</span></span><br><span class="line">w1 = lr.coef_[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">w2 = lr.coef_[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(w1, w2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、已知w1和w2的情况下，传进来数据的X，返回数据的y_predict</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">X, w1, w2</span>):</span><br><span class="line">    z = w1*X[<span class="number">0</span>] + w2*X[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、传入一份已知数据的X，y，如果已知w1和w2的情况下，计算对应这份数据的Loss损失</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_function</span>(<span class="params">X, y, w1, w2</span>):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历数据集中的每一条样本，并且计算每条样本的损失，加到loss身上得到整体的数据集损失</span></span><br><span class="line">    <span class="keyword">for</span> x_i, y_i <span class="keyword">in</span> <span class="built_in">zip</span>(X, y):</span><br><span class="line">        <span class="comment"># 这是计算一条样本的y_predict，即概率</span></span><br><span class="line">        p = sigmoid(x_i, w1, w2)</span><br><span class="line">        loss += -<span class="number">1</span>*y_i*np.log(p)-(<span class="number">1</span>-y_i)*np.log(<span class="number">1</span>-p)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、参数w1和w2取值空间</span></span><br><span class="line">w1_space = np.linspace(w1-<span class="number">2</span>, w1+<span class="number">2</span>, <span class="number">100</span>)</span><br><span class="line">w2_space = np.linspace(w2-<span class="number">2</span>, w2+<span class="number">2</span>, <span class="number">100</span>)</span><br><span class="line">loss1_ = np.array([loss_function(X, y, i, w2) <span class="keyword">for</span> i <span class="keyword">in</span> w1_space])</span><br><span class="line">loss2_ = np.array([loss_function(X, y, w1, i) <span class="keyword">for</span> i <span class="keyword">in</span> w2_space])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7、数据可视化</span></span><br><span class="line">fig1 = plt.figure(figsize=(<span class="number">12</span>, <span class="number">9</span>))</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(w1_space, loss1_)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(w2_space, loss2_)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">w1_grid, w2_grid = np.meshgrid(w1_space, w2_space)</span><br><span class="line">loss_grid = loss_function(X, y, w1_grid, w2_grid)</span><br><span class="line">plt.contour(w1_grid, w2_grid, loss_grid,<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.contourf(w1_grid, w2_grid, loss_grid,<span class="number">20</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;../img/post/LogisticRegression/4-损失函数可视化.png&#x27;</span>,dpi = <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8、3D立体可视化</span></span><br><span class="line">fig2 = plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">ax = Axes3D(fig2)</span><br><span class="line">ax.plot_surface(w1_grid, w2_grid, loss_grid,cmap = <span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;w1&#x27;</span>,fontsize = <span class="number">20</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;w2&#x27;</span>,fontsize = <span class="number">20</span>)</span><br><span class="line">ax.view_init(<span class="number">30</span>,-<span class="number">30</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;../img/post/LogisticRegression/5-损失函数可视化.png&#x27;</span>,dpi = <span class="number">200</span>)</span><br></pre></td></tr></table></figure><p><img src="/../img/post/LogisticRegression/4-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%AF%E8%A7%86%E5%8C%96.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p><img src="/../img/post/LogisticRegression/5-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%AF%E8%A7%86%E5%8C%96.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><h2 id="3、逻辑回归迭代公式"><a href="#3、逻辑回归迭代公式" class="headerlink" title="3、逻辑回归迭代公式"></a>3、逻辑回归迭代公式</h2><h3 id="3-1、函数特性"><a href="#3-1、函数特性" class="headerlink" title="3.1、函数特性"></a>3.1、函数特性</h3><p>&emsp;&emsp;逻辑回归参数更新规则和，线性回归一模一样！</p><p><font size = 6>$\theta_j^{t + 1} &#x3D; \theta_j^t - \alpha\frac{\partial}{\partial_{\theta_j}}J(\theta)$</font></p><ul><li>$\alpha$ 表示学习率</li></ul><p>逻辑回归函数：</p><p><font size = 6>$h_{\theta}(x) &#x3D; g(\theta^Tx) &#x3D; g(z) &#x3D; \frac{1}{1 + e^{-z}}$</font></p><ul><li>$z &#x3D; \theta^Tx$</li></ul><p>逻辑回归函数求导时有一个特性，这个特性将在下面的推导中用到，这个特性为：</p><p><font size = 4>$\begin{aligned} g’(z) &amp;&#x3D; \frac{\partial}{\partial z}\frac{1}{1 + e^{-z}} \\&amp;&#x3D; \frac{e^{-z}}{(1 + e^{-z})^2}\\&amp; &#x3D; \frac{1}{(1 + e^{-z})^2}\cdot e^{-z}\\&amp;&#x3D;\frac{1}{1 + e^{-z}} \cdot (1 - \frac{1}{1 + e^{-z}})\\&amp;&#x3D;g(z)\cdot (1 - g(z))\end{aligned}$</font></p><p>回到逻辑回归损失函数求导：</p><p><font size = 4>$J(\theta) &#x3D;  -\sum\limits_{i &#x3D; 1}^n(y^{(i)}\ln(h_{\theta}(x^{i})) + (1-y^{(i)})\ln(1-h_{\theta}(x^{(i)})))$</font></p><h3 id="3-2、求导过程"><a href="#3-2、求导过程" class="headerlink" title="3.2、求导过程"></a>3.2、求导过程</h3><p><font size = 4>$\begin{aligned} \frac{\partial}{\partial{\theta_j}}J(\theta) &amp;&#x3D; -\sum\limits_{i &#x3D; 1}^n(y^{(i)}\frac{1}{h_{\theta}(x^{(i)})}\frac{\partial}{\partial_{\theta_j}}h_{\theta}(x^{i}) + (1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})}\frac{\partial}{\partial_{\theta_j}}(1-h_{\theta}(x^{(i)}))) \\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)}\frac{1}{h_{\theta}(x^{(i)})}\frac{\partial}{\partial_{\theta_j}}h_{\theta}(x^{(i)}) - (1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})}\frac{\partial}{\partial_{\theta_j}}h_{\theta}(x^{(i)}))\\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)}\frac{1}{h_{\theta}(x^{(i)})} - (1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})})\frac{\partial}{\partial_{\theta_j}}h_{\theta}(x^{(i)})\\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)}\frac{1}{h_{\theta}(x^{(i)})} - (1-y^{(i)})\frac{1}{1-h_{\theta}(x^{(i)})})h_{\theta}(x^{(i)})(1-h_{\theta}(x^{(i)}))\frac{\partial}{\partial_{\theta_j}}\theta^Tx\\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)}(1-h_{\theta}(x^{(i)})) - (1-y^{(i)})h_{\theta}(x^{(i)}))\frac{\partial}{\partial_{\theta_j}}\theta^Tx\\&amp;&#x3D;-\sum\limits_{i &#x3D; 1}^n(y^{(i)} - h_{\theta}(x^{(i)}))\frac{\partial}{\partial_{\theta_j}}\theta^Tx\\&amp;&#x3D;\sum\limits_{i &#x3D; 1}^n(h_{\theta}(x^{(i)}) -y^{(i)})x_j^{(i)}\end{aligned}$</font></p><p>求导最终的公式：</p><p><font color = 'red' size = 6>$\frac{\partial}{\partial{\theta_j}}J(\theta) &#x3D; \sum\limits_{i &#x3D; 1}^n(h_{\theta}(x^{(i)}) -y^{(i)})x_j^{(i)}$</font></p><p>这里我们发现导函数的形式和多元线性回归一样~</p><p>逻辑回归参数迭代更新公式：</p><p><font size = 6 color = 'green'>$\theta_j^{t+1} &#x3D; \theta_j^t - \alpha \cdot \sum\limits_{i&#x3D;1}^{n}(h_{\theta}(x^{(i)}) -y^{(i)})x_j^{(i)}$</font></p><h3 id="3-3、代码实战"><a href="#3-3、代码实战" class="headerlink" title="3.3、代码实战"></a>3.3、代码实战</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、数据加载</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据提取与筛选</span></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">cond = y != <span class="number">2</span></span><br><span class="line">X = X[cond]</span><br><span class="line">y = y[cond]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、数据拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、模型训练</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、模型预测</span></span><br><span class="line">y_predict = lr.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据保留类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测类别是：&#x27;</span>,y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测概率是：\n&#x27;</span>,lr.predict_proba(X_test))</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>通过数据提取与筛选，创建二分类问题</li><li>类别的划分，通过概率比较大小完成了</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 线性回归方程</span></span><br><span class="line">b = lr.intercept_</span><br><span class="line">w = lr.coef_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = 1 概率</span></span><br><span class="line">z = X_test.dot(w.T) + b</span><br><span class="line">p_1 = sigmoid(z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y = 0 概率</span></span><br><span class="line">p_0 = <span class="number">1</span> - p_1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终结果</span></span><br><span class="line">p = np.concatenate([p_0,p_1],axis = <span class="number">1</span>)</span><br><span class="line">p</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>线性方程，对应方程 $z$</li><li>sigmoid 函数，将线性方程转变为概率</li><li>自己求解概率和直接使用 LogisticRegression 结果一样，可知计算流程正确</li></ul><h2 id="4、逻辑回归做多分类"><a href="#4、逻辑回归做多分类" class="headerlink" title="4、逻辑回归做多分类"></a>4、逻辑回归做多分类</h2><h3 id="4-1、One-Vs-Rest-思想"><a href="#4-1、One-Vs-Rest-思想" class="headerlink" title="4.1、One-Vs-Rest 思想"></a>4.1、One-Vs-Rest 思想</h3><p>&emsp;&emsp;在上面，我们主要使用逻辑回归解决二分类的问题，那对于多分类的问题，也可以用逻辑回归来解决！</p><p>多分类问题：</p><ul><li>将邮件分为不同类别&#x2F;标签：工作(y&#x3D;1)，朋友(y&#x3D;2)，家庭(y&#x3D;3)，爱好(y&#x3D;4)</li><li>天气分类：晴天(y&#x3D;1)，多云天(y&#x3D;2)，下雨天(y&#x3D;3)，下雪天(y&#x3D;4)</li><li>医学图示：没生病(y&#x3D;1)，感冒(y&#x3D;2)，流感(y&#x3D;3)</li><li>……</li></ul><p>上面都是多分类问题。</p><p>假设我们要解决一个分类问题，该分类问题有三个类别，分别用 △，□ 和 × 表示，每个实例有两个属性，如果把属性 1 作为 X 轴，属性 2 作为 Y 轴，训练集的分布可以表示为下图：</p><p><img src="/../img/post/LogisticRegression/6-ovr%E5%A4%9A%E5%88%86%E7%B1%BB.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>&emsp;&emsp;One-Vs-Rest（ovr）的思想是把一个多分类的问题变成多个二分类的问题。转变的思路就如同方法名称描述的那样，选择其中一个类别为正类（Positive），使其他所有类别为负类（Negative）。比如第一步，我们可以将 △ 所代表的实例全部视为正类，其他实例全部视为负类，得到的分类器如图：</p><p><img src="/../img/post/LogisticRegression/7-ovr%E5%A4%9A%E5%88%86%E7%B1%BB.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>同理我们把 × 视为正类，其他视为负类，可以得到第二个分类器：</p><p><img src="/../img/post/LogisticRegression/8-ovr%E5%A4%9A%E5%88%86%E7%B1%BB.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>最后，第三个分类器是把 □ 视为正类，其余视为负类：</p><p><img src="/../img/post/LogisticRegression/9-ovr%E5%A4%9A%E5%88%86%E7%B1%BB.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><p>&emsp;&emsp;对于一个三分类问题，我们最终得到 3 个二元分类器。在预测阶段，每个分类器可以根据测试样本，得到当前类别的概率。即 P(y &#x3D; i | x; θ)，i &#x3D; 1, 2, 3。选择计算结果最高的分类器，其所对应类别就可以作为预测结果。</p><p>One-Vs-Rest 作为一种常用的二分类拓展方法，其优缺点也十分明显：</p><ul><li><p>优点：普适性还比较广，可以应用于能输出值或者概率的分类器，同时效率相对较好，有多少个类别就训练多少个分类器。</p></li><li><p>缺点：很容易造成训练集样本数量的不平衡（Unbalance），尤其在类别较多的情况下，经常容易出现正类样本的数量远远不及负类样本的数量，这样就会造成分类器的偏向性。</p></li></ul><h3 id="4-2、代码实战"><a href="#4-2、代码实战" class="headerlink" title="4.2、代码实战"></a>4.2、代码实战</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、数据加载</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据提取</span></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、数据拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、模型训练</span></span><br><span class="line">lr = LogisticRegression(multi_class = <span class="string">&#x27;ovr&#x27;</span>)</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、模型预测</span></span><br><span class="line">y_predict = lr.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据保留类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测类别是：&#x27;</span>,y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测概率是：\n&#x27;</span>,lr.predict_proba(X_test))</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>通过数据提取，创建三分类问题</li><li>类别的划分，通过概率比较大小完成了</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 线性回归方程，3个方程</span></span><br><span class="line">b = lr.intercept_</span><br><span class="line">w = lr.coef_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算三个方程的概率</span></span><br><span class="line">z = X_test.dot(w.T) + b</span><br><span class="line">p = sigmoid(z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化处理，概率求和为1</span></span><br><span class="line">p = p/p.<span class="built_in">sum</span>(axis = <span class="number">1</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">p</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>线性方程，对应方程 $z$ ，此时对应三个方程</li><li>sigmoid 函数，将线性方程转变为概率，并进行标准化处理</li><li>自己求解概率和直接使用 LogisticRegression 结果一样</li></ul><h2 id="5、多分类-Softmax-回归"><a href="#5、多分类-Softmax-回归" class="headerlink" title="5、多分类 Softmax 回归"></a>5、多分类 Softmax 回归</h2><h3 id="5-1、多项分布指数分布族形式"><a href="#5-1、多项分布指数分布族形式" class="headerlink" title="5.1、多项分布指数分布族形式"></a>5.1、多项分布指数分布族形式</h3><p>&emsp;&emsp;Softmax 回归是另一种做多分类的算法。从名字中大家是不是可以联想到广义线性回归，Softmax 回归是假设多项分布的，多项分布可以理解为二项分布的扩展。投硬币是二项分布，掷骰子是多项分布。</p><p>&emsp;&emsp;我们知道，对于伯努利分布，我们采用 Logistic 回归建模。那么我们应该如何处理多分类问题？对于这种多项分布我们使用 softmax 回归建模。</p><p>y 有多个可能的分类： $y \in {1,2,3,……,k}$，</p><p>每种分类对应的概率： $\phi_1,\phi_2……\phi_k$ ，由于 $\sum\limits_{i &#x3D; 1}^k\phi_i &#x3D; 1$ ，所以一般用 k-1 个参数$\phi_1,\phi_2……\phi_{k-1}$ 。其中：</p><ul><li>$p(y &#x3D; i;\phi) &#x3D; \phi_i$</li><li>$p(y &#x3D; k;\phi) &#x3D; 1 - \sum\limits_{i &#x3D; 1}^{k -1}\phi_i$ 。</li></ul><p>为了将多项分布表达为指数族分布，做一下工作：</p><ul><li><p>定义 ，$T(y) \in R^{k-1}$它不再是一个数而是一个变量</p><p><img src="/../img/post/LogisticRegression/9-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%88%86%E5%B8%83.png" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p></li><li><p>引进指示函数：$I{\cdot}$为$I{True} &#x3D; 1$，$I{False} &#x3D; 0$</p><p>$E(T(y)_i) &#x3D; p(y &#x3D; i) &#x3D; \phi_i$</p></li></ul><p>得到它的指数分布族形式：</p><p><font size = 4>$\begin{aligned}p(y;\phi) &amp;&#x3D; \phi_1^{I{y &#x3D; 1}}\phi_2^{I{y &#x3D; 2}}…\phi_k^{I{y &#x3D; k}}\\&amp;&#x3D;\phi_1^{I{y &#x3D; 1}}\phi_2^{I{y &#x3D; 2}}…\phi_k^{1 - \sum\limits_{i&#x3D;1}^{k-1}I{y &#x3D; i}}\\&amp;&#x3D;\phi_1^{(T(y))_1}\phi_2^{(T(y))<em>2}…\phi_k^{1 - \sum\limits</em>{i &#x3D; 1}^{k-1}(T(y))_i}\\&amp;&#x3D;\exp((T(y))_1\log(\phi_1) + (T(y))<em>2\log(\phi_2)…+(1 - \sum\limits</em>{i &#x3D; 1}^{k-1}(T(y))_i)\log(\phi_k))\\&amp;&#x3D;\exp((T(y))<em>1\log\frac{\phi_1}{\phi_k} + (T(y))<em>2\log\frac{\phi_2}{\phi_k} + … + (T(y))</em>{k-1}\log\frac {\phi</em>{k-1}}{\phi_k} + \log(\phi_k))\end{aligned}$</font></p><p>指数分布族标准表达式如下：</p><p><font size = 6>$p(y;\eta) &#x3D; b(y)\exp(\eta T(y) - \alpha(\eta))$</font></p><p><strong>得到对应模型参数：</strong></p><p>$ \eta &#x3D; \left{ \begin{aligned} &amp;\log(\phi<em>1&#x2F;\phi_k) \ &amp;\log(\phi_2&#x2F;\phi_k) \ &amp;…\&amp;\log(\phi</em>{k-1}&#x2F;\phi_k) \end{aligned} \right.$</p><p>$\alpha(\eta) &#x3D; -\log(\phi_k)$</p><p>$b(y) &#x3D; 1$</p><h3 id="5-2、广义线性模型推导-Softmax-回归"><a href="#5-2、广义线性模型推导-Softmax-回归" class="headerlink" title="5.2、广义线性模型推导 Softmax 回归"></a>5.2、广义线性模型推导 Softmax 回归</h3><p>&emsp;&emsp;证明了多项分布属于指数分布族后，接下来求取由它推导出的概率函数 Softmax</p><ul><li><p><font size = 5>$\eta_i &#x3D; \log\frac{\phi_i}{\phi_k}$   —&gt;   $e^{\eta_i} &#x3D; \frac{\phi_i}{\phi_k}$   —&gt;   $\phi_ke^{\eta_i} &#x3D; \phi_i$</font></p></li><li><p><font size = 5>$\phi_k\sum\limits_{i &#x3D; 1}^k e^{\eta_i} &#x3D; \sum\limits_{i &#x3D; 1}^k &#x3D; 1$</font></p></li><li><p><font size = 5>$\phi_k &#x3D; \frac{1}{\sum\limits_{i &#x3D; 1}^ke^{\eta_i}}$</font></p></li><li><p><font size = 5 color = 'red'>$\phi_i &#x3D; \frac{e^{\eta_i}}{\sum\limits_{j &#x3D; 1}^ke^{\eta_j}}$</font></p></li></ul><p>上面这个函数，就叫做 Softmax 函数。</p><p>引用广义线性模型的<strong>假设 3</strong>，即 $\eta$ 是 x 的线性函数，带入 Softmax 函数可以得到：</p><p><font size = 5>$\begin{aligned}p(y &#x3D; i|x;\theta) &amp;&#x3D; \phi_i \\ &amp;&#x3D;\frac{e^{\eta_i}}{\sum\limits_{j &#x3D; 1}^ke^{\eta_j}} \\&amp;&#x3D;\frac{e^{\theta_i^Tx}}{\sum\limits_{j &#x3D; 1}^ke^{\theta_j^Tx}}\end{aligned}$</font></p><p>这个模型被应用到 y &#x3D; {1, 2, …, k}就称作<strong>Softmax 回归</strong>，是逻辑回归的推广。最终可以得到它的假设函数 $h_{\theta}(x)$：</p><p><font size = 5>$ h*{\theta}(x) &#x3D; \left{ \begin{aligned} &amp;\frac{e^{\theta_1^Tx}}{\sum\limits*{j &#x3D; 1}^ke^{\theta<em>j^Tx}} , y &#x3D; 1\ &amp;\frac{e^{\theta_2^Tx}}{\sum\limits</em>{j &#x3D; 1}^ke^{\theta<em>j^Tx}} , y &#x3D; 2\ &amp;…\&amp;\frac{e^{\theta_k^Tx}}{\sum\limits</em>{j &#x3D; 1}^ke^{\theta_j^Tx}}, y &#x3D; k \end{aligned} \right.$</font></p><p>举例说明：</p><p><img src="/../img/post/LogisticRegression/10-softmax.jpeg" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p><h3 id="5-3、代码实战"><a href="#5-3、代码实战" class="headerlink" title="5.3、代码实战"></a>5.3、代码实战</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、数据加载</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据提取</span></span><br><span class="line">X = iris[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、数据拆分</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、模型训练，使用multinomial分类器，表示多分类</span></span><br><span class="line">lr = LogisticRegression(multi_class = <span class="string">&#x27;multinomial&#x27;</span>,max_iter=<span class="number">5000</span>)</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、模型预测</span></span><br><span class="line">y_predict = lr.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据保留类别是：&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测类别是：&#x27;</span>,y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试数据算法预测概率是：\n&#x27;</span>,lr.predict_proba(X_test))</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>通过数据提取，创建三分类问题</li><li>参数 multi_class 设置成 multinomial 表示多分类，使用交叉熵作为损失函数</li><li>类别的划分，通过概率比较大小完成了</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 线性回归方程，3个方程</span></span><br><span class="line">b = lr.intercept_</span><br><span class="line">w = lr.coef_</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(z)/np.exp(z).<span class="built_in">sum</span>(axis = <span class="number">1</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算三个方程的概率</span></span><br><span class="line">z = X_test.dot(w.T) + b</span><br><span class="line">p = softmax(z)</span><br><span class="line">p</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>线性方程，对应方程 $z$ ，多分类，此时对应三个方程</li><li>softmax 函数，将线性方程转变为概率</li><li>自己求解概率和直接使用 LogisticRegression 结果一样</li></ul><h2 id="6、逻辑回归与-Softmax-回归对比"><a href="#6、逻辑回归与-Softmax-回归对比" class="headerlink" title="6、逻辑回归与 Softmax 回归对比"></a>6、逻辑回归与 Softmax 回归对比</h2><h3 id="6-1、逻辑回归是-Softmax-回归特例证明"><a href="#6-1、逻辑回归是-Softmax-回归特例证明" class="headerlink" title="6.1、逻辑回归是 Softmax 回归特例证明"></a>6.1、逻辑回归是 Softmax 回归特例证明</h3><p>逻辑回归可以看成是 Softmax 回归的特例，当 k &#x3D; 2 时，softmax 回归退化为逻辑回归，softmax 回归的假设函数为：</p><p><font size = 5>$h_{\theta}(x) &#x3D; \frac{1}{e^{\theta_1^Tx} + e^{\theta_2^Tx}} \Bigg[\begin{aligned}e^{\theta_1^Tx}\e^{\theta_2^Tx} \end{aligned}\Bigg]$</font></p><p>利用 softmax 回归参数冗余的特点，我们令$\psi &#x3D; \theta_1$并且从两个参数向量中都减去向量 $\theta_1$ ，得到:</p><p><font size = 5>$h_{\theta}(x) &#x3D; \frac{1}{e^{\vec{0}^Tx}   + e^{(\theta_2 - \theta_1)^Tx}} \Bigg[\begin{aligned}&amp;e^{\vec{0}^Tx}\&amp;e^{(\theta_2 - \theta_1)^Tx} \end{aligned}\Bigg]$</font></p><p>展开：</p><p><font size = 5>$\frac{e^{\vec{0}^Tx} }{e^{\vec{0}^Tx}   + e^{(\theta_2 - \theta_1)^Tx}}$</font> —&gt; <font size = 5>$\frac{1}{1   + e^{(\theta_2 - \theta_1)^Tx}}$</font></p><p><font size =5>$\frac{ e^{(\theta_2 - \theta_1)^Tx} }{e^{\vec{0}^Tx}   + e^{(\theta_2 - \theta_1)^Tx}}$</font> —&gt; <font size =5>$\frac{ e^{(\theta_2 - \theta_1)^Tx} }{1   + e^{(\theta_2 - \theta_1)^Tx}}$</font></p><p>因此，用$\theta$ 来表示 $\theta_2 - \theta_1$：</p><p><font size = 5>$\frac{1}{1   + e^{\theta^Tx}}$</font></p><p><font size =5>$\frac{ e^{\theta^Tx} }{1   + e^{\theta^Tx}}$</font> —&gt;<font size =5>$\frac{ 1 }{1   + e^{-\theta^Tx}}$</font> （这就是逻辑回归公式）</p><h3 id="6-2、Softmax-损失函数"><a href="#6-2、Softmax-损失函数" class="headerlink" title="6.2、Softmax 损失函数"></a>6.2、Softmax 损失函数</h3><p>求极大似然：</p><p><font size = 5>$L(\theta) &#x3D; \prod\limits_{i &#x3D; 1}^np(y^{(i)}|x^{(i)};\theta) &#x3D; \prod\limits_{i &#x3D; 1}^n\prod\limits_{j &#x3D; 1}^k\phi_j^{I&lt;!–swig￼8–&gt;}$</font></p><p>求对数：</p><p><font size = 5>$\begin{aligned}l(\theta) &amp;&#x3D; \sum\limits_{i &#x3D; 1}^n\log p(y^{(i)}|x^{(i)};\theta) \ \&amp;&#x3D;\sum\limits_{i &#x3D; 1}^n\log\prod\limits_{j &#x3D; 1}^k\phi_j^{I&lt;!–swig￼9–&gt;}\\&amp;&#x3D; \sum\limits_{i &#x3D; 1}^n\log\prod\limits_{j &#x3D; 1}^k(\frac{e^{\theta_j^Tx^{(i)}}}{\sum\limits_{l &#x3D; 1}^ke^{\theta_l^Tx^{(i)}}})^{I&lt;!–swig￼10–&gt;}\end{aligned}$</font></p><p>取反，损失函数是：</p><p><font size = 5>$\begin{aligned}J(\theta) &amp;&#x3D; -\sum\limits*{i &#x3D; 1}^n\log\prod\limits*{j &#x3D; 1}^k(\frac{e^{\theta<em>j^Tx^{(i)}}}{\sum\limits</em>{l &#x3D; 1}^ke^{\theta<em>l^Tx^{(i)}}})^{I&lt;!–swig￼11–&gt;}\\ &amp;&#x3D; \sum\limits</em>{i &#x3D; 1}^n\sum\limits*{j &#x3D; 1}^kI&lt;!–swig￼12–&gt;\log\frac{e^{\theta_j^Tx^{(i)}}}{\sum\limits*{l &#x3D; 1}^ke^{\theta_l^Tx^{(i)}}}\end{aligned} $</font></p><p>上面公式对应着<strong>交叉熵</strong>！</p><p>对比百度百科给出的交叉熵定义公式，H(p,q)称之为交叉熵（p 为真实分布，q 为非真实分布即预测概率）：</p><p><font size =5>$H(p,q) &#x3D; \sum\limits_ip(i)\cdot log(\frac{1}{q(i)})$</font></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;逻辑回归&quot;&gt;&lt;a href=&quot;#逻辑回归&quot; class=&quot;headerlink&quot; title=&quot;逻辑回归&quot;&gt;&lt;/a&gt;逻辑回归&lt;/h1&gt;&lt;h2 id=&quot;1、广义线性回归到逻辑回归&quot;&gt;&lt;a href=&quot;#1、广义线性回归到逻辑回归&quot; class=&quot;headerlink</summary>
      
    
    
    
    <category term="学习记录类" scheme="https://www.adream.icu/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%E7%B1%BB/"/>
    
    
    <category term="算法" scheme="https://www.adream.icu/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="机器学习" scheme="https://www.adream.icu/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
